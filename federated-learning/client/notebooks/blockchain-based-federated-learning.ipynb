{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of one round of blockchain-based federated learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n",
      "Using device: cuda\n",
      "Cuda set as default device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config variables for models and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.train import train\n",
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, weights_zero_init,  weights_init, update_lr\n",
    "from client.aggregators import federated_aggregate\n",
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two local models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "\n",
    "model1 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model1.to(device)\n",
    "print(model1)\n",
    "\n",
    "model2 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train first local model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3019\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2963\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2884\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2762\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2575\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2355\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2271\n",
      "Epoch [1/1], Step [9/245], Loss: 2.2054\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1763\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1626\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1433\n",
      "Epoch [1/1], Step [13/245], Loss: 2.1169\n",
      "Epoch [1/1], Step [14/245], Loss: 2.0500\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0615\n",
      "Epoch [1/1], Step [16/245], Loss: 2.0413\n",
      "Epoch [1/1], Step [17/245], Loss: 2.0203\n",
      "Epoch [1/1], Step [18/245], Loss: 2.0597\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0752\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0442\n",
      "Epoch [1/1], Step [21/245], Loss: 2.0299\n",
      "Epoch [1/1], Step [22/245], Loss: 1.9978\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0546\n",
      "Epoch [1/1], Step [24/245], Loss: 2.0400\n",
      "Epoch [1/1], Step [25/245], Loss: 1.8730\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9636\n",
      "Epoch [1/1], Step [27/245], Loss: 2.0168\n",
      "Epoch [1/1], Step [28/245], Loss: 2.0053\n",
      "Epoch [1/1], Step [29/245], Loss: 1.8916\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9510\n",
      "Epoch [1/1], Step [31/245], Loss: 1.8441\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9355\n",
      "Epoch [1/1], Step [33/245], Loss: 1.9534\n",
      "Epoch [1/1], Step [34/245], Loss: 1.8217\n",
      "Epoch [1/1], Step [35/245], Loss: 1.9426\n",
      "Epoch [1/1], Step [36/245], Loss: 1.8470\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9031\n",
      "Epoch [1/1], Step [38/245], Loss: 1.7801\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8541\n",
      "Epoch [1/1], Step [40/245], Loss: 1.8403\n",
      "Epoch [1/1], Step [41/245], Loss: 1.7908\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8510\n",
      "Epoch [1/1], Step [43/245], Loss: 1.7431\n",
      "Epoch [1/1], Step [44/245], Loss: 1.9062\n",
      "Epoch [1/1], Step [45/245], Loss: 1.9221\n",
      "Epoch [1/1], Step [46/245], Loss: 1.8530\n",
      "Epoch [1/1], Step [47/245], Loss: 1.8715\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8086\n",
      "Epoch [1/1], Step [49/245], Loss: 1.8320\n",
      "Epoch [1/1], Step [50/245], Loss: 1.8761\n",
      "Epoch [1/1], Step [51/245], Loss: 1.9405\n",
      "Epoch [1/1], Step [52/245], Loss: 1.7559\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8597\n",
      "Epoch [1/1], Step [54/245], Loss: 1.8055\n",
      "Epoch [1/1], Step [55/245], Loss: 1.8709\n",
      "Epoch [1/1], Step [56/245], Loss: 1.7905\n",
      "Epoch [1/1], Step [57/245], Loss: 1.9088\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8603\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8450\n",
      "Epoch [1/1], Step [60/245], Loss: 2.0085\n",
      "Epoch [1/1], Step [61/245], Loss: 1.9297\n",
      "Epoch [1/1], Step [62/245], Loss: 1.7529\n",
      "Epoch [1/1], Step [63/245], Loss: 1.8074\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8532\n",
      "Epoch [1/1], Step [65/245], Loss: 1.8650\n",
      "Epoch [1/1], Step [66/245], Loss: 1.8074\n",
      "Epoch [1/1], Step [67/245], Loss: 1.8126\n",
      "Epoch [1/1], Step [68/245], Loss: 1.9137\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7432\n",
      "Epoch [1/1], Step [70/245], Loss: 1.9039\n",
      "Epoch [1/1], Step [71/245], Loss: 1.8433\n",
      "Epoch [1/1], Step [72/245], Loss: 1.7267\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8518\n",
      "Epoch [1/1], Step [74/245], Loss: 1.8052\n",
      "Epoch [1/1], Step [75/245], Loss: 1.8099\n",
      "Epoch [1/1], Step [76/245], Loss: 1.9232\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8763\n",
      "Epoch [1/1], Step [78/245], Loss: 1.8152\n",
      "Epoch [1/1], Step [79/245], Loss: 1.7736\n",
      "Epoch [1/1], Step [80/245], Loss: 1.7765\n",
      "Epoch [1/1], Step [81/245], Loss: 1.8486\n",
      "Epoch [1/1], Step [82/245], Loss: 1.7818\n",
      "Epoch [1/1], Step [83/245], Loss: 1.8150\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7177\n",
      "Epoch [1/1], Step [85/245], Loss: 1.7617\n",
      "Epoch [1/1], Step [86/245], Loss: 1.7729\n",
      "Epoch [1/1], Step [87/245], Loss: 1.7913\n",
      "Epoch [1/1], Step [88/245], Loss: 1.7742\n",
      "Epoch [1/1], Step [89/245], Loss: 1.8071\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7582\n",
      "Epoch [1/1], Step [91/245], Loss: 1.7682\n",
      "Epoch [1/1], Step [92/245], Loss: 1.6996\n",
      "Epoch [1/1], Step [93/245], Loss: 1.7112\n",
      "Epoch [1/1], Step [94/245], Loss: 1.7372\n",
      "Epoch [1/1], Step [95/245], Loss: 1.7236\n",
      "Epoch [1/1], Step [96/245], Loss: 1.7721\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7512\n",
      "Epoch [1/1], Step [98/245], Loss: 1.7470\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7772\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7402\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7040\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7420\n",
      "Epoch [1/1], Step [103/245], Loss: 1.8488\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7129\n",
      "Epoch [1/1], Step [105/245], Loss: 1.8260\n",
      "Epoch [1/1], Step [106/245], Loss: 1.6823\n",
      "Epoch [1/1], Step [107/245], Loss: 1.6807\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6884\n",
      "Epoch [1/1], Step [109/245], Loss: 1.7834\n",
      "Epoch [1/1], Step [110/245], Loss: 1.7732\n",
      "Epoch [1/1], Step [111/245], Loss: 1.6565\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7951\n",
      "Epoch [1/1], Step [113/245], Loss: 1.7386\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7276\n",
      "Epoch [1/1], Step [115/245], Loss: 1.7610\n",
      "Epoch [1/1], Step [116/245], Loss: 1.6995\n",
      "Epoch [1/1], Step [117/245], Loss: 1.7620\n",
      "Epoch [1/1], Step [118/245], Loss: 1.6985\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7480\n",
      "Epoch [1/1], Step [120/245], Loss: 1.6483\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7953\n",
      "Epoch [1/1], Step [122/245], Loss: 1.6996\n",
      "Epoch [1/1], Step [123/245], Loss: 1.7982\n",
      "Epoch [1/1], Step [124/245], Loss: 1.6288\n",
      "Epoch [1/1], Step [125/245], Loss: 1.7767\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7331\n",
      "Epoch [1/1], Step [127/245], Loss: 1.8097\n",
      "Epoch [1/1], Step [128/245], Loss: 1.6497\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7153\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7474\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6998\n",
      "Epoch [1/1], Step [132/245], Loss: 1.6835\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6902\n",
      "Epoch [1/1], Step [134/245], Loss: 1.6960\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6880\n",
      "Epoch [1/1], Step [136/245], Loss: 1.6694\n",
      "Epoch [1/1], Step [137/245], Loss: 1.6989\n",
      "Epoch [1/1], Step [138/245], Loss: 1.6012\n",
      "Epoch [1/1], Step [139/245], Loss: 1.6446\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6633\n",
      "Epoch [1/1], Step [141/245], Loss: 1.6710\n",
      "Epoch [1/1], Step [142/245], Loss: 1.6686\n",
      "Epoch [1/1], Step [143/245], Loss: 1.7798\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6664\n",
      "Epoch [1/1], Step [145/245], Loss: 1.7046\n",
      "Epoch [1/1], Step [146/245], Loss: 1.7361\n",
      "Epoch [1/1], Step [147/245], Loss: 1.7538\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7646\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6139\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6058\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7007\n",
      "Epoch [1/1], Step [152/245], Loss: 1.6806\n",
      "Epoch [1/1], Step [153/245], Loss: 1.7554\n",
      "Epoch [1/1], Step [154/245], Loss: 1.7318\n",
      "Epoch [1/1], Step [155/245], Loss: 1.6731\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6714\n",
      "Epoch [1/1], Step [157/245], Loss: 1.6582\n",
      "Epoch [1/1], Step [158/245], Loss: 1.6767\n",
      "Epoch [1/1], Step [159/245], Loss: 1.6769\n",
      "Epoch [1/1], Step [160/245], Loss: 1.6835\n",
      "Epoch [1/1], Step [161/245], Loss: 1.6544\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6245\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6284\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6982\n",
      "Epoch [1/1], Step [165/245], Loss: 1.7396\n",
      "Epoch [1/1], Step [166/245], Loss: 1.5493\n",
      "Epoch [1/1], Step [167/245], Loss: 1.7156\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6647\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7497\n",
      "Epoch [1/1], Step [170/245], Loss: 1.7900\n",
      "Epoch [1/1], Step [171/245], Loss: 1.7386\n",
      "Epoch [1/1], Step [172/245], Loss: 1.6477\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6818\n",
      "Epoch [1/1], Step [174/245], Loss: 1.7377\n",
      "Epoch [1/1], Step [175/245], Loss: 1.5511\n",
      "Epoch [1/1], Step [176/245], Loss: 1.7379\n",
      "Epoch [1/1], Step [177/245], Loss: 1.6503\n",
      "Epoch [1/1], Step [178/245], Loss: 1.6018\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7131\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6814\n",
      "Epoch [1/1], Step [181/245], Loss: 1.5735\n",
      "Epoch [1/1], Step [182/245], Loss: 1.6852\n",
      "Epoch [1/1], Step [183/245], Loss: 1.7762\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6603\n",
      "Epoch [1/1], Step [185/245], Loss: 1.6590\n",
      "Epoch [1/1], Step [186/245], Loss: 1.5419\n",
      "Epoch [1/1], Step [187/245], Loss: 1.6692\n",
      "Epoch [1/1], Step [188/245], Loss: 1.6318\n",
      "Epoch [1/1], Step [189/245], Loss: 1.6866\n",
      "Epoch [1/1], Step [190/245], Loss: 1.6539\n",
      "Epoch [1/1], Step [191/245], Loss: 1.5270\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6784\n",
      "Epoch [1/1], Step [193/245], Loss: 1.7897\n",
      "Epoch [1/1], Step [194/245], Loss: 1.6607\n",
      "Epoch [1/1], Step [195/245], Loss: 1.7915\n",
      "Epoch [1/1], Step [196/245], Loss: 1.7618\n",
      "Epoch [1/1], Step [197/245], Loss: 1.7052\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6937\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6033\n",
      "Epoch [1/1], Step [200/245], Loss: 1.5945\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6023\n",
      "Epoch [1/1], Step [202/245], Loss: 1.7523\n",
      "Epoch [1/1], Step [203/245], Loss: 1.5881\n",
      "Epoch [1/1], Step [204/245], Loss: 1.7341\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6192\n",
      "Epoch [1/1], Step [206/245], Loss: 1.6254\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7592\n",
      "Epoch [1/1], Step [208/245], Loss: 1.6883\n",
      "Epoch [1/1], Step [209/245], Loss: 1.5619\n",
      "Epoch [1/1], Step [210/245], Loss: 1.6909\n",
      "Epoch [1/1], Step [211/245], Loss: 1.4801\n",
      "Epoch [1/1], Step [212/245], Loss: 1.6930\n",
      "Epoch [1/1], Step [213/245], Loss: 1.6353\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6930\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6847\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7198\n",
      "Epoch [1/1], Step [217/245], Loss: 1.7362\n",
      "Epoch [1/1], Step [218/245], Loss: 1.5854\n",
      "Epoch [1/1], Step [219/245], Loss: 1.5422\n",
      "Epoch [1/1], Step [220/245], Loss: 1.7147\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6892\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5838\n",
      "Epoch [1/1], Step [223/245], Loss: 1.6485\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7207\n",
      "Epoch [1/1], Step [225/245], Loss: 1.7104\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6499\n",
      "Epoch [1/1], Step [227/245], Loss: 1.5336\n",
      "Epoch [1/1], Step [228/245], Loss: 1.5255\n",
      "Epoch [1/1], Step [229/245], Loss: 1.7436\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6908\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6888\n",
      "Epoch [1/1], Step [232/245], Loss: 1.6272\n",
      "Epoch [1/1], Step [233/245], Loss: 1.6514\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6755\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6035\n",
      "Epoch [1/1], Step [236/245], Loss: 1.6294\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5221\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6009\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6156\n",
      "Epoch [1/1], Step [240/245], Loss: 1.5985\n",
      "Epoch [1/1], Step [241/245], Loss: 1.5274\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5266\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6920\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6646\n",
      "Epoch [1/1], Step [245/245], Loss: 1.5610\n",
      "Train accuracy is: 36.43061224489796 %\n",
      "Validation accuracy is: 44.2 %\n"
     ]
    }
   ],
   "source": [
    "model1_name = 'bcfl_model1'\n",
    "\n",
    "# Training\n",
    "model1.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model1.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model1, modelpath, model1_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train second local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3002\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2940\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2777\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2647\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2574\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2379\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2019\n",
      "Epoch [1/1], Step [9/245], Loss: 2.1465\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1681\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1650\n",
      "Epoch [1/1], Step [12/245], Loss: 2.0986\n",
      "Epoch [1/1], Step [13/245], Loss: 2.0828\n",
      "Epoch [1/1], Step [14/245], Loss: 2.0830\n",
      "Epoch [1/1], Step [15/245], Loss: 2.1340\n",
      "Epoch [1/1], Step [16/245], Loss: 2.1054\n",
      "Epoch [1/1], Step [17/245], Loss: 2.0922\n",
      "Epoch [1/1], Step [18/245], Loss: 2.0420\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0794\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0314\n",
      "Epoch [1/1], Step [21/245], Loss: 2.0477\n",
      "Epoch [1/1], Step [22/245], Loss: 1.9625\n",
      "Epoch [1/1], Step [23/245], Loss: 1.9378\n",
      "Epoch [1/1], Step [24/245], Loss: 2.0280\n",
      "Epoch [1/1], Step [25/245], Loss: 2.0042\n",
      "Epoch [1/1], Step [26/245], Loss: 2.0679\n",
      "Epoch [1/1], Step [27/245], Loss: 1.8851\n",
      "Epoch [1/1], Step [28/245], Loss: 2.0873\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9917\n",
      "Epoch [1/1], Step [30/245], Loss: 2.0009\n",
      "Epoch [1/1], Step [31/245], Loss: 1.9638\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9194\n",
      "Epoch [1/1], Step [33/245], Loss: 1.8620\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9967\n",
      "Epoch [1/1], Step [35/245], Loss: 1.9133\n",
      "Epoch [1/1], Step [36/245], Loss: 1.8722\n",
      "Epoch [1/1], Step [37/245], Loss: 1.7799\n",
      "Epoch [1/1], Step [38/245], Loss: 1.9828\n",
      "Epoch [1/1], Step [39/245], Loss: 1.9571\n",
      "Epoch [1/1], Step [40/245], Loss: 1.8276\n",
      "Epoch [1/1], Step [41/245], Loss: 1.9111\n",
      "Epoch [1/1], Step [42/245], Loss: 1.9350\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9120\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8044\n",
      "Epoch [1/1], Step [45/245], Loss: 1.8886\n",
      "Epoch [1/1], Step [46/245], Loss: 1.9828\n",
      "Epoch [1/1], Step [47/245], Loss: 1.9025\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8498\n",
      "Epoch [1/1], Step [49/245], Loss: 1.8958\n",
      "Epoch [1/1], Step [50/245], Loss: 1.8947\n",
      "Epoch [1/1], Step [51/245], Loss: 1.7954\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8481\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8043\n",
      "Epoch [1/1], Step [54/245], Loss: 1.8739\n",
      "Epoch [1/1], Step [55/245], Loss: 1.8514\n",
      "Epoch [1/1], Step [56/245], Loss: 1.8430\n",
      "Epoch [1/1], Step [57/245], Loss: 1.8306\n",
      "Epoch [1/1], Step [58/245], Loss: 1.9096\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8357\n",
      "Epoch [1/1], Step [60/245], Loss: 1.9205\n",
      "Epoch [1/1], Step [61/245], Loss: 1.9315\n",
      "Epoch [1/1], Step [62/245], Loss: 1.7459\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7042\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8221\n",
      "Epoch [1/1], Step [65/245], Loss: 1.7567\n",
      "Epoch [1/1], Step [66/245], Loss: 1.8822\n",
      "Epoch [1/1], Step [67/245], Loss: 1.7379\n",
      "Epoch [1/1], Step [68/245], Loss: 1.7894\n",
      "Epoch [1/1], Step [69/245], Loss: 1.8352\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8164\n",
      "Epoch [1/1], Step [71/245], Loss: 1.8502\n",
      "Epoch [1/1], Step [72/245], Loss: 1.7928\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8684\n",
      "Epoch [1/1], Step [74/245], Loss: 1.8138\n",
      "Epoch [1/1], Step [75/245], Loss: 1.6514\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7570\n",
      "Epoch [1/1], Step [77/245], Loss: 1.6961\n",
      "Epoch [1/1], Step [78/245], Loss: 1.8772\n",
      "Epoch [1/1], Step [79/245], Loss: 1.7884\n",
      "Epoch [1/1], Step [80/245], Loss: 1.7546\n",
      "Epoch [1/1], Step [81/245], Loss: 1.7776\n",
      "Epoch [1/1], Step [82/245], Loss: 1.6934\n",
      "Epoch [1/1], Step [83/245], Loss: 1.6990\n",
      "Epoch [1/1], Step [84/245], Loss: 1.8010\n",
      "Epoch [1/1], Step [85/245], Loss: 1.7620\n",
      "Epoch [1/1], Step [86/245], Loss: 1.7491\n",
      "Epoch [1/1], Step [87/245], Loss: 1.8070\n",
      "Epoch [1/1], Step [88/245], Loss: 1.7515\n",
      "Epoch [1/1], Step [89/245], Loss: 1.8010\n",
      "Epoch [1/1], Step [90/245], Loss: 1.6982\n",
      "Epoch [1/1], Step [91/245], Loss: 1.8549\n",
      "Epoch [1/1], Step [92/245], Loss: 1.8088\n",
      "Epoch [1/1], Step [93/245], Loss: 1.7815\n",
      "Epoch [1/1], Step [94/245], Loss: 1.8256\n",
      "Epoch [1/1], Step [95/245], Loss: 1.8186\n",
      "Epoch [1/1], Step [96/245], Loss: 1.7577\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7711\n",
      "Epoch [1/1], Step [98/245], Loss: 1.7123\n",
      "Epoch [1/1], Step [99/245], Loss: 1.9510\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7601\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7582\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7237\n",
      "Epoch [1/1], Step [103/245], Loss: 1.8390\n",
      "Epoch [1/1], Step [104/245], Loss: 1.6822\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7490\n",
      "Epoch [1/1], Step [106/245], Loss: 1.7985\n",
      "Epoch [1/1], Step [107/245], Loss: 1.7867\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6708\n",
      "Epoch [1/1], Step [109/245], Loss: 1.7656\n",
      "Epoch [1/1], Step [110/245], Loss: 1.7922\n",
      "Epoch [1/1], Step [111/245], Loss: 1.7512\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7474\n",
      "Epoch [1/1], Step [113/245], Loss: 1.7516\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7438\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6632\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8228\n",
      "Epoch [1/1], Step [117/245], Loss: 1.7013\n",
      "Epoch [1/1], Step [118/245], Loss: 1.7544\n",
      "Epoch [1/1], Step [119/245], Loss: 1.8596\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7252\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7684\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7687\n",
      "Epoch [1/1], Step [123/245], Loss: 1.8649\n",
      "Epoch [1/1], Step [124/245], Loss: 1.7550\n",
      "Epoch [1/1], Step [125/245], Loss: 1.7179\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7775\n",
      "Epoch [1/1], Step [127/245], Loss: 1.6713\n",
      "Epoch [1/1], Step [128/245], Loss: 1.6712\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7925\n",
      "Epoch [1/1], Step [130/245], Loss: 1.8480\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6284\n",
      "Epoch [1/1], Step [132/245], Loss: 1.7525\n",
      "Epoch [1/1], Step [133/245], Loss: 1.7019\n",
      "Epoch [1/1], Step [134/245], Loss: 1.7507\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6976\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7505\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7342\n",
      "Epoch [1/1], Step [138/245], Loss: 1.7366\n",
      "Epoch [1/1], Step [139/245], Loss: 1.7334\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6944\n",
      "Epoch [1/1], Step [141/245], Loss: 1.7571\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7376\n",
      "Epoch [1/1], Step [143/245], Loss: 1.7146\n",
      "Epoch [1/1], Step [144/245], Loss: 1.7080\n",
      "Epoch [1/1], Step [145/245], Loss: 1.6234\n",
      "Epoch [1/1], Step [146/245], Loss: 1.7417\n",
      "Epoch [1/1], Step [147/245], Loss: 1.7083\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7125\n",
      "Epoch [1/1], Step [149/245], Loss: 1.7074\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6131\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7642\n",
      "Epoch [1/1], Step [152/245], Loss: 1.6820\n",
      "Epoch [1/1], Step [153/245], Loss: 1.8189\n",
      "Epoch [1/1], Step [154/245], Loss: 1.6814\n",
      "Epoch [1/1], Step [155/245], Loss: 1.6031\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6591\n",
      "Epoch [1/1], Step [157/245], Loss: 1.6157\n",
      "Epoch [1/1], Step [158/245], Loss: 1.7562\n",
      "Epoch [1/1], Step [159/245], Loss: 1.6722\n",
      "Epoch [1/1], Step [160/245], Loss: 1.7096\n",
      "Epoch [1/1], Step [161/245], Loss: 1.7544\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6357\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6094\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6286\n",
      "Epoch [1/1], Step [165/245], Loss: 1.7042\n",
      "Epoch [1/1], Step [166/245], Loss: 1.7457\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6794\n",
      "Epoch [1/1], Step [168/245], Loss: 1.5918\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7295\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6095\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6183\n",
      "Epoch [1/1], Step [172/245], Loss: 1.7228\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6196\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6763\n",
      "Epoch [1/1], Step [175/245], Loss: 1.6908\n",
      "Epoch [1/1], Step [176/245], Loss: 1.7649\n",
      "Epoch [1/1], Step [177/245], Loss: 1.7483\n",
      "Epoch [1/1], Step [178/245], Loss: 1.6875\n",
      "Epoch [1/1], Step [179/245], Loss: 1.6076\n",
      "Epoch [1/1], Step [180/245], Loss: 1.5962\n",
      "Epoch [1/1], Step [181/245], Loss: 1.8427\n",
      "Epoch [1/1], Step [182/245], Loss: 1.7002\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6368\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6655\n",
      "Epoch [1/1], Step [185/245], Loss: 1.5768\n",
      "Epoch [1/1], Step [186/245], Loss: 1.7149\n",
      "Epoch [1/1], Step [187/245], Loss: 1.7828\n",
      "Epoch [1/1], Step [188/245], Loss: 1.5714\n",
      "Epoch [1/1], Step [189/245], Loss: 1.6859\n",
      "Epoch [1/1], Step [190/245], Loss: 1.6600\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6281\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6434\n",
      "Epoch [1/1], Step [193/245], Loss: 1.6524\n",
      "Epoch [1/1], Step [194/245], Loss: 1.5293\n",
      "Epoch [1/1], Step [195/245], Loss: 1.7509\n",
      "Epoch [1/1], Step [196/245], Loss: 1.7000\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6119\n",
      "Epoch [1/1], Step [198/245], Loss: 1.5799\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6536\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6902\n",
      "Epoch [1/1], Step [201/245], Loss: 1.7825\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6411\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6803\n",
      "Epoch [1/1], Step [204/245], Loss: 1.7293\n",
      "Epoch [1/1], Step [205/245], Loss: 1.7643\n",
      "Epoch [1/1], Step [206/245], Loss: 1.8079\n",
      "Epoch [1/1], Step [207/245], Loss: 1.6356\n",
      "Epoch [1/1], Step [208/245], Loss: 1.7154\n",
      "Epoch [1/1], Step [209/245], Loss: 1.7559\n",
      "Epoch [1/1], Step [210/245], Loss: 1.6748\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6371\n",
      "Epoch [1/1], Step [212/245], Loss: 1.6464\n",
      "Epoch [1/1], Step [213/245], Loss: 1.8370\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6534\n",
      "Epoch [1/1], Step [215/245], Loss: 1.7445\n",
      "Epoch [1/1], Step [216/245], Loss: 1.5909\n",
      "Epoch [1/1], Step [217/245], Loss: 1.6314\n",
      "Epoch [1/1], Step [218/245], Loss: 1.5386\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6420\n",
      "Epoch [1/1], Step [220/245], Loss: 1.7063\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6522\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5869\n",
      "Epoch [1/1], Step [223/245], Loss: 1.5202\n",
      "Epoch [1/1], Step [224/245], Loss: 1.5547\n",
      "Epoch [1/1], Step [225/245], Loss: 1.4076\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6047\n",
      "Epoch [1/1], Step [227/245], Loss: 1.5846\n",
      "Epoch [1/1], Step [228/245], Loss: 1.6757\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6522\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6933\n",
      "Epoch [1/1], Step [231/245], Loss: 1.5809\n",
      "Epoch [1/1], Step [232/245], Loss: 1.5716\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5993\n",
      "Epoch [1/1], Step [234/245], Loss: 1.5937\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6317\n",
      "Epoch [1/1], Step [236/245], Loss: 1.5834\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5628\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6500\n",
      "Epoch [1/1], Step [239/245], Loss: 1.5263\n",
      "Epoch [1/1], Step [240/245], Loss: 1.6897\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6388\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5456\n",
      "Epoch [1/1], Step [243/245], Loss: 1.8741\n",
      "Epoch [1/1], Step [244/245], Loss: 1.5984\n",
      "Epoch [1/1], Step [245/245], Loss: 1.5818\n",
      "Train accuracy is: 36.23877551020408 %\n",
      "Validation accuracy is: 45.1 %\n"
     ]
    }
   ],
   "source": [
    "model2_name = 'bcfl_model2'\n",
    "# Training\n",
    "model2.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model2.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model2, modelpath, model2_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 41.8 %\n",
      "Accuracy of the network on the 1000 test images: 42.5 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "model_ckpt = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model_ckpt = torch.load(pjoin(modelpath, model1_name + '.ckpt'))\n",
    "model1.load_state_dict(model_ckpt)\n",
    "model = model1\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))\n",
    "    \n",
    "    \n",
    "\n",
    "model = model2\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Forward the two local models to the blockchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model submitted succesfully'}\n",
      "{'message': 'Model submitted succesfully'}\n"
     ]
    }
   ],
   "source": [
    "# Send the saved model to Fabric-SDK via Gateway Client (REST call)\n",
    "\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "\n",
    "\n",
    "print(submit_local_model(model1_name, model1.state_dict()))\n",
    "\n",
    "print(submit_local_model(model2_name, model2.state_dict()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Aggregate the local models on the blockchain\n",
    "TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this should be triggered automatically when the total users in the blockchain have triggered their updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download the new global model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json\n",
    "\n",
    "# retrieve future global model and convert it again to pytorch model\n",
    "\n",
    "# TODO change\n",
    "model_avg_name = model1_name\n",
    "\n",
    "model_params = get_model(model_avg_name)\n",
    "\n",
    "global_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "global_model.to(device)\n",
    "print(global_model)\n",
    "\n",
    "load_model_from_json(global_model, model_params)\n",
    "print(model)\n",
    "   \n",
    "print(model1.state_dict()['layers.0.bias'])\n",
    "print(global_model.state_dict()['layers.0.bias'])\n",
    "# the global model should be the same as model 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new global model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
