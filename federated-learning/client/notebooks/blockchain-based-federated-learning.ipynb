{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of one round of blockchain-based federated learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCuda available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get the name of the CUDA device\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmajor and minor cuda capability of the device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_capability()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:419\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:449\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config variables for models and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_file_path' from 'client.utils' (/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mperceptron\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiLayerPerceptron\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservices\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgateway_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m submit_model, get_all_models, get_model\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model_from_json,  weights_init, update_lr\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maggregators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m federated_aggregate\n",
      "File \u001b[0;32m~/_bcfl/fabric-federated-learning/federated-learning/client/services/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgateway_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/_bcfl/fabric-federated-learning/federated-learning/client/services/gateway_client.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m join \u001b[38;5;28;01mas\u001b[39;00m pjoin\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_file_path, serialize_model_json, serialize_model_msgpack\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Base URL of the NestJS server\u001b[39;00m\n\u001b[1;32m      7\u001b[0m BASE_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:3000/gateway\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust port if needed\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_file_path' from 'client.utils' (/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/utils.py)"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.train import train\n",
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json,  weights_init, update_lr\n",
    "from client.aggregators import federated_aggregate\n",
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two local models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "\n",
    "model1 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model1.to(device)\n",
    "print(model1)\n",
    "model1_name = 'bcfl_model1'\n",
    "\n",
    "model2 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "model2_name = 'bcfl_model2'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train first local model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3011\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2946\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2808\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2647\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2555\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2303\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2195\n",
      "Epoch [1/1], Step [9/245], Loss: 2.2171\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1714\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1580\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1134\n",
      "Epoch [1/1], Step [13/245], Loss: 2.0887\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1647\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0902\n",
      "Epoch [1/1], Step [16/245], Loss: 2.1081\n",
      "Epoch [1/1], Step [17/245], Loss: 1.9998\n",
      "Epoch [1/1], Step [18/245], Loss: 1.9906\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0200\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0716\n",
      "Epoch [1/1], Step [21/245], Loss: 1.9121\n",
      "Epoch [1/1], Step [22/245], Loss: 1.9942\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0938\n",
      "Epoch [1/1], Step [24/245], Loss: 1.8950\n",
      "Epoch [1/1], Step [25/245], Loss: 1.9199\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9666\n",
      "Epoch [1/1], Step [27/245], Loss: 1.9981\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9457\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9062\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9506\n",
      "Epoch [1/1], Step [31/245], Loss: 1.8596\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9322\n",
      "Epoch [1/1], Step [33/245], Loss: 1.8839\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9427\n",
      "Epoch [1/1], Step [35/245], Loss: 1.7980\n",
      "Epoch [1/1], Step [36/245], Loss: 2.0129\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9361\n",
      "Epoch [1/1], Step [38/245], Loss: 1.7984\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8914\n",
      "Epoch [1/1], Step [40/245], Loss: 1.9120\n",
      "Epoch [1/1], Step [41/245], Loss: 1.8122\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8714\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9302\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8855\n",
      "Epoch [1/1], Step [45/245], Loss: 1.9332\n",
      "Epoch [1/1], Step [46/245], Loss: 1.8836\n",
      "Epoch [1/1], Step [47/245], Loss: 1.9147\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8419\n",
      "Epoch [1/1], Step [49/245], Loss: 1.9262\n",
      "Epoch [1/1], Step [50/245], Loss: 1.9036\n",
      "Epoch [1/1], Step [51/245], Loss: 1.8924\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8379\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8412\n",
      "Epoch [1/1], Step [54/245], Loss: 1.9727\n",
      "Epoch [1/1], Step [55/245], Loss: 1.9214\n",
      "Epoch [1/1], Step [56/245], Loss: 1.7963\n",
      "Epoch [1/1], Step [57/245], Loss: 1.8779\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8603\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8511\n",
      "Epoch [1/1], Step [60/245], Loss: 1.8113\n",
      "Epoch [1/1], Step [61/245], Loss: 1.8982\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8888\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7673\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8763\n",
      "Epoch [1/1], Step [65/245], Loss: 1.7802\n",
      "Epoch [1/1], Step [66/245], Loss: 1.7704\n",
      "Epoch [1/1], Step [67/245], Loss: 1.7857\n",
      "Epoch [1/1], Step [68/245], Loss: 1.9336\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7673\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8219\n",
      "Epoch [1/1], Step [71/245], Loss: 1.7899\n",
      "Epoch [1/1], Step [72/245], Loss: 1.8216\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8010\n",
      "Epoch [1/1], Step [74/245], Loss: 1.6592\n",
      "Epoch [1/1], Step [75/245], Loss: 1.7626\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7580\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8317\n",
      "Epoch [1/1], Step [78/245], Loss: 1.7938\n",
      "Epoch [1/1], Step [79/245], Loss: 1.8490\n",
      "Epoch [1/1], Step [80/245], Loss: 1.6906\n",
      "Epoch [1/1], Step [81/245], Loss: 1.7044\n",
      "Epoch [1/1], Step [82/245], Loss: 1.7760\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7119\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7508\n",
      "Epoch [1/1], Step [85/245], Loss: 1.8057\n",
      "Epoch [1/1], Step [86/245], Loss: 1.7991\n",
      "Epoch [1/1], Step [87/245], Loss: 1.8606\n",
      "Epoch [1/1], Step [88/245], Loss: 1.8354\n",
      "Epoch [1/1], Step [89/245], Loss: 1.7586\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7629\n",
      "Epoch [1/1], Step [91/245], Loss: 1.6584\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7221\n",
      "Epoch [1/1], Step [93/245], Loss: 1.6189\n",
      "Epoch [1/1], Step [94/245], Loss: 1.7850\n",
      "Epoch [1/1], Step [95/245], Loss: 1.8464\n",
      "Epoch [1/1], Step [96/245], Loss: 1.7949\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7131\n",
      "Epoch [1/1], Step [98/245], Loss: 1.8195\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7796\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7417\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7980\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7503\n",
      "Epoch [1/1], Step [103/245], Loss: 1.7170\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7776\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7181\n",
      "Epoch [1/1], Step [106/245], Loss: 1.7184\n",
      "Epoch [1/1], Step [107/245], Loss: 1.7681\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6804\n",
      "Epoch [1/1], Step [109/245], Loss: 1.6817\n",
      "Epoch [1/1], Step [110/245], Loss: 1.6851\n",
      "Epoch [1/1], Step [111/245], Loss: 1.8385\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7510\n",
      "Epoch [1/1], Step [113/245], Loss: 1.6187\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7430\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6759\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8023\n",
      "Epoch [1/1], Step [117/245], Loss: 1.6975\n",
      "Epoch [1/1], Step [118/245], Loss: 1.8035\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7474\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7691\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7329\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7194\n",
      "Epoch [1/1], Step [123/245], Loss: 1.6862\n",
      "Epoch [1/1], Step [124/245], Loss: 1.6901\n",
      "Epoch [1/1], Step [125/245], Loss: 1.6500\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7394\n",
      "Epoch [1/1], Step [127/245], Loss: 1.6189\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7119\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7769\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7788\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6808\n",
      "Epoch [1/1], Step [132/245], Loss: 1.8057\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6660\n",
      "Epoch [1/1], Step [134/245], Loss: 1.8247\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6267\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7105\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7804\n",
      "Epoch [1/1], Step [138/245], Loss: 1.5440\n",
      "Epoch [1/1], Step [139/245], Loss: 1.6957\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6264\n",
      "Epoch [1/1], Step [141/245], Loss: 1.6500\n",
      "Epoch [1/1], Step [142/245], Loss: 1.6996\n",
      "Epoch [1/1], Step [143/245], Loss: 1.6518\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6480\n",
      "Epoch [1/1], Step [145/245], Loss: 1.7467\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6326\n",
      "Epoch [1/1], Step [147/245], Loss: 1.6924\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7258\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6743\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6237\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7640\n",
      "Epoch [1/1], Step [152/245], Loss: 1.7164\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6932\n",
      "Epoch [1/1], Step [154/245], Loss: 1.5997\n",
      "Epoch [1/1], Step [155/245], Loss: 1.5274\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6805\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7284\n",
      "Epoch [1/1], Step [158/245], Loss: 1.7080\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7793\n",
      "Epoch [1/1], Step [160/245], Loss: 1.8509\n",
      "Epoch [1/1], Step [161/245], Loss: 1.5259\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6146\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6040\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6241\n",
      "Epoch [1/1], Step [165/245], Loss: 1.8419\n",
      "Epoch [1/1], Step [166/245], Loss: 1.7545\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6575\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6854\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7243\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6508\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6757\n",
      "Epoch [1/1], Step [172/245], Loss: 1.7235\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6745\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6274\n",
      "Epoch [1/1], Step [175/245], Loss: 1.7269\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6485\n",
      "Epoch [1/1], Step [177/245], Loss: 1.6865\n",
      "Epoch [1/1], Step [178/245], Loss: 1.7015\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7065\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6765\n",
      "Epoch [1/1], Step [181/245], Loss: 1.5908\n",
      "Epoch [1/1], Step [182/245], Loss: 1.7183\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6652\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6368\n",
      "Epoch [1/1], Step [185/245], Loss: 1.5792\n",
      "Epoch [1/1], Step [186/245], Loss: 1.5869\n",
      "Epoch [1/1], Step [187/245], Loss: 1.7262\n",
      "Epoch [1/1], Step [188/245], Loss: 1.7164\n",
      "Epoch [1/1], Step [189/245], Loss: 1.5252\n",
      "Epoch [1/1], Step [190/245], Loss: 1.5870\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6398\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6537\n",
      "Epoch [1/1], Step [193/245], Loss: 1.6757\n",
      "Epoch [1/1], Step [194/245], Loss: 1.5606\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6196\n",
      "Epoch [1/1], Step [196/245], Loss: 1.5829\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6310\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6663\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6097\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6798\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6025\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6614\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6933\n",
      "Epoch [1/1], Step [204/245], Loss: 1.6653\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6342\n",
      "Epoch [1/1], Step [206/245], Loss: 1.7325\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7199\n",
      "Epoch [1/1], Step [208/245], Loss: 1.5724\n",
      "Epoch [1/1], Step [209/245], Loss: 1.8516\n",
      "Epoch [1/1], Step [210/245], Loss: 1.7012\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6391\n",
      "Epoch [1/1], Step [212/245], Loss: 1.6800\n",
      "Epoch [1/1], Step [213/245], Loss: 1.7150\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6790\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6065\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7222\n",
      "Epoch [1/1], Step [217/245], Loss: 1.5669\n",
      "Epoch [1/1], Step [218/245], Loss: 1.8494\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6028\n",
      "Epoch [1/1], Step [220/245], Loss: 1.5970\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6788\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5805\n",
      "Epoch [1/1], Step [223/245], Loss: 1.4679\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7814\n",
      "Epoch [1/1], Step [225/245], Loss: 1.6269\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6181\n",
      "Epoch [1/1], Step [227/245], Loss: 1.6239\n",
      "Epoch [1/1], Step [228/245], Loss: 1.7547\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6940\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6672\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6737\n",
      "Epoch [1/1], Step [232/245], Loss: 1.5525\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5265\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6486\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6876\n",
      "Epoch [1/1], Step [236/245], Loss: 1.5303\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5122\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6195\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6079\n",
      "Epoch [1/1], Step [240/245], Loss: 1.5872\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6833\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5718\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6573\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6394\n",
      "Epoch [1/1], Step [245/245], Loss: 1.6573\n",
      "Train accuracy is: 36.940816326530616 %\n",
      "Validation accuracy is: 43.8 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model1_name = 'bcfl_model1'\n",
    "# Training\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model1.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "# optimizer.to(device)\n",
    "\n",
    "train(model1, modelpath, model1_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train second local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m      7\u001b[0m     model2\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate, weight_decay\u001b[38;5;241m=\u001b[39mreg)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_bcfl/fabric-federated-learning/federated-learning/client/train.py:45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, modelpath, modelname, dataloaders, criterion, optimizer, learning_rate, learning_rate_decay, input_size, num_epochs, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[1;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 45\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# track train accuracy\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/optim/adam.py:138\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Performs a single optimization step.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/optim/optimizer.py:321\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 321\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    325\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    326\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/graphs.py:32\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model2_name = 'bcfl_model4'\n",
    "# Training\n",
    "model2.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model2.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model2, modelpath, model2_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 42.5 %\n",
      "Accuracy of the network on the 1000 test images: 10.5 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "model_ckpt = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model_ckpt = torch.load(pjoin(modelpath, model1_name + '.ckpt'))\n",
    "model1.load_state_dict(model_ckpt)\n",
    "model = model1\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))\n",
    "    \n",
    "    \n",
    "\n",
    "model = model2\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Forward the two local models to the blockchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model submitted succesfully'}\n"
     ]
    }
   ],
   "source": [
    "# Send the saved model to Fabric-SDK via Gateway Client (REST call)\n",
    "\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "\n",
    "\n",
    "print(submit_model(model1_name, model1.state_dict()))\n",
    "\n",
    "# print(submit_model(model2_name, model2.state_dict()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit empty model to the blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model submitted succesfully'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n",
    "\n",
    "model3 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model3.to(device)\n",
    "model3.zero_init()\n",
    "model3_name = 'bcfl_model_empty'\n",
    "# print(model3)\n",
    "submit_model(model3_name, model3.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Aggregate the local models on the blockchain\n",
    "TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Models aggregated succesfully'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n",
    "\n",
    "from client.services.gateway_client import aggregate_models\n",
    "\n",
    "\n",
    "\n",
    "aggregate_models([model1_name, model3_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download the new global model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, deserialize_model_msgpack\n",
    "\n",
    "# retrieve future global model and convert it again to pytorch model\n",
    "\n",
    "# TODO change\n",
    "model_avg_name = model1_name + 'and' + model3_name\n",
    "model_data = get_model(model_avg_name)\n",
    "decoded_state_dict = deserialize_model_msgpack(model_data['modelParams'])\n",
    "\n",
    "global_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "global_model.to(device)\n",
    "global_model.load_state_dict(decoded_state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the new global model and compare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0142, -0.0449,  0.0383,  0.0089,  0.0415,  0.0235, -0.0104, -0.0061,\n",
      "         0.0021, -0.0400], device='cuda:0')\n",
      "tensor([-0.0071, -0.0225,  0.0192,  0.0044,  0.0207,  0.0117, -0.0052, -0.0030,\n",
      "         0.0011, -0.0200], device='cuda:0')\n",
      "154160\n",
      "154160\n"
     ]
    }
   ],
   "source": [
    "from client.utils import count_parameters, compare_models\n",
    "\n",
    "\n",
    "# print(global_model)\n",
    "   \n",
    "print(model1.state_dict()['layers.2.bias'])\n",
    "print(global_model.state_dict()['layers.2.bias'])\n",
    "# the averaged model should be half the model1\n",
    "\n",
    "\n",
    "print(count_parameters(model1))\n",
    "print(count_parameters(global_model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 42.3 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from client.test import test_cifar\n",
    "\n",
    "\n",
    "model = global_model\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "test_cifar(model, input_size, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve global model and convert it again to pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, count_parameters, compare_models\n",
    "\n",
    "\n",
    "local_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "local_model = torch.load(pjoin(modelpath,  'ml_model2.ckpt'))\n",
    "model.load_state_dict(local_model)\n",
    "\n",
    "model_params = get_model('ml_model2')\n",
    "# print(client_response)\n",
    "\n",
    "\n",
    "bc_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "bc_model.to(device)\n",
    "# print(bc_model)\n",
    "\n",
    "load_model_from_json(bc_model, model_params)\n",
    "print(bc_model)\n",
    "print(count_parameters(model))\n",
    "print(count_parameters(bc_model))\n",
    "print(compare_models(model, bc_model))\n",
    "# for parameter in model.parameters():\n",
    "#     print(parameter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bert Tiny model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "from transformers import AutoModel # For BERTs\n",
    "from transformers import AutoModelForSequenceClassification # For models fine-tuned on MNLI\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "print(bert_model)\n",
    "bert_modelname = 'bert_model'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "bert_model2 = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "bert_modelname2 = 'bert_model2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model in a local file, load it again and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'count_parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m loaded_bert_model_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(pjoin(modelpath, bert_modelname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     13\u001b[0m loaded_bert_model\u001b[38;5;241m.\u001b[39mload_state_dict(loaded_bert_model_params)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcount_parameters\u001b[49m(bert_model))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(count_parameters(loaded_bert_model))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(compare_models(bert_model, loaded_bert_model))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count_parameters' is not defined"
     ]
    }
   ],
   "source": [
    "# Send the saved model to Fabric-SDK via Gateway Client (REST call)\n",
    "\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(bert_model.state_dict(), pjoin(modelpath, bert_modelname + '.pt'))\n",
    "    \n",
    "loaded_bert_model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "\n",
    "loaded_bert_model_params = torch.load(pjoin(modelpath, bert_modelname + '.pt'))\n",
    "loaded_bert_model.load_state_dict(loaded_bert_model_params)\n",
    "\n",
    "print(count_parameters(bert_model))\n",
    "print(count_parameters(loaded_bert_model))\n",
    "print(compare_models(bert_model, loaded_bert_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize and encode model, decode and try if its equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "from client.services.gateway_client import submit_model\n",
    "from client.services.utils import serialize_model_numpy, deserialize_model_numpy, print_layer_size, serialize_model_msgpack, deserialize_model_msgpack\n",
    "from client.utils import compare_models, compare_state_dicts, compare_weights\n",
    "from client.model.bert_tiny import get_bert_tiny_model\n",
    "from client.model.bert_mini import get_bert_mini_model\n",
    "from client.model.bert_small import get_bert_small_model\n",
    "from client.model.bert_medium import get_bert_medium_model\n",
    "from client.model.distilbert_base import get_distilbert_base_model\n",
    "\n",
    "# encoded = serialize_model_msgpack(bert_model.state_dict(), 0, 0)\n",
    "# # encoded = serialize_model_numpy(bert_model.state_dict())\n",
    "\n",
    "# print(sys.getsizeof(encoded) / 1024 / 1024)\n",
    "# print(type(encoded))\n",
    "# decoded_state_dict = deserialize_model_msgpack(encoded)\n",
    "# # decoded_state_dict = deserialize_model_numpy(encoded)\n",
    "\n",
    "\n",
    "\n",
    "# bert2_model = get_bert_tiny_model('cpu')\n",
    "# bert2_model.load_state_dict(decoded_state_dict)\n",
    "\n",
    "\n",
    "# print(compare_state_dicts(bert_model.state_dict(), bert2_model.state_dict()))\n",
    "# print(compare_models(bert_model, bert2_model))\n",
    "# print(compare_weights(bert_model, bert2_model))\n",
    "\n",
    "# bert_tiny_model = get_bert_tiny_model('cpu')\n",
    "# encoded_tiny = serialize_model_msgpack(bert_tiny_model.state_dict(), 0, 0)\n",
    "# print(sys.getsizeof(encoded_tiny) / 1024 / 1024)\n",
    "\n",
    "# bert_mini_model = get_bert_mini_model('cpu')\n",
    "# encoded_mini = serialize_model_msgpack(bert_mini_model.state_dict(), 0, 0)\n",
    "# print(sys.getsizeof(encoded_mini) / 1024 / 1024)\n",
    "\n",
    "# bert_small_model = get_bert_small_model('cpu')\n",
    "# encoded_small = serialize_model_msgpack(bert_small_model.state_dict(), 0, 0)\n",
    "# print(sys.getsizeof(encoded_small) / 1024 / 1024)\n",
    "\n",
    "\n",
    "# bert_medium_model = get_bert_medium_model('cpu')\n",
    "# encoded_medium = serialize_model_msgpack(bert_medium_model.state_dict(), 0, 0)\n",
    "# print(sys.getsizeof(encoded_medium) / 1024 / 1024)\n",
    "\n",
    "\n",
    "distilbert_base_model = get_distilbert_base_model('cpu')\n",
    "encoded_distilbert_base = serialize_model_msgpack(distilbert_base_model.state_dict(), 0, 0)\n",
    "print(sys.getsizeof(encoded_distilbert_base) / 1024 / 1024)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Bert Tiny model to the blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model submitted succesfully'}\n",
      "{'message': 'Model submitted succesfully'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "from client.services.gateway_client import submit_model\n",
    "from client.utils import print_layer_size, serialize_model_msgpack, deserialize_model_msgpack, compare_models, compare_state_dicts, compare_weights\n",
    "\n",
    "# Send the saved model to Fabric-SDK via Gateway Client (REST call)\n",
    "# print(submit_model(bert_modelname, bert_model.state_dict()))\n",
    "print(submit_model(bert_modelname, bert_model.state_dict(), 0, 0))\n",
    "print(submit_model(bert_modelname2, bert_model2.state_dict(), 0, 0))\n",
    "\n",
    "# print_layer_size(bert_model.state_dict(), 0, 6, 'mb', 'base64')\n",
    "# print(submit_compressed_model(bert_modelname, bert_model.state_dict()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model and load it again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "4386178\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bc_bert_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 27\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# load_model_from_json(bc_bert_model, bert_model_params)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# compare it with previous bert model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(count_parameters(bert_model))\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mprint\u001b[39m(count_parameters(\u001b[43mbc_bert_model\u001b[49m))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(compare_models(bert_model, bc_bert_model))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bc_bert_model' is not defined"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, count_parameters, compare_models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "blockchain_bert_model = get_model(bert_modelname)\n",
    "\n",
    "decoded_state_dict = deserialize_model_msgpack(blockchain_bert_model['modelParams'])\n",
    "\n",
    "\n",
    "bert2_model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "\n",
    "bert2_model.load_state_dict(decoded_state_dict)\n",
    "\n",
    "print(compare_state_dicts(bert_model.state_dict(), bert2_model.state_dict()))\n",
    "print(compare_models(bert_model, bert2_model))\n",
    "print(compare_weights(bert_model, bert2_model))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the bert models on the blockchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Models aggregated succesfully'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n",
    "\n",
    "from client.services.gateway_client import aggregate_models\n",
    "\n",
    "\n",
    "\n",
    "aggregate_models([bert_modelname, bert_modelname2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the new global BERT model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, deserialize_model_msgpack\n",
    "\n",
    "# retrieve future global model and convert it again to pytorch model\n",
    "\n",
    "bert_global_model_name = bert_modelname + 'and' + bert_modelname2\n",
    "bert_global_data = get_model(bert_global_model_name)\n",
    "decoded_state_dict = deserialize_model_msgpack(bert_global_data['modelParams'])\n",
    "\n",
    "\n",
    "bert_global_model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\") # v1 and v2\n",
    "bert_global_model.load_state_dict(decoded_state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the new global model and compare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0176, -0.0025,  0.0031,  0.0403,  0.0071, -0.0137,  0.0155,  0.0092,\n",
      "         -0.0148,  0.0160, -0.0336,  0.0085, -0.0220, -0.0046,  0.0186, -0.0057,\n",
      "          0.0012,  0.0070, -0.0008, -0.0072, -0.0223,  0.0316,  0.0265,  0.0123,\n",
      "         -0.0250,  0.0260,  0.0037, -0.0412,  0.0500,  0.0091, -0.0261, -0.0048,\n",
      "         -0.0104,  0.0037,  0.0301, -0.0183,  0.0080, -0.0004, -0.0162,  0.0089,\n",
      "         -0.0075,  0.0042, -0.0013,  0.0015,  0.0108, -0.0135, -0.0197,  0.0087,\n",
      "         -0.0028,  0.0166,  0.0035, -0.0078,  0.0092, -0.0178,  0.0275, -0.0143,\n",
      "         -0.0245, -0.0093,  0.0155, -0.0292,  0.0071,  0.0064, -0.0435,  0.0062,\n",
      "         -0.0222,  0.0182,  0.0045, -0.0125,  0.0027,  0.0191,  0.0496, -0.0256,\n",
      "         -0.0383, -0.0020, -0.0140,  0.0282,  0.0127,  0.0414,  0.0132, -0.0198,\n",
      "          0.0092,  0.0149, -0.0034,  0.0033, -0.0270, -0.0232, -0.0431, -0.0148,\n",
      "          0.0134,  0.0216,  0.0276,  0.0171,  0.0036,  0.0227,  0.0279,  0.0063,\n",
      "          0.0101, -0.0112,  0.0306, -0.0200,  0.0023, -0.0070, -0.0195,  0.0108,\n",
      "          0.0111, -0.0210, -0.0077,  0.0147, -0.0029,  0.0189,  0.0103, -0.0149,\n",
      "          0.0008,  0.0389, -0.0361, -0.0021, -0.0141,  0.0020,  0.0241, -0.0028,\n",
      "         -0.0012, -0.0044, -0.0026, -0.0065, -0.0177, -0.0428, -0.0191, -0.0022],\n",
      "        [ 0.0136, -0.0287, -0.0043, -0.0476,  0.0181, -0.0187, -0.0065,  0.0006,\n",
      "          0.0045,  0.0012, -0.0052,  0.0022, -0.0083,  0.0102, -0.0103,  0.0240,\n",
      "          0.0224,  0.0092,  0.0194, -0.0274, -0.0171, -0.0024, -0.0144,  0.0202,\n",
      "          0.0278, -0.0245,  0.0082,  0.0050,  0.0177,  0.0203, -0.0274,  0.0085,\n",
      "          0.0399,  0.0048,  0.0161, -0.0096,  0.0075,  0.0078,  0.0027, -0.0592,\n",
      "          0.0122,  0.0144, -0.0484,  0.0133,  0.0126,  0.0159,  0.0198,  0.0217,\n",
      "         -0.0486,  0.0199, -0.0039, -0.0120, -0.0137, -0.0009,  0.0087,  0.0120,\n",
      "          0.0170, -0.0168, -0.0125,  0.0013, -0.0145, -0.0049, -0.0124, -0.0264,\n",
      "         -0.0024,  0.0251, -0.0021, -0.0135,  0.0149,  0.0203, -0.0223, -0.0335,\n",
      "         -0.0190,  0.0154, -0.0177, -0.0165,  0.0109,  0.0090, -0.0043,  0.0329,\n",
      "         -0.0116, -0.0275, -0.0132, -0.0116, -0.0067, -0.0211, -0.0098,  0.0186,\n",
      "          0.0104,  0.0243,  0.0372, -0.0072, -0.0195, -0.0049, -0.0221, -0.0049,\n",
      "          0.0271, -0.0233,  0.0138,  0.0158, -0.0126,  0.0023, -0.0045, -0.0017,\n",
      "          0.0112,  0.0052,  0.0078,  0.0054, -0.0175, -0.0153, -0.0350, -0.0191,\n",
      "          0.0297, -0.0082, -0.0262, -0.0323,  0.0054,  0.0158,  0.0199, -0.0151,\n",
      "         -0.0125,  0.0147, -0.0236,  0.0029, -0.0093,  0.0034, -0.0089,  0.0088]])\n",
      "tensor([[-2.0184e-03,  1.1020e-02, -1.1113e-02,  7.5877e-03,  2.6995e-02,\n",
      "          8.5440e-03, -8.3826e-03, -1.5104e-02, -9.2580e-03, -1.9748e-02,\n",
      "          3.5525e-03, -7.8557e-03,  7.0362e-03,  7.2781e-03,  1.0215e-02,\n",
      "         -7.1603e-03, -2.5446e-02, -1.8594e-03, -1.2839e-02,  3.4658e-02,\n",
      "          5.5583e-03,  1.6164e-02, -1.7125e-02, -5.8912e-03,  2.4299e-02,\n",
      "          8.8632e-04,  1.0082e-02, -3.7090e-03,  1.7419e-02, -2.7417e-03,\n",
      "          1.3300e-02,  9.0539e-03,  1.7292e-03, -2.1572e-03, -1.7209e-02,\n",
      "          1.3334e-02,  1.3346e-03, -5.9699e-03, -8.7559e-03, -9.4003e-03,\n",
      "         -5.5735e-03, -1.6394e-02, -7.2465e-03, -8.8522e-03, -8.6439e-03,\n",
      "          1.1392e-02,  6.4678e-03,  1.6395e-02, -3.6814e-02,  8.5796e-03,\n",
      "         -3.0757e-03,  2.1877e-02, -9.1511e-03, -6.1992e-03, -2.8541e-03,\n",
      "          7.1911e-03, -1.3977e-02, -8.6993e-03, -2.4847e-02, -2.2718e-03,\n",
      "          2.6081e-02,  6.0058e-03, -2.0408e-02,  2.0025e-03,  1.8800e-02,\n",
      "         -6.6151e-03,  3.7249e-03,  1.8292e-02, -1.9648e-03, -7.1906e-03,\n",
      "         -1.5855e-02,  2.0104e-02,  1.0156e-02,  3.6754e-03, -2.8442e-02,\n",
      "         -2.0903e-02,  3.0540e-03,  2.0786e-03, -2.4367e-02,  2.2294e-02,\n",
      "          1.4622e-03,  6.6697e-04, -1.5999e-02,  2.4865e-04,  1.9542e-03,\n",
      "         -2.3746e-02,  1.4136e-02, -1.5003e-02,  1.3102e-02, -4.7884e-03,\n",
      "          7.2307e-03,  4.1489e-03, -2.2363e-02, -9.2584e-03, -2.0357e-02,\n",
      "         -1.2480e-03, -2.5020e-02, -1.8247e-03,  7.9460e-03,  2.4723e-02,\n",
      "          8.6642e-04,  2.7445e-02, -2.3491e-04,  3.4149e-03,  1.7128e-02,\n",
      "          4.1323e-04,  1.7782e-03, -8.4221e-03, -3.6996e-04, -4.0630e-02,\n",
      "         -5.5694e-03, -2.0889e-02, -8.5993e-03,  1.2304e-02,  2.5195e-05,\n",
      "          1.2087e-02,  9.2521e-03,  9.8754e-03, -3.2809e-02, -4.2566e-03,\n",
      "         -1.0663e-02,  3.1371e-03,  9.4123e-03,  2.2559e-04, -2.8963e-02,\n",
      "         -1.1763e-03,  2.1507e-02, -1.8778e-02],\n",
      "        [ 4.7808e-03,  3.5839e-02,  1.4797e-02,  1.1747e-02, -1.6293e-02,\n",
      "         -1.7558e-02,  1.8723e-02, -8.6330e-03, -7.8114e-03, -2.7619e-04,\n",
      "         -1.4580e-02, -2.7770e-02,  4.3080e-03,  1.3558e-02, -1.0741e-02,\n",
      "         -6.1803e-03,  3.4057e-03,  1.1170e-02,  1.3847e-02,  1.7067e-02,\n",
      "          3.0522e-03,  8.7519e-03, -1.1547e-02,  5.2504e-04,  2.0559e-03,\n",
      "          1.2979e-02,  1.0016e-02, -5.2550e-03,  1.9431e-04,  1.1286e-02,\n",
      "          8.1675e-03,  1.6646e-02,  1.3228e-02, -1.5584e-02, -1.3890e-02,\n",
      "         -8.8766e-03,  1.1642e-02, -5.7839e-03,  5.2323e-03,  1.8368e-02,\n",
      "         -3.9629e-03,  3.9042e-03,  3.7804e-03,  3.9556e-03,  3.8395e-02,\n",
      "          1.6912e-02, -2.9784e-03, -1.4870e-03,  1.4677e-02, -2.5548e-03,\n",
      "          1.2480e-02, -1.0135e-02,  1.0514e-02,  1.0398e-02,  1.8616e-02,\n",
      "          3.1039e-03,  1.2795e-02, -9.9168e-03,  1.1419e-02, -1.4203e-02,\n",
      "         -4.4319e-03,  2.6003e-03, -1.7428e-02, -2.0194e-03, -6.5896e-03,\n",
      "          1.7083e-02, -1.5218e-02,  9.8724e-03, -1.8412e-02,  4.4902e-03,\n",
      "          1.4859e-03, -1.4596e-03,  1.7189e-02,  1.5124e-02, -4.8237e-03,\n",
      "          1.5378e-02,  4.6638e-03, -2.1568e-02, -1.2663e-02,  9.9997e-03,\n",
      "          7.4615e-03, -7.5812e-03, -1.3436e-02,  1.7162e-02, -9.3002e-03,\n",
      "          4.4175e-03,  1.8971e-03,  1.7873e-02, -1.7120e-03, -1.6662e-02,\n",
      "         -4.8397e-03, -4.3561e-02, -6.2560e-03,  2.1129e-02, -2.0636e-02,\n",
      "          2.1856e-03, -9.0215e-03, -7.8007e-03,  2.9044e-02,  8.3768e-03,\n",
      "         -1.6079e-02,  1.6700e-02, -2.6739e-03, -2.9432e-03, -2.7043e-02,\n",
      "         -2.9517e-02, -1.0631e-02,  1.2849e-02,  1.8069e-03, -2.6517e-02,\n",
      "          1.4428e-02,  1.2181e-02, -1.6766e-02, -2.2245e-03,  2.7958e-02,\n",
      "         -2.4091e-02,  1.9560e-02, -9.1743e-03,  3.1436e-03, -1.4782e-03,\n",
      "         -3.4589e-02, -8.8902e-03, -1.1068e-03,  1.9111e-02,  1.1265e-02,\n",
      "          8.6733e-03,  1.4249e-02,  4.0962e-03]])\n",
      "4386178\n",
      "4386178\n"
     ]
    }
   ],
   "source": [
    "from client.utils import count_parameters, compare_models\n",
    "\n",
    "\n",
    "# print(global_model)\n",
    "   \n",
    "print(bert_model.state_dict()['classifier.weight'])\n",
    "print(bert_global_model.state_dict()['classifier.weight'])\n",
    "# the averaged model should be half the model1\n",
    "\n",
    "\n",
    "print(count_parameters(bert_model))\n",
    "print(count_parameters(bert_global_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# NVIDIA drivers not working\n",
    "torch.set_default_device('cpu')\n",
    "device = ('cpu')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
