{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation of one round of blockchain-based federated learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n",
      "Using device: cuda\n",
      "Cuda set as default device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config variables for models and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.train import train\n",
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, weights_zero_init,  weights_init, update_lr\n",
    "from client.aggregators import federated_aggregate\n",
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create two local models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "\n",
    "model1 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model1.to(device)\n",
    "print(model1)\n",
    "\n",
    "model2 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model2.to(device)\n",
    "print(model2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train first local model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3009\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2944\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2815\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2652\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2571\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2337\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2261\n",
      "Epoch [1/1], Step [9/245], Loss: 2.2200\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1710\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1556\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1138\n",
      "Epoch [1/1], Step [13/245], Loss: 2.0962\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1602\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0818\n",
      "Epoch [1/1], Step [16/245], Loss: 2.1103\n",
      "Epoch [1/1], Step [17/245], Loss: 1.9963\n",
      "Epoch [1/1], Step [18/245], Loss: 1.9784\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0129\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0633\n",
      "Epoch [1/1], Step [21/245], Loss: 1.9089\n",
      "Epoch [1/1], Step [22/245], Loss: 1.9906\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0812\n",
      "Epoch [1/1], Step [24/245], Loss: 1.8901\n",
      "Epoch [1/1], Step [25/245], Loss: 1.9126\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9519\n",
      "Epoch [1/1], Step [27/245], Loss: 2.0050\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9351\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9058\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9419\n",
      "Epoch [1/1], Step [31/245], Loss: 1.8638\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9266\n",
      "Epoch [1/1], Step [33/245], Loss: 1.8667\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9464\n",
      "Epoch [1/1], Step [35/245], Loss: 1.7960\n",
      "Epoch [1/1], Step [36/245], Loss: 2.0087\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9379\n",
      "Epoch [1/1], Step [38/245], Loss: 1.7936\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8958\n",
      "Epoch [1/1], Step [40/245], Loss: 1.9058\n",
      "Epoch [1/1], Step [41/245], Loss: 1.8047\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8672\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9300\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8780\n",
      "Epoch [1/1], Step [45/245], Loss: 1.9532\n",
      "Epoch [1/1], Step [46/245], Loss: 1.8803\n",
      "Epoch [1/1], Step [47/245], Loss: 1.9164\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8471\n",
      "Epoch [1/1], Step [49/245], Loss: 1.9205\n",
      "Epoch [1/1], Step [50/245], Loss: 1.9085\n",
      "Epoch [1/1], Step [51/245], Loss: 1.8760\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8403\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8162\n",
      "Epoch [1/1], Step [54/245], Loss: 1.9498\n",
      "Epoch [1/1], Step [55/245], Loss: 1.9276\n",
      "Epoch [1/1], Step [56/245], Loss: 1.8027\n",
      "Epoch [1/1], Step [57/245], Loss: 1.8800\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8453\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8304\n",
      "Epoch [1/1], Step [60/245], Loss: 1.7858\n",
      "Epoch [1/1], Step [61/245], Loss: 1.9144\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8921\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7647\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8757\n",
      "Epoch [1/1], Step [65/245], Loss: 1.7829\n",
      "Epoch [1/1], Step [66/245], Loss: 1.7695\n",
      "Epoch [1/1], Step [67/245], Loss: 1.7907\n",
      "Epoch [1/1], Step [68/245], Loss: 1.9296\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7650\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8162\n",
      "Epoch [1/1], Step [71/245], Loss: 1.8130\n",
      "Epoch [1/1], Step [72/245], Loss: 1.8188\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8235\n",
      "Epoch [1/1], Step [74/245], Loss: 1.6756\n",
      "Epoch [1/1], Step [75/245], Loss: 1.7514\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7388\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8373\n",
      "Epoch [1/1], Step [78/245], Loss: 1.8102\n",
      "Epoch [1/1], Step [79/245], Loss: 1.8402\n",
      "Epoch [1/1], Step [80/245], Loss: 1.6943\n",
      "Epoch [1/1], Step [81/245], Loss: 1.7029\n",
      "Epoch [1/1], Step [82/245], Loss: 1.7918\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7276\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7423\n",
      "Epoch [1/1], Step [85/245], Loss: 1.7972\n",
      "Epoch [1/1], Step [86/245], Loss: 1.8103\n",
      "Epoch [1/1], Step [87/245], Loss: 1.8662\n",
      "Epoch [1/1], Step [88/245], Loss: 1.8229\n",
      "Epoch [1/1], Step [89/245], Loss: 1.7456\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7691\n",
      "Epoch [1/1], Step [91/245], Loss: 1.6432\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7031\n",
      "Epoch [1/1], Step [93/245], Loss: 1.6119\n",
      "Epoch [1/1], Step [94/245], Loss: 1.8063\n",
      "Epoch [1/1], Step [95/245], Loss: 1.8522\n",
      "Epoch [1/1], Step [96/245], Loss: 1.8035\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7396\n",
      "Epoch [1/1], Step [98/245], Loss: 1.8218\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7895\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7186\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7914\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7647\n",
      "Epoch [1/1], Step [103/245], Loss: 1.7130\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7654\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7102\n",
      "Epoch [1/1], Step [106/245], Loss: 1.7417\n",
      "Epoch [1/1], Step [107/245], Loss: 1.7685\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6800\n",
      "Epoch [1/1], Step [109/245], Loss: 1.7007\n",
      "Epoch [1/1], Step [110/245], Loss: 1.6786\n",
      "Epoch [1/1], Step [111/245], Loss: 1.8691\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7445\n",
      "Epoch [1/1], Step [113/245], Loss: 1.6418\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7650\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6874\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8039\n",
      "Epoch [1/1], Step [117/245], Loss: 1.6984\n",
      "Epoch [1/1], Step [118/245], Loss: 1.7902\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7532\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7508\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7385\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7198\n",
      "Epoch [1/1], Step [123/245], Loss: 1.6826\n",
      "Epoch [1/1], Step [124/245], Loss: 1.6821\n",
      "Epoch [1/1], Step [125/245], Loss: 1.6423\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7368\n",
      "Epoch [1/1], Step [127/245], Loss: 1.5996\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7107\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7954\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7997\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6783\n",
      "Epoch [1/1], Step [132/245], Loss: 1.8221\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6822\n",
      "Epoch [1/1], Step [134/245], Loss: 1.8069\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6238\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7251\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7813\n",
      "Epoch [1/1], Step [138/245], Loss: 1.5621\n",
      "Epoch [1/1], Step [139/245], Loss: 1.6981\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6239\n",
      "Epoch [1/1], Step [141/245], Loss: 1.6533\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7240\n",
      "Epoch [1/1], Step [143/245], Loss: 1.6418\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6677\n",
      "Epoch [1/1], Step [145/245], Loss: 1.7470\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6390\n",
      "Epoch [1/1], Step [147/245], Loss: 1.7011\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7211\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6745\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6530\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7727\n",
      "Epoch [1/1], Step [152/245], Loss: 1.7437\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6869\n",
      "Epoch [1/1], Step [154/245], Loss: 1.6301\n",
      "Epoch [1/1], Step [155/245], Loss: 1.5472\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6916\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7256\n",
      "Epoch [1/1], Step [158/245], Loss: 1.6969\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7781\n",
      "Epoch [1/1], Step [160/245], Loss: 1.8808\n",
      "Epoch [1/1], Step [161/245], Loss: 1.5214\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6329\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6245\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6348\n",
      "Epoch [1/1], Step [165/245], Loss: 1.8377\n",
      "Epoch [1/1], Step [166/245], Loss: 1.7659\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6711\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6783\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7160\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6627\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6736\n",
      "Epoch [1/1], Step [172/245], Loss: 1.7165\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6591\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6379\n",
      "Epoch [1/1], Step [175/245], Loss: 1.7114\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6588\n",
      "Epoch [1/1], Step [177/245], Loss: 1.7096\n",
      "Epoch [1/1], Step [178/245], Loss: 1.7134\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7141\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6784\n",
      "Epoch [1/1], Step [181/245], Loss: 1.6247\n",
      "Epoch [1/1], Step [182/245], Loss: 1.7105\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6714\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6345\n",
      "Epoch [1/1], Step [185/245], Loss: 1.5675\n",
      "Epoch [1/1], Step [186/245], Loss: 1.5892\n",
      "Epoch [1/1], Step [187/245], Loss: 1.7230\n",
      "Epoch [1/1], Step [188/245], Loss: 1.7226\n",
      "Epoch [1/1], Step [189/245], Loss: 1.5498\n",
      "Epoch [1/1], Step [190/245], Loss: 1.5832\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6551\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6500\n",
      "Epoch [1/1], Step [193/245], Loss: 1.6876\n",
      "Epoch [1/1], Step [194/245], Loss: 1.5842\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6238\n",
      "Epoch [1/1], Step [196/245], Loss: 1.5681\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6269\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6473\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6138\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6532\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6077\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6453\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6985\n",
      "Epoch [1/1], Step [204/245], Loss: 1.6437\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6348\n",
      "Epoch [1/1], Step [206/245], Loss: 1.7277\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7251\n",
      "Epoch [1/1], Step [208/245], Loss: 1.5747\n",
      "Epoch [1/1], Step [209/245], Loss: 1.8638\n",
      "Epoch [1/1], Step [210/245], Loss: 1.7157\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6270\n",
      "Epoch [1/1], Step [212/245], Loss: 1.6977\n",
      "Epoch [1/1], Step [213/245], Loss: 1.6944\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6642\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6238\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7136\n",
      "Epoch [1/1], Step [217/245], Loss: 1.5408\n",
      "Epoch [1/1], Step [218/245], Loss: 1.8258\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6052\n",
      "Epoch [1/1], Step [220/245], Loss: 1.6072\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6571\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5780\n",
      "Epoch [1/1], Step [223/245], Loss: 1.4578\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7871\n",
      "Epoch [1/1], Step [225/245], Loss: 1.6035\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6332\n",
      "Epoch [1/1], Step [227/245], Loss: 1.6152\n",
      "Epoch [1/1], Step [228/245], Loss: 1.7437\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6694\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6549\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6809\n",
      "Epoch [1/1], Step [232/245], Loss: 1.5516\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5361\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6398\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6680\n",
      "Epoch [1/1], Step [236/245], Loss: 1.5234\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5036\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6118\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6263\n",
      "Epoch [1/1], Step [240/245], Loss: 1.5832\n",
      "Epoch [1/1], Step [241/245], Loss: 1.7001\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5712\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6553\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6483\n",
      "Epoch [1/1], Step [245/245], Loss: 1.6621\n",
      "Train accuracy is: 36.704081632653065 %\n",
      "Validation accuracy is: 43.2 %\n"
     ]
    }
   ],
   "source": [
    "model1_name = 'bcfl_model3'\n",
    "\n",
    "# Training\n",
    "model1.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model1.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model1, modelpath, model1_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train second local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3006\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2943\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2900\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2674\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2441\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2341\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2066\n",
      "Epoch [1/1], Step [9/245], Loss: 2.1784\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1761\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1666\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1576\n",
      "Epoch [1/1], Step [13/245], Loss: 2.0994\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1363\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0135\n",
      "Epoch [1/1], Step [16/245], Loss: 2.0541\n",
      "Epoch [1/1], Step [17/245], Loss: 2.1163\n",
      "Epoch [1/1], Step [18/245], Loss: 2.0126\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0440\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0545\n",
      "Epoch [1/1], Step [21/245], Loss: 2.0066\n",
      "Epoch [1/1], Step [22/245], Loss: 2.0536\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0547\n",
      "Epoch [1/1], Step [24/245], Loss: 1.9864\n",
      "Epoch [1/1], Step [25/245], Loss: 2.0128\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9094\n",
      "Epoch [1/1], Step [27/245], Loss: 2.0003\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9799\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9768\n",
      "Epoch [1/1], Step [30/245], Loss: 1.8767\n",
      "Epoch [1/1], Step [31/245], Loss: 1.9387\n",
      "Epoch [1/1], Step [32/245], Loss: 1.8853\n",
      "Epoch [1/1], Step [33/245], Loss: 1.9520\n",
      "Epoch [1/1], Step [34/245], Loss: 2.0137\n",
      "Epoch [1/1], Step [35/245], Loss: 1.9263\n",
      "Epoch [1/1], Step [36/245], Loss: 1.9398\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9212\n",
      "Epoch [1/1], Step [38/245], Loss: 1.8868\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8856\n",
      "Epoch [1/1], Step [40/245], Loss: 1.7938\n",
      "Epoch [1/1], Step [41/245], Loss: 1.9774\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8948\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9123\n",
      "Epoch [1/1], Step [44/245], Loss: 1.9623\n",
      "Epoch [1/1], Step [45/245], Loss: 1.8343\n",
      "Epoch [1/1], Step [46/245], Loss: 1.7810\n",
      "Epoch [1/1], Step [47/245], Loss: 1.8951\n",
      "Epoch [1/1], Step [48/245], Loss: 1.7858\n",
      "Epoch [1/1], Step [49/245], Loss: 2.0186\n",
      "Epoch [1/1], Step [50/245], Loss: 1.7345\n",
      "Epoch [1/1], Step [51/245], Loss: 1.8466\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8116\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8009\n",
      "Epoch [1/1], Step [54/245], Loss: 1.7630\n",
      "Epoch [1/1], Step [55/245], Loss: 1.7578\n",
      "Epoch [1/1], Step [56/245], Loss: 1.7506\n",
      "Epoch [1/1], Step [57/245], Loss: 1.7957\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8189\n",
      "Epoch [1/1], Step [59/245], Loss: 1.7304\n",
      "Epoch [1/1], Step [60/245], Loss: 1.7502\n",
      "Epoch [1/1], Step [61/245], Loss: 1.7272\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8336\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7145\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8643\n",
      "Epoch [1/1], Step [65/245], Loss: 1.9531\n",
      "Epoch [1/1], Step [66/245], Loss: 1.7885\n",
      "Epoch [1/1], Step [67/245], Loss: 1.7650\n",
      "Epoch [1/1], Step [68/245], Loss: 1.8184\n",
      "Epoch [1/1], Step [69/245], Loss: 1.8072\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8615\n",
      "Epoch [1/1], Step [71/245], Loss: 1.7734\n",
      "Epoch [1/1], Step [72/245], Loss: 1.7646\n",
      "Epoch [1/1], Step [73/245], Loss: 1.7787\n",
      "Epoch [1/1], Step [74/245], Loss: 1.8296\n",
      "Epoch [1/1], Step [75/245], Loss: 1.8354\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7445\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8631\n",
      "Epoch [1/1], Step [78/245], Loss: 1.6596\n",
      "Epoch [1/1], Step [79/245], Loss: 1.8048\n",
      "Epoch [1/1], Step [80/245], Loss: 1.8561\n",
      "Epoch [1/1], Step [81/245], Loss: 1.8377\n",
      "Epoch [1/1], Step [82/245], Loss: 1.8485\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7868\n",
      "Epoch [1/1], Step [84/245], Loss: 1.6332\n",
      "Epoch [1/1], Step [85/245], Loss: 1.7393\n",
      "Epoch [1/1], Step [86/245], Loss: 1.8199\n",
      "Epoch [1/1], Step [87/245], Loss: 1.7573\n",
      "Epoch [1/1], Step [88/245], Loss: 1.7847\n",
      "Epoch [1/1], Step [89/245], Loss: 1.8054\n",
      "Epoch [1/1], Step [90/245], Loss: 1.8033\n",
      "Epoch [1/1], Step [91/245], Loss: 1.7154\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7149\n",
      "Epoch [1/1], Step [93/245], Loss: 1.7086\n",
      "Epoch [1/1], Step [94/245], Loss: 1.7570\n",
      "Epoch [1/1], Step [95/245], Loss: 1.6855\n",
      "Epoch [1/1], Step [96/245], Loss: 1.8058\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7073\n",
      "Epoch [1/1], Step [98/245], Loss: 1.7337\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7180\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7651\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7538\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7152\n",
      "Epoch [1/1], Step [103/245], Loss: 1.6850\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7630\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7801\n",
      "Epoch [1/1], Step [106/245], Loss: 1.8587\n",
      "Epoch [1/1], Step [107/245], Loss: 1.8110\n",
      "Epoch [1/1], Step [108/245], Loss: 1.7180\n",
      "Epoch [1/1], Step [109/245], Loss: 1.7995\n",
      "Epoch [1/1], Step [110/245], Loss: 1.7972\n",
      "Epoch [1/1], Step [111/245], Loss: 1.7187\n",
      "Epoch [1/1], Step [112/245], Loss: 1.6581\n",
      "Epoch [1/1], Step [113/245], Loss: 1.7613\n",
      "Epoch [1/1], Step [114/245], Loss: 1.6400\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6073\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8160\n",
      "Epoch [1/1], Step [117/245], Loss: 1.7394\n",
      "Epoch [1/1], Step [118/245], Loss: 1.6715\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7337\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7238\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7119\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7695\n",
      "Epoch [1/1], Step [123/245], Loss: 1.6840\n",
      "Epoch [1/1], Step [124/245], Loss: 1.8353\n",
      "Epoch [1/1], Step [125/245], Loss: 1.8309\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7812\n",
      "Epoch [1/1], Step [127/245], Loss: 1.7148\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7573\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7928\n",
      "Epoch [1/1], Step [130/245], Loss: 1.6513\n",
      "Epoch [1/1], Step [131/245], Loss: 1.7825\n",
      "Epoch [1/1], Step [132/245], Loss: 1.7736\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6391\n",
      "Epoch [1/1], Step [134/245], Loss: 1.7925\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6898\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7079\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7862\n",
      "Epoch [1/1], Step [138/245], Loss: 1.6793\n",
      "Epoch [1/1], Step [139/245], Loss: 1.7265\n",
      "Epoch [1/1], Step [140/245], Loss: 1.5614\n",
      "Epoch [1/1], Step [141/245], Loss: 1.7443\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7551\n",
      "Epoch [1/1], Step [143/245], Loss: 1.7298\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6025\n",
      "Epoch [1/1], Step [145/245], Loss: 1.5800\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6216\n",
      "Epoch [1/1], Step [147/245], Loss: 1.6553\n",
      "Epoch [1/1], Step [148/245], Loss: 1.6524\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6718\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6678\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7080\n",
      "Epoch [1/1], Step [152/245], Loss: 1.5639\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6980\n",
      "Epoch [1/1], Step [154/245], Loss: 1.6209\n",
      "Epoch [1/1], Step [155/245], Loss: 1.8048\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6632\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7507\n",
      "Epoch [1/1], Step [158/245], Loss: 1.6908\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7118\n",
      "Epoch [1/1], Step [160/245], Loss: 1.7136\n",
      "Epoch [1/1], Step [161/245], Loss: 1.7064\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6787\n",
      "Epoch [1/1], Step [163/245], Loss: 1.7089\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6442\n",
      "Epoch [1/1], Step [165/245], Loss: 1.7413\n",
      "Epoch [1/1], Step [166/245], Loss: 1.5291\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6490\n",
      "Epoch [1/1], Step [168/245], Loss: 1.7520\n",
      "Epoch [1/1], Step [169/245], Loss: 1.5218\n",
      "Epoch [1/1], Step [170/245], Loss: 1.7110\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6860\n",
      "Epoch [1/1], Step [172/245], Loss: 1.6982\n",
      "Epoch [1/1], Step [173/245], Loss: 1.7970\n",
      "Epoch [1/1], Step [174/245], Loss: 1.5988\n",
      "Epoch [1/1], Step [175/245], Loss: 1.7681\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6091\n",
      "Epoch [1/1], Step [177/245], Loss: 1.6574\n",
      "Epoch [1/1], Step [178/245], Loss: 1.6699\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7009\n",
      "Epoch [1/1], Step [180/245], Loss: 1.7272\n",
      "Epoch [1/1], Step [181/245], Loss: 1.6774\n",
      "Epoch [1/1], Step [182/245], Loss: 1.6339\n",
      "Epoch [1/1], Step [183/245], Loss: 1.7186\n",
      "Epoch [1/1], Step [184/245], Loss: 1.5761\n",
      "Epoch [1/1], Step [185/245], Loss: 1.6616\n",
      "Epoch [1/1], Step [186/245], Loss: 1.7407\n",
      "Epoch [1/1], Step [187/245], Loss: 1.6234\n",
      "Epoch [1/1], Step [188/245], Loss: 1.6668\n",
      "Epoch [1/1], Step [189/245], Loss: 1.6367\n",
      "Epoch [1/1], Step [190/245], Loss: 1.6329\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6531\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6633\n",
      "Epoch [1/1], Step [193/245], Loss: 1.7093\n",
      "Epoch [1/1], Step [194/245], Loss: 1.6512\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6861\n",
      "Epoch [1/1], Step [196/245], Loss: 1.8245\n",
      "Epoch [1/1], Step [197/245], Loss: 1.5935\n",
      "Epoch [1/1], Step [198/245], Loss: 1.7002\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6674\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6356\n",
      "Epoch [1/1], Step [201/245], Loss: 1.7725\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6576\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6088\n",
      "Epoch [1/1], Step [204/245], Loss: 1.5823\n",
      "Epoch [1/1], Step [205/245], Loss: 1.7126\n",
      "Epoch [1/1], Step [206/245], Loss: 1.6809\n",
      "Epoch [1/1], Step [207/245], Loss: 1.5994\n",
      "Epoch [1/1], Step [208/245], Loss: 1.6376\n",
      "Epoch [1/1], Step [209/245], Loss: 1.6414\n",
      "Epoch [1/1], Step [210/245], Loss: 1.6446\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6737\n",
      "Epoch [1/1], Step [212/245], Loss: 1.5876\n",
      "Epoch [1/1], Step [213/245], Loss: 1.7090\n",
      "Epoch [1/1], Step [214/245], Loss: 1.7741\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6777\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7498\n",
      "Epoch [1/1], Step [217/245], Loss: 1.7266\n",
      "Epoch [1/1], Step [218/245], Loss: 1.7043\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6036\n",
      "Epoch [1/1], Step [220/245], Loss: 1.6985\n",
      "Epoch [1/1], Step [221/245], Loss: 1.5633\n",
      "Epoch [1/1], Step [222/245], Loss: 1.7091\n",
      "Epoch [1/1], Step [223/245], Loss: 1.7691\n",
      "Epoch [1/1], Step [224/245], Loss: 1.5843\n",
      "Epoch [1/1], Step [225/245], Loss: 1.7023\n",
      "Epoch [1/1], Step [226/245], Loss: 1.5792\n",
      "Epoch [1/1], Step [227/245], Loss: 1.5820\n",
      "Epoch [1/1], Step [228/245], Loss: 1.6157\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6722\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6279\n",
      "Epoch [1/1], Step [231/245], Loss: 1.5875\n",
      "Epoch [1/1], Step [232/245], Loss: 1.6171\n",
      "Epoch [1/1], Step [233/245], Loss: 1.7207\n",
      "Epoch [1/1], Step [234/245], Loss: 1.5807\n",
      "Epoch [1/1], Step [235/245], Loss: 1.7292\n",
      "Epoch [1/1], Step [236/245], Loss: 1.6396\n",
      "Epoch [1/1], Step [237/245], Loss: 1.6856\n",
      "Epoch [1/1], Step [238/245], Loss: 1.5368\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6354\n",
      "Epoch [1/1], Step [240/245], Loss: 1.6581\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6153\n",
      "Epoch [1/1], Step [242/245], Loss: 1.7019\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6888\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6504\n",
      "Epoch [1/1], Step [245/245], Loss: 1.7125\n",
      "Train accuracy is: 36.62244897959184 %\n",
      "Validation accuracy is: 43.6 %\n"
     ]
    }
   ],
   "source": [
    "model2_name = 'bcfl_model4'\n",
    "# Training\n",
    "model2.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model2.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model2, modelpath, model2_name, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 41.7 %\n",
      "Accuracy of the network on the 1000 test images: 42.9 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "model_ckpt = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model_ckpt = torch.load(pjoin(modelpath, model1_name + '.ckpt'))\n",
    "model1.load_state_dict(model_ckpt)\n",
    "model = model1\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))\n",
    "    \n",
    "    \n",
    "\n",
    "model = model2\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Forward the two local models to the blockchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Error creating model', 'error': '10 ABORTED: failed to endorse transaction, see attached details for more info'}\n",
      "{'message': 'Model submitted succesfully'}\n"
     ]
    }
   ],
   "source": [
    "# Send the saved model to Fabric-SDK via Gateway Client (REST call)\n",
    "\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "\n",
    "\n",
    "print(submit_local_model(model1_name, model1.state_dict()))\n",
    "\n",
    "print(submit_local_model(model2_name, model2.state_dict()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Aggregate the local models on the blockchain\n",
    "TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'Model submitted succesfully'}\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:294\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/util/util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:1386\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1386\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/http/client.py:294\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;66;03m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RemoteDisconnected(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote end closed connection without\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(model3)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(submit_local_model(model3_name, model3\u001b[38;5;241m.\u001b[39mstate_dict()))\n\u001b[0;32m---> 14\u001b[0m \u001b[43maggregate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel1_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel3_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/_bcfl/fabric-federated-learning/federated-learning/client/services/gateway_client.py:45\u001b[0m, in \u001b[0;36maggregate_models\u001b[0;34m(modelIds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate_models\u001b[39m(modelIds):\n\u001b[1;32m     44\u001b[0m     headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m---> 45\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBASE_URL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/aggregate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelIds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/requests/adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MaxRetryError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, ConnectTimeoutError):\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "# TODO this should be triggered automatically when the total users in the blockchain have triggered their updates\n",
    "\n",
    "from client.services.gateway_client import aggregate_models\n",
    "from client.utils import weights_zero_init\n",
    "\n",
    "model3 = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model3.to(device)\n",
    "weights_zero_init(model3)\n",
    "model3_name = 'bcfl_model_empty'\n",
    "# print(model3)\n",
    "print(submit_local_model(model3_name, model3.state_dict()))\n",
    "\n",
    "\n",
    "aggregate_models([model1_name, model3_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Download the new global model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json\n",
    "\n",
    "# retrieve future global model and convert it again to pytorch model\n",
    "\n",
    "# TODO change\n",
    "model_avg_name = model1_name\n",
    "\n",
    "model_params = get_model(model_avg_name)\n",
    "\n",
    "global_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "global_model.to(device)\n",
    "print(global_model)\n",
    "\n",
    "load_model_from_json(global_model, model_params)\n",
    "print(model)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the new global model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0781,  0.0531,  0.0765,  0.0695,  0.0584,  0.0888, -0.0152, -0.0041,\n",
      "         0.0655,  0.0632,  0.0207, -0.0331, -0.0308,  0.0388,  0.0202,  0.0874,\n",
      "        -0.0027,  0.0364,  0.0482,  0.0680, -0.0027, -0.0260,  0.0715,  0.0244,\n",
      "         0.0654,  0.0858,  0.0561,  0.0563, -0.0233,  0.0454,  0.0577, -0.0090,\n",
      "        -0.0112, -0.0342, -0.0198, -0.0160,  0.0385, -0.0171,  0.0479,  0.0897,\n",
      "         0.0603,  0.0571,  0.0074,  0.0662, -0.0064,  0.0493, -0.0284,  0.0637,\n",
      "         0.0816,  0.0661], device='cuda:0')\n",
      "tensor([ 0.0781,  0.0531,  0.0765,  0.0695,  0.0584,  0.0888, -0.0152, -0.0041,\n",
      "         0.0655,  0.0632,  0.0207, -0.0331, -0.0308,  0.0388,  0.0202,  0.0874,\n",
      "        -0.0027,  0.0364,  0.0482,  0.0680, -0.0027, -0.0260,  0.0715,  0.0244,\n",
      "         0.0654,  0.0858,  0.0561,  0.0563, -0.0233,  0.0454,  0.0577, -0.0090,\n",
      "        -0.0112, -0.0342, -0.0198, -0.0160,  0.0385, -0.0171,  0.0479,  0.0897,\n",
      "         0.0603,  0.0571,  0.0074,  0.0662, -0.0064,  0.0493, -0.0284,  0.0637,\n",
      "         0.0816,  0.0661], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model1.state_dict()['layers.0.bias'])\n",
    "print(global_model.state_dict()['layers.0.bias'])\n",
    "# the global model should be the same as model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the new global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 41.8 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = global_model\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
