{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXMFvm5AQYbF"
      },
      "source": [
        "# Bert Centralised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi8FiPVrQYbL"
      },
      "source": [
        "Set the module directory to import python files (RUN JUST ONCE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "tl_TYofaQYbM",
        "outputId": "523cb490-70c6-4e51-b4ac-2980a92adfd6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
        "import sys\n",
        "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
        "print(sys.path)\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOEovptTQZ8B",
        "outputId": "f388da2c-961f-413c-bb50-cb52458af2f0"
      },
      "outputs": [],
      "source": [
        "# Running in colaboratory\n",
        "!git clone https://github.com/vdevictor96/fabric-federated-learning\n",
        "%cd fabric-federated-learning/federated-learning/\n",
        "!git pull\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yEW7uOjQYbP",
        "outputId": "412e868f-8395-4e50-8611-609df99bf89b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Q_fGcfQYbR"
      },
      "source": [
        "### Initialize variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yKcPkLOQYbR",
        "outputId": "4775c80c-be0c-49f3-d0a1-28397feed7f6"
      },
      "outputs": [],
      "source": [
        "from client.model.bert_tiny import get_bert_tiny_tokenizer\n",
        "\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 4\n",
        "EVAL_BATCH_SIZE = 2\n",
        "TEST_BATCH_SIZE = 8\n",
        "TRAIN_SIZE = 0.8\n",
        "EVAL_SIZE = 0.2\n",
        "NUM_EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "SEED = 200\n",
        "tokenizer = get_bert_tiny_tokenizer()\n",
        "twitter_dep_train = 'client/data/datasets/twitter_dep/twitter_dep_train.csv'\n",
        "twitter_dep_test = 'client/data/datasets/twitter_dep/twitter_dep_test.csv'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJQ6woPCQYbS"
      },
      "source": [
        "### Loading Reddit Depression Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDbgjQiDQYbT",
        "outputId": "a6e2340f-c105-4929-d39e-d189db76d938"
      },
      "outputs": [],
      "source": [
        "from client.data.twitter_dep import get_twitter_dep_dataloaders\n",
        "\n",
        "\n",
        "train_loader, eval_loader = get_twitter_dep_dataloaders(twitter_dep_train, tokenizer, \n",
        "                                                                    train_size=TRAIN_SIZE,\n",
        "                                                                    eval_size=EVAL_SIZE,\n",
        "                                                                    train_batch_size=TRAIN_BATCH_SIZE, \n",
        "                                                                    eval_batch_size=EVAL_BATCH_SIZE, \n",
        "                                                                    max_len=MAX_LEN, \n",
        "                                                                    seed=SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBnf2FYYQYbT"
      },
      "source": [
        "### Creating Bert Tiny Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwM1xXI8QYbU",
        "outputId": "e8da0cae-4784-455a-d9f3-d956bd186996"
      },
      "outputs": [],
      "source": [
        "from client.model.bert_tiny import get_bert_tiny_model\n",
        "\n",
        "bert_tiny = get_bert_tiny_model(device=device)\n",
        "print(bert_tiny)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEXVeNvpR_yZ",
        "outputId": "3abf84bd-080f-43ff-fa2e-08249670f46c"
      },
      "outputs": [],
      "source": [
        "# TODO necessary?\n",
        "!pip install evaluate\n",
        "!pip install accelerate\n",
        "!pip install transformers[torch]\n",
        "!pip show accelerate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlVPAehfQYbU"
      },
      "source": [
        "### Loading Transformers Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9or1K77uQYbU"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from client.data.twitter_dep import get_twitter_dep_datasets, get_twitter_dep_test_dataset\n",
        "\n",
        "train_dataset, eval_dataset = get_twitter_dep_datasets(twitter_dep_train, tokenizer, TRAIN_SIZE, EVAL_SIZE, MAX_LEN, SEED)\n",
        "test_dataset = get_twitter_dep_test_dataset(twitter_dep_test, tokenizer, MAX_LEN, SEED)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"client/models/bert-tiny/\", evaluation_strategy=\"epoch\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"client/models/bert-tiny/\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=bert_tiny,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcaxIm1lQYbU"
      },
      "source": [
        "### Train model with Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "H01Y0_56QYbV",
        "outputId": "0cb7e62b-a130-4de0-f731-8ac5564a9e33"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT2pWHNTQYbV"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "YZogoQtQQYbV",
        "outputId": "6cdc5850-9c06-4e57-bc26-a3df6315651d"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from transformers import get_scheduler\n",
        "\n",
        "\n",
        "# Loss function\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "# Optimizer and learning rate scheduler\n",
        "optimizer = Adam(bert_tiny.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTabl8QpQYbV"
      },
      "source": [
        "### Test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpq6wAOtQYbV",
        "outputId": "5d96bd24-bb0c-4fe8-b7aa-7624e113b804"
      },
      "outputs": [],
      "source": [
        "from client.test import test_text_class\n",
        "# Test the model\n",
        "test_text_class(bert_tiny, test_loader, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "Rd08b21RfWhA",
        "outputId": "43552a69-4a95-479a-f460-cc9b78f0095b"
      },
      "outputs": [],
      "source": [
        "! pip install optuna\n",
        "# ! pip install ray[tune]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "from client.data.twitter_dep import get_twitter_dep_datasets, get_twitter_dep_test_dataset\n",
        "from client.model.bert_tiny import get_bert_tiny_tokenizer\n",
        "\n",
        "train_dataset, eval_dataset = get_twitter_dep_datasets(twitter_dep_train, tokenizer, TRAIN_SIZE, EVAL_SIZE, MAX_LEN, SEED)\n",
        "test_dataset = get_twitter_dep_test_dataset(twitter_dep_test, tokenizer, MAX_LEN, SEED)\n",
        "tokenizer = get_bert_tiny_tokenizer()\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"client/models/bert-tiny/\", evaluation_strategy=\"epoch\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"client/models/bert-tiny/\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "RIgJ1ceVffTC",
        "outputId": "b9ae1cbc-0e5a-42a8-8736-d9fb4593d205"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "def model_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")    \n",
        "\n",
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "def my_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 1, 15),\n",
        "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [4, 8, 16, 32, 64]),\n",
        "    }\n",
        "\n",
        "# best_run = trainer.hyperparameter_search(hp_space=my_hp_space, n_trials=20, direction=\"maximize\")\n",
        "best_run = trainer.hyperparameter_search(n_trials=20, direction=\"maximize\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
