{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_tokenizer\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 8\n",
    "TRAIN_SIZE = 0.8\n",
    "EVAL_SIZE = 0.2\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "SEED = 200\n",
    "tokenizer = get_bert_tiny_tokenizer()\n",
    "twitter_dep_train = 'client/data/datasets/twitter_dep/twitter_dep_train.csv'\n",
    "twitter_dep_test = 'client/data/datasets/twitter_dep/twitter_dep_test.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Reddit Depression Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.data.twitter_dep import get_twitter_dep_dataloaders\n",
    "\n",
    "\n",
    "train_loader, eval_loader = get_twitter_dep_dataloaders(twitter_dep_train, tokenizer, \n",
    "                                                                    train_size=TRAIN_SIZE,\n",
    "                                                                    eval_size=EVAL_SIZE,\n",
    "                                                                    train_batch_size=TRAIN_BATCH_SIZE, \n",
    "                                                                    eval_batch_size=EVAL_BATCH_SIZE, \n",
    "                                                                    max_len=MAX_LEN, \n",
    "                                                                    seed=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bert Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_model\n",
    "\n",
    "bert_tiny = get_bert_tiny_model(device=device)\n",
    "print(bert_tiny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Transformers Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from client.data.twitter_dep import get_twitter_dep_datasets, get_twitter_dep_test_dataset\n",
    "\n",
    "train_dataset, eval_dataset = get_twitter_dep_datasets(twitter_dep_train, tokenizer, TRAIN_SIZE, EVAL_SIZE, MAX_LEN, SEED)\n",
    "test_dataset = get_twitter_dep_test_dataset(twitter_dep_test, tokenizer, MAX_LEN, SEED)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"client/models/bert-tiny/\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_tiny,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e1273dae1c4e77b6bd240eb0182fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/744 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80bb115377d4fa192fe839198f2a485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aac0aee03f144a2ac61ab150a2ce507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4992581009864807, 'eval_accuracy': 0.7782258064516129, 'eval_runtime': 2.9603, 'eval_samples_per_second': 167.552, 'eval_steps_per_second': 20.944, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537498996781415d9620c681f5808f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47255343198776245, 'eval_accuracy': 0.7943548387096774, 'eval_runtime': 2.7936, 'eval_samples_per_second': 177.546, 'eval_steps_per_second': 22.193, 'epoch': 2.0}\n",
      "{'loss': 0.5215, 'learning_rate': 1.639784946236559e-05, 'epoch': 2.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513a9c5ec9364d1bb03b23028bbf7fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4657380282878876, 'eval_accuracy': 0.7943548387096774, 'eval_runtime': 3.0177, 'eval_samples_per_second': 164.365, 'eval_steps_per_second': 20.546, 'epoch': 3.0}\n",
      "{'train_runtime': 66.3665, 'train_samples_per_second': 89.593, 'train_steps_per_second': 11.21, 'train_loss': 0.4979045109082294, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=744, training_loss=0.4979045109082294, metrics={'train_runtime': 66.3665, 'train_samples_per_second': 89.593, 'train_steps_per_second': 11.21, 'train_loss': 0.4979045109082294, 'epoch': 3.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclient\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m test_text_class\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_text_class(bert_tiny, test_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'client'"
     ]
    }
   ],
   "source": [
    "from client.test import test_text_class\n",
    "\n",
    "# Test the model\n",
    "test_text_class(bert_tiny, test_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
