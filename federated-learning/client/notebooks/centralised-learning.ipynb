{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCuda available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get the name of the CUDA device\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmajor and minor cuda capability of the device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_capability()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:419\u001b[0m, in \u001b[0;36mget_device_name\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:449\u001b[0m, in \u001b[0;36mget_device_properties\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[0;32m~/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a sample Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc.weight \t torch.Size([1, 10])\n",
      "fc.bias \t torch.Size([1])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]\n",
      "cuda:0\n",
      "Epoch 0, Loss: 0.7403390407562256\n",
      "Epoch 1, Loss: 0.7397933602333069\n",
      "Epoch 2, Loss: 0.7392504811286926\n",
      "Epoch 3, Loss: 0.7387102842330933\n",
      "Epoch 4, Loss: 0.7381728887557983\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# torch.set_default_device('cpu')\n",
    "\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "num_classes = 1  # Example number of classes\n",
    "# model = Perceptron(n_features, num_classes)  # Instantiate the model (on the default device\n",
    "dummy_model = Perceptron(n_features)  # Instantiate the model (on the default device\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in dummy_model.state_dict():\n",
    "    print(param_tensor, \"\\t\", dummy_model.state_dict()[param_tensor].size())\n",
    "    \n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(dummy_model.parameters(), lr=0.01)\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    outputs = dummy_model(dummy_inputs)  # Forward pass\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading CIFAR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3021\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2964\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2850\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2702\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2597\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2343\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2246\n",
      "Epoch [1/1], Step [9/245], Loss: 2.2242\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1748\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1605\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1233\n",
      "Epoch [1/1], Step [13/245], Loss: 2.0954\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1732\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0841\n",
      "Epoch [1/1], Step [16/245], Loss: 2.1275\n",
      "Epoch [1/1], Step [17/245], Loss: 2.0114\n",
      "Epoch [1/1], Step [18/245], Loss: 1.9886\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0234\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0858\n",
      "Epoch [1/1], Step [21/245], Loss: 1.9284\n",
      "Epoch [1/1], Step [22/245], Loss: 2.0179\n",
      "Epoch [1/1], Step [23/245], Loss: 2.1011\n",
      "Epoch [1/1], Step [24/245], Loss: 1.9127\n",
      "Epoch [1/1], Step [25/245], Loss: 1.9349\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9748\n",
      "Epoch [1/1], Step [27/245], Loss: 2.0012\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9589\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9110\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9563\n",
      "Epoch [1/1], Step [31/245], Loss: 1.8837\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9488\n",
      "Epoch [1/1], Step [33/245], Loss: 1.8926\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9582\n",
      "Epoch [1/1], Step [35/245], Loss: 1.8252\n",
      "Epoch [1/1], Step [36/245], Loss: 2.0204\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9434\n",
      "Epoch [1/1], Step [38/245], Loss: 1.8173\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8894\n",
      "Epoch [1/1], Step [40/245], Loss: 1.9254\n",
      "Epoch [1/1], Step [41/245], Loss: 1.8121\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8870\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9446\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8961\n",
      "Epoch [1/1], Step [45/245], Loss: 1.9609\n",
      "Epoch [1/1], Step [46/245], Loss: 1.9061\n",
      "Epoch [1/1], Step [47/245], Loss: 1.9204\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8615\n",
      "Epoch [1/1], Step [49/245], Loss: 1.9318\n",
      "Epoch [1/1], Step [50/245], Loss: 1.9328\n",
      "Epoch [1/1], Step [51/245], Loss: 1.8998\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8498\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8327\n",
      "Epoch [1/1], Step [54/245], Loss: 1.9739\n",
      "Epoch [1/1], Step [55/245], Loss: 1.9434\n",
      "Epoch [1/1], Step [56/245], Loss: 1.8114\n",
      "Epoch [1/1], Step [57/245], Loss: 1.9044\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8693\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8425\n",
      "Epoch [1/1], Step [60/245], Loss: 1.8126\n",
      "Epoch [1/1], Step [61/245], Loss: 1.9136\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8961\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7793\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8679\n",
      "Epoch [1/1], Step [65/245], Loss: 1.7959\n",
      "Epoch [1/1], Step [66/245], Loss: 1.7859\n",
      "Epoch [1/1], Step [67/245], Loss: 1.8059\n",
      "Epoch [1/1], Step [68/245], Loss: 1.9489\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7912\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8359\n",
      "Epoch [1/1], Step [71/245], Loss: 1.8136\n",
      "Epoch [1/1], Step [72/245], Loss: 1.8389\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8206\n",
      "Epoch [1/1], Step [74/245], Loss: 1.6909\n",
      "Epoch [1/1], Step [75/245], Loss: 1.7554\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7437\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8432\n",
      "Epoch [1/1], Step [78/245], Loss: 1.8067\n",
      "Epoch [1/1], Step [79/245], Loss: 1.8576\n",
      "Epoch [1/1], Step [80/245], Loss: 1.6933\n",
      "Epoch [1/1], Step [81/245], Loss: 1.7110\n",
      "Epoch [1/1], Step [82/245], Loss: 1.7942\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7239\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7573\n",
      "Epoch [1/1], Step [85/245], Loss: 1.8013\n",
      "Epoch [1/1], Step [86/245], Loss: 1.8180\n",
      "Epoch [1/1], Step [87/245], Loss: 1.8746\n",
      "Epoch [1/1], Step [88/245], Loss: 1.8386\n",
      "Epoch [1/1], Step [89/245], Loss: 1.7487\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7815\n",
      "Epoch [1/1], Step [91/245], Loss: 1.6696\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7227\n",
      "Epoch [1/1], Step [93/245], Loss: 1.6197\n",
      "Epoch [1/1], Step [94/245], Loss: 1.8048\n",
      "Epoch [1/1], Step [95/245], Loss: 1.8517\n",
      "Epoch [1/1], Step [96/245], Loss: 1.8169\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7320\n",
      "Epoch [1/1], Step [98/245], Loss: 1.8398\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7832\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7294\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7924\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7500\n",
      "Epoch [1/1], Step [103/245], Loss: 1.7205\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7700\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7094\n",
      "Epoch [1/1], Step [106/245], Loss: 1.7332\n",
      "Epoch [1/1], Step [107/245], Loss: 1.8005\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6878\n",
      "Epoch [1/1], Step [109/245], Loss: 1.6925\n",
      "Epoch [1/1], Step [110/245], Loss: 1.6823\n",
      "Epoch [1/1], Step [111/245], Loss: 1.8627\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7486\n",
      "Epoch [1/1], Step [113/245], Loss: 1.6159\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7619\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6803\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8196\n",
      "Epoch [1/1], Step [117/245], Loss: 1.7040\n",
      "Epoch [1/1], Step [118/245], Loss: 1.8081\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7535\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7494\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7575\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7231\n",
      "Epoch [1/1], Step [123/245], Loss: 1.6936\n",
      "Epoch [1/1], Step [124/245], Loss: 1.6913\n",
      "Epoch [1/1], Step [125/245], Loss: 1.6346\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7415\n",
      "Epoch [1/1], Step [127/245], Loss: 1.6203\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7041\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7930\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7836\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6779\n",
      "Epoch [1/1], Step [132/245], Loss: 1.8265\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6872\n",
      "Epoch [1/1], Step [134/245], Loss: 1.8153\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6197\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7273\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7923\n",
      "Epoch [1/1], Step [138/245], Loss: 1.5590\n",
      "Epoch [1/1], Step [139/245], Loss: 1.7056\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6408\n",
      "Epoch [1/1], Step [141/245], Loss: 1.6757\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7174\n",
      "Epoch [1/1], Step [143/245], Loss: 1.6451\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6593\n",
      "Epoch [1/1], Step [145/245], Loss: 1.7571\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6310\n",
      "Epoch [1/1], Step [147/245], Loss: 1.7046\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7252\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6688\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6531\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7720\n",
      "Epoch [1/1], Step [152/245], Loss: 1.7205\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6974\n",
      "Epoch [1/1], Step [154/245], Loss: 1.6360\n",
      "Epoch [1/1], Step [155/245], Loss: 1.5527\n",
      "Epoch [1/1], Step [156/245], Loss: 1.7016\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7475\n",
      "Epoch [1/1], Step [158/245], Loss: 1.6891\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7860\n",
      "Epoch [1/1], Step [160/245], Loss: 1.8762\n",
      "Epoch [1/1], Step [161/245], Loss: 1.5194\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6435\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6253\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6371\n",
      "Epoch [1/1], Step [165/245], Loss: 1.8456\n",
      "Epoch [1/1], Step [166/245], Loss: 1.7788\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6747\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6889\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7335\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6568\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6732\n",
      "Epoch [1/1], Step [172/245], Loss: 1.7388\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6555\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6151\n",
      "Epoch [1/1], Step [175/245], Loss: 1.7047\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6533\n",
      "Epoch [1/1], Step [177/245], Loss: 1.7286\n",
      "Epoch [1/1], Step [178/245], Loss: 1.7123\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7235\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6899\n",
      "Epoch [1/1], Step [181/245], Loss: 1.6204\n",
      "Epoch [1/1], Step [182/245], Loss: 1.7155\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6949\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6383\n",
      "Epoch [1/1], Step [185/245], Loss: 1.5801\n",
      "Epoch [1/1], Step [186/245], Loss: 1.6019\n",
      "Epoch [1/1], Step [187/245], Loss: 1.7230\n",
      "Epoch [1/1], Step [188/245], Loss: 1.7156\n",
      "Epoch [1/1], Step [189/245], Loss: 1.5623\n",
      "Epoch [1/1], Step [190/245], Loss: 1.6067\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6674\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6534\n",
      "Epoch [1/1], Step [193/245], Loss: 1.7008\n",
      "Epoch [1/1], Step [194/245], Loss: 1.5903\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6174\n",
      "Epoch [1/1], Step [196/245], Loss: 1.5996\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6216\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6453\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6339\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6673\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6113\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6664\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6704\n",
      "Epoch [1/1], Step [204/245], Loss: 1.6752\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6546\n",
      "Epoch [1/1], Step [206/245], Loss: 1.7576\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7283\n",
      "Epoch [1/1], Step [208/245], Loss: 1.5969\n",
      "Epoch [1/1], Step [209/245], Loss: 1.8728\n",
      "Epoch [1/1], Step [210/245], Loss: 1.7116\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6564\n",
      "Epoch [1/1], Step [212/245], Loss: 1.6959\n",
      "Epoch [1/1], Step [213/245], Loss: 1.7080\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6781\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6200\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7105\n",
      "Epoch [1/1], Step [217/245], Loss: 1.5507\n",
      "Epoch [1/1], Step [218/245], Loss: 1.8383\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6185\n",
      "Epoch [1/1], Step [220/245], Loss: 1.6021\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6531\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5717\n",
      "Epoch [1/1], Step [223/245], Loss: 1.4599\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7779\n",
      "Epoch [1/1], Step [225/245], Loss: 1.6132\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6012\n",
      "Epoch [1/1], Step [227/245], Loss: 1.6072\n",
      "Epoch [1/1], Step [228/245], Loss: 1.7559\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6750\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6372\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6774\n",
      "Epoch [1/1], Step [232/245], Loss: 1.5593\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5330\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6369\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6917\n",
      "Epoch [1/1], Step [236/245], Loss: 1.5276\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5023\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6131\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6093\n",
      "Epoch [1/1], Step [240/245], Loss: 1.5844\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6806\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5733\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6673\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6664\n",
      "Epoch [1/1], Step [245/245], Loss: 1.6566\n",
      "Train accuracy is: 36.51632653061225 %\n",
      "Validation accuracy is: 42.7 %\n"
     ]
    }
   ],
   "source": [
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.train import train\n",
    "from client.utils import weights_init, update_lr\n",
    "\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n",
    "\n",
    "model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "print(model)\n",
    "modelname = 'ml_model2'\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "# Training\n",
    "model.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model, modelpath, modelname, dataloaders, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 40.8 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "best_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "best_model = torch.load(pjoin(modelpath, modelname + '.ckpt'))\n",
    "model.load_state_dict(best_model)\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blockchain and FL code \n",
    "TODO remove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the saved model to Fabric-SDK via Gateway Client (REST call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Model submitted succesfully'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "# best_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "# best_model = torch.load(pjoin(modelpath, 'model.ckpt'))\n",
    "# model.load_state_dict(best_model)\n",
    "\n",
    "submit_local_model('ml_model2', model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve future global model and convert it again to pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "154160\n",
      "154160\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os.path import join as pjoin\n",
    "import json\n",
    "from client.services.gateway_client import submit_local_model, get_all_models, get_model\n",
    "from client.utils import load_model_from_json, count_parameters, compare_models\n",
    "\n",
    "\n",
    "local_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "local_model = torch.load(pjoin(modelpath,  'ml_model2.ckpt'))\n",
    "model.load_state_dict(local_model)\n",
    "\n",
    "model_params = get_model('ml_model2')\n",
    "# print(client_response)\n",
    "\n",
    "\n",
    "bc_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "bc_model.to(device)\n",
    "# print(bc_model)\n",
    "\n",
    "load_model_from_json(bc_model, model_params)\n",
    "print(bc_model)\n",
    "print(count_parameters(model))\n",
    "print(count_parameters(bc_model))\n",
    "print(compare_models(model, bc_model))\n",
    "# for parameter in model.parameters():\n",
    "#     print(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 40.8 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "test_model = bc_model\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = test_model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample neural network code that checks if the tensors and model are running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "# Instantiate the model (on the default device\n",
    "model = Perceptron(n_features).to('cuda')\n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    start_event.record()\n",
    "    outputs = model(dummy_inputs)  # Forward pass\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "    print(f\"Elapsed time (in milliseconds): {elapsed_time_ms}\")\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
