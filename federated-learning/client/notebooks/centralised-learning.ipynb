{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n",
      "Using device: cuda\n",
      "Cuda set as default device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a sample Perceptron to try the blockchain integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc.weight \t torch.Size([1, 10])\n",
      "fc.bias \t torch.Size([1])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]\n",
      "cuda:0\n",
      "Epoch 0, Loss: 0.7856053113937378\n",
      "Epoch 1, Loss: 0.7848466038703918\n",
      "Epoch 2, Loss: 0.7840920686721802\n",
      "Epoch 3, Loss: 0.7833415269851685\n",
      "Epoch 4, Loss: 0.7825950384140015\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# torch.set_default_device('cpu')\n",
    "\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "num_classes = 1  # Example number of classes\n",
    "# model = Perceptron(n_features, num_classes)  # Instantiate the model (on the default device\n",
    "model = Perceptron(n_features)  # Instantiate the model (on the default device\n",
    "\n",
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "    \n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "    \n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    outputs = model(dummy_inputs)  # Forward pass\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading CIFAR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3016\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2952\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2841\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2660\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2646\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2366\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2292\n",
      "Epoch [1/1], Step [9/245], Loss: 2.2277\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1804\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1678\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1297\n",
      "Epoch [1/1], Step [13/245], Loss: 2.1010\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1641\n",
      "Epoch [1/1], Step [15/245], Loss: 2.0933\n",
      "Epoch [1/1], Step [16/245], Loss: 2.1161\n",
      "Epoch [1/1], Step [17/245], Loss: 2.0117\n",
      "Epoch [1/1], Step [18/245], Loss: 1.9915\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0184\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0849\n",
      "Epoch [1/1], Step [21/245], Loss: 1.9209\n",
      "Epoch [1/1], Step [22/245], Loss: 2.0141\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0970\n",
      "Epoch [1/1], Step [24/245], Loss: 1.9083\n",
      "Epoch [1/1], Step [25/245], Loss: 1.9209\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9716\n",
      "Epoch [1/1], Step [27/245], Loss: 2.0031\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9680\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9121\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9543\n",
      "Epoch [1/1], Step [31/245], Loss: 1.8778\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9462\n",
      "Epoch [1/1], Step [33/245], Loss: 1.8830\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9599\n",
      "Epoch [1/1], Step [35/245], Loss: 1.8120\n",
      "Epoch [1/1], Step [36/245], Loss: 2.0224\n",
      "Epoch [1/1], Step [37/245], Loss: 1.9450\n",
      "Epoch [1/1], Step [38/245], Loss: 1.8203\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8854\n",
      "Epoch [1/1], Step [40/245], Loss: 1.9233\n",
      "Epoch [1/1], Step [41/245], Loss: 1.8212\n",
      "Epoch [1/1], Step [42/245], Loss: 1.8813\n",
      "Epoch [1/1], Step [43/245], Loss: 1.9324\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8940\n",
      "Epoch [1/1], Step [45/245], Loss: 1.9614\n",
      "Epoch [1/1], Step [46/245], Loss: 1.8946\n",
      "Epoch [1/1], Step [47/245], Loss: 1.9080\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8641\n",
      "Epoch [1/1], Step [49/245], Loss: 1.9301\n",
      "Epoch [1/1], Step [50/245], Loss: 1.9193\n",
      "Epoch [1/1], Step [51/245], Loss: 1.8829\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8606\n",
      "Epoch [1/1], Step [53/245], Loss: 1.8319\n",
      "Epoch [1/1], Step [54/245], Loss: 1.9731\n",
      "Epoch [1/1], Step [55/245], Loss: 1.9200\n",
      "Epoch [1/1], Step [56/245], Loss: 1.8014\n",
      "Epoch [1/1], Step [57/245], Loss: 1.8955\n",
      "Epoch [1/1], Step [58/245], Loss: 1.8491\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8380\n",
      "Epoch [1/1], Step [60/245], Loss: 1.7982\n",
      "Epoch [1/1], Step [61/245], Loss: 1.8964\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8891\n",
      "Epoch [1/1], Step [63/245], Loss: 1.7768\n",
      "Epoch [1/1], Step [64/245], Loss: 1.8688\n",
      "Epoch [1/1], Step [65/245], Loss: 1.7766\n",
      "Epoch [1/1], Step [66/245], Loss: 1.7566\n",
      "Epoch [1/1], Step [67/245], Loss: 1.7984\n",
      "Epoch [1/1], Step [68/245], Loss: 1.9372\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7773\n",
      "Epoch [1/1], Step [70/245], Loss: 1.8189\n",
      "Epoch [1/1], Step [71/245], Loss: 1.8139\n",
      "Epoch [1/1], Step [72/245], Loss: 1.8233\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8175\n",
      "Epoch [1/1], Step [74/245], Loss: 1.6845\n",
      "Epoch [1/1], Step [75/245], Loss: 1.7573\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7369\n",
      "Epoch [1/1], Step [77/245], Loss: 1.8419\n",
      "Epoch [1/1], Step [78/245], Loss: 1.8109\n",
      "Epoch [1/1], Step [79/245], Loss: 1.8505\n",
      "Epoch [1/1], Step [80/245], Loss: 1.6913\n",
      "Epoch [1/1], Step [81/245], Loss: 1.7074\n",
      "Epoch [1/1], Step [82/245], Loss: 1.7941\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7198\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7527\n",
      "Epoch [1/1], Step [85/245], Loss: 1.8008\n",
      "Epoch [1/1], Step [86/245], Loss: 1.8134\n",
      "Epoch [1/1], Step [87/245], Loss: 1.8610\n",
      "Epoch [1/1], Step [88/245], Loss: 1.8217\n",
      "Epoch [1/1], Step [89/245], Loss: 1.7407\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7638\n",
      "Epoch [1/1], Step [91/245], Loss: 1.6648\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7113\n",
      "Epoch [1/1], Step [93/245], Loss: 1.6213\n",
      "Epoch [1/1], Step [94/245], Loss: 1.8016\n",
      "Epoch [1/1], Step [95/245], Loss: 1.8496\n",
      "Epoch [1/1], Step [96/245], Loss: 1.8056\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7218\n",
      "Epoch [1/1], Step [98/245], Loss: 1.8311\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7812\n",
      "Epoch [1/1], Step [100/245], Loss: 1.7263\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7815\n",
      "Epoch [1/1], Step [102/245], Loss: 1.7542\n",
      "Epoch [1/1], Step [103/245], Loss: 1.7105\n",
      "Epoch [1/1], Step [104/245], Loss: 1.7842\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7153\n",
      "Epoch [1/1], Step [106/245], Loss: 1.7362\n",
      "Epoch [1/1], Step [107/245], Loss: 1.7860\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6915\n",
      "Epoch [1/1], Step [109/245], Loss: 1.6947\n",
      "Epoch [1/1], Step [110/245], Loss: 1.6885\n",
      "Epoch [1/1], Step [111/245], Loss: 1.8681\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7567\n",
      "Epoch [1/1], Step [113/245], Loss: 1.6161\n",
      "Epoch [1/1], Step [114/245], Loss: 1.7643\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6845\n",
      "Epoch [1/1], Step [116/245], Loss: 1.8107\n",
      "Epoch [1/1], Step [117/245], Loss: 1.7008\n",
      "Epoch [1/1], Step [118/245], Loss: 1.8020\n",
      "Epoch [1/1], Step [119/245], Loss: 1.7542\n",
      "Epoch [1/1], Step [120/245], Loss: 1.7610\n",
      "Epoch [1/1], Step [121/245], Loss: 1.7508\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7311\n",
      "Epoch [1/1], Step [123/245], Loss: 1.6879\n",
      "Epoch [1/1], Step [124/245], Loss: 1.6721\n",
      "Epoch [1/1], Step [125/245], Loss: 1.6372\n",
      "Epoch [1/1], Step [126/245], Loss: 1.7403\n",
      "Epoch [1/1], Step [127/245], Loss: 1.6217\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7056\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7804\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7797\n",
      "Epoch [1/1], Step [131/245], Loss: 1.6761\n",
      "Epoch [1/1], Step [132/245], Loss: 1.8165\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6742\n",
      "Epoch [1/1], Step [134/245], Loss: 1.8238\n",
      "Epoch [1/1], Step [135/245], Loss: 1.6243\n",
      "Epoch [1/1], Step [136/245], Loss: 1.7162\n",
      "Epoch [1/1], Step [137/245], Loss: 1.7858\n",
      "Epoch [1/1], Step [138/245], Loss: 1.5575\n",
      "Epoch [1/1], Step [139/245], Loss: 1.6939\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6480\n",
      "Epoch [1/1], Step [141/245], Loss: 1.6592\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7228\n",
      "Epoch [1/1], Step [143/245], Loss: 1.6500\n",
      "Epoch [1/1], Step [144/245], Loss: 1.6588\n",
      "Epoch [1/1], Step [145/245], Loss: 1.7703\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6295\n",
      "Epoch [1/1], Step [147/245], Loss: 1.6897\n",
      "Epoch [1/1], Step [148/245], Loss: 1.7286\n",
      "Epoch [1/1], Step [149/245], Loss: 1.6666\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6617\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7643\n",
      "Epoch [1/1], Step [152/245], Loss: 1.7220\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6863\n",
      "Epoch [1/1], Step [154/245], Loss: 1.6177\n",
      "Epoch [1/1], Step [155/245], Loss: 1.5316\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6940\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7269\n",
      "Epoch [1/1], Step [158/245], Loss: 1.7115\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7823\n",
      "Epoch [1/1], Step [160/245], Loss: 1.8779\n",
      "Epoch [1/1], Step [161/245], Loss: 1.5174\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6295\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6224\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6328\n",
      "Epoch [1/1], Step [165/245], Loss: 1.8381\n",
      "Epoch [1/1], Step [166/245], Loss: 1.7774\n",
      "Epoch [1/1], Step [167/245], Loss: 1.6713\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6907\n",
      "Epoch [1/1], Step [169/245], Loss: 1.7299\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6646\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6695\n",
      "Epoch [1/1], Step [172/245], Loss: 1.7067\n",
      "Epoch [1/1], Step [173/245], Loss: 1.6507\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6244\n",
      "Epoch [1/1], Step [175/245], Loss: 1.6951\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6508\n",
      "Epoch [1/1], Step [177/245], Loss: 1.7038\n",
      "Epoch [1/1], Step [178/245], Loss: 1.6932\n",
      "Epoch [1/1], Step [179/245], Loss: 1.7303\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6931\n",
      "Epoch [1/1], Step [181/245], Loss: 1.6193\n",
      "Epoch [1/1], Step [182/245], Loss: 1.6956\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6825\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6461\n",
      "Epoch [1/1], Step [185/245], Loss: 1.5853\n",
      "Epoch [1/1], Step [186/245], Loss: 1.5822\n",
      "Epoch [1/1], Step [187/245], Loss: 1.7266\n",
      "Epoch [1/1], Step [188/245], Loss: 1.7208\n",
      "Epoch [1/1], Step [189/245], Loss: 1.5560\n",
      "Epoch [1/1], Step [190/245], Loss: 1.5868\n",
      "Epoch [1/1], Step [191/245], Loss: 1.6718\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6550\n",
      "Epoch [1/1], Step [193/245], Loss: 1.6864\n",
      "Epoch [1/1], Step [194/245], Loss: 1.5539\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6190\n",
      "Epoch [1/1], Step [196/245], Loss: 1.5862\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6302\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6741\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6327\n",
      "Epoch [1/1], Step [200/245], Loss: 1.6675\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6087\n",
      "Epoch [1/1], Step [202/245], Loss: 1.6613\n",
      "Epoch [1/1], Step [203/245], Loss: 1.6657\n",
      "Epoch [1/1], Step [204/245], Loss: 1.6863\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6375\n",
      "Epoch [1/1], Step [206/245], Loss: 1.7534\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7209\n",
      "Epoch [1/1], Step [208/245], Loss: 1.5853\n",
      "Epoch [1/1], Step [209/245], Loss: 1.8760\n",
      "Epoch [1/1], Step [210/245], Loss: 1.7052\n",
      "Epoch [1/1], Step [211/245], Loss: 1.6579\n",
      "Epoch [1/1], Step [212/245], Loss: 1.7091\n",
      "Epoch [1/1], Step [213/245], Loss: 1.6900\n",
      "Epoch [1/1], Step [214/245], Loss: 1.6761\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6098\n",
      "Epoch [1/1], Step [216/245], Loss: 1.7194\n",
      "Epoch [1/1], Step [217/245], Loss: 1.5741\n",
      "Epoch [1/1], Step [218/245], Loss: 1.8353\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6066\n",
      "Epoch [1/1], Step [220/245], Loss: 1.6232\n",
      "Epoch [1/1], Step [221/245], Loss: 1.6506\n",
      "Epoch [1/1], Step [222/245], Loss: 1.5810\n",
      "Epoch [1/1], Step [223/245], Loss: 1.4486\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7769\n",
      "Epoch [1/1], Step [225/245], Loss: 1.6250\n",
      "Epoch [1/1], Step [226/245], Loss: 1.6031\n",
      "Epoch [1/1], Step [227/245], Loss: 1.6276\n",
      "Epoch [1/1], Step [228/245], Loss: 1.7709\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6954\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6498\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6816\n",
      "Epoch [1/1], Step [232/245], Loss: 1.5589\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5308\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6511\n",
      "Epoch [1/1], Step [235/245], Loss: 1.6863\n",
      "Epoch [1/1], Step [236/245], Loss: 1.5229\n",
      "Epoch [1/1], Step [237/245], Loss: 1.5066\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6003\n",
      "Epoch [1/1], Step [239/245], Loss: 1.6184\n",
      "Epoch [1/1], Step [240/245], Loss: 1.5945\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6917\n",
      "Epoch [1/1], Step [242/245], Loss: 1.5729\n",
      "Epoch [1/1], Step [243/245], Loss: 1.6576\n",
      "Epoch [1/1], Step [244/245], Loss: 1.6604\n",
      "Epoch [1/1], Step [245/245], Loss: 1.6560\n",
      "Train accuracy is: 36.779591836734696 %\n",
      "Validation accuracy is: 43.1 %\n"
     ]
    }
   ],
   "source": [
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.train import train\n",
    "from client.utils import weights_init, update_lr\n",
    "\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n",
    "\n",
    "model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "# Training\n",
    "model.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model, dataloaders, modelpath, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 41.5 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "best_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "best_model = torch.load(pjoin(modelpath, 'model.ckpt'))\n",
    "model.load_state_dict(best_model)\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the saved model to Fabric-SDK via Gateway Client (REST call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Error creating model',\n",
       " 'error': '8 RESOURCE_EXHAUSTED: Received message larger than max (6578059 vs. 4194304)'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "from client.services.gateway_client import submit_local_model\n",
    "\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "best_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "best_model = torch.load(pjoin(modelpath, 'model.ckpt'))\n",
    "model.load_state_dict(best_model)\n",
    "\n",
    "submit_local_model(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample neural network code that checks if the tensors and model are running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Elapsed time (in milliseconds): 0.2836480140686035\n",
      "Epoch 0, Loss: 0.7509689331054688\n",
      "Elapsed time (in milliseconds): 0.23996800184249878\n",
      "Epoch 1, Loss: 0.7505505681037903\n",
      "Elapsed time (in milliseconds): 0.1724800020456314\n",
      "Epoch 2, Loss: 0.7501339316368103\n",
      "Elapsed time (in milliseconds): 0.151296004652977\n",
      "Epoch 3, Loss: 0.7497190833091736\n",
      "Elapsed time (in milliseconds): 0.11884800344705582\n",
      "Epoch 4, Loss: 0.7493058443069458\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "# Instantiate the model (on the default device\n",
    "model = Perceptron(n_features).to('cuda')\n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    start_event.record()\n",
    "    outputs = model(dummy_inputs)  # Forward pass\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "    print(f\"Elapsed time (in milliseconds): {elapsed_time_ms}\")\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
