{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n",
      "Using device: cuda\n",
      "Cuda set as default device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available and set the default tensor type to CUDA\n",
    "print('Using device: %s' % device)\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device('cuda')\n",
    "    print(\"Cuda set as default device\")\n",
    "else:\n",
    "    torch.set_default_device('cpu')\n",
    "    print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a sample Perceptron to try the blockchain integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 0, Loss: 0.696426510810852\n",
      "Epoch 1, Loss: 0.6962855458259583\n",
      "Epoch 2, Loss: 0.6961452960968018\n",
      "Epoch 3, Loss: 0.6960055232048035\n",
      "Epoch 4, Loss: 0.6958665251731873\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "# torch.set_default_device('cpu')\n",
    "\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "num_classes = 1  # Example number of classes\n",
    "# model = Perceptron(n_features, num_classes)  # Instantiate the model (on the default device\n",
    "model = Perceptron(n_features)  # Instantiate the model (on the default device\n",
    "\n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    outputs = model(dummy_inputs)  # Forward pass\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading CIFAR DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from client.dataloader import get_cifar10_dataloaders, get_cifar10_datasets\n",
    "\n",
    "root = 'client/data/'\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "batch_size = 200\n",
    "train_dataset, val_dataset, test_dataset = get_cifar10_datasets(\n",
    "    root, num_training, num_validation)\n",
    "train_loader, val_loader, test_loader = get_cifar10_dataloaders(\n",
    "    root, batch_size, num_training, num_validation, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptron(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/1], Step [1/245], Loss: 2.3026\n",
      "Epoch [1/1], Step [2/245], Loss: 2.3003\n",
      "Epoch [1/1], Step [3/245], Loss: 2.2937\n",
      "Epoch [1/1], Step [4/245], Loss: 2.2779\n",
      "Epoch [1/1], Step [5/245], Loss: 2.2734\n",
      "Epoch [1/1], Step [6/245], Loss: 2.2475\n",
      "Epoch [1/1], Step [7/245], Loss: 2.2168\n",
      "Epoch [1/1], Step [8/245], Loss: 2.2045\n",
      "Epoch [1/1], Step [9/245], Loss: 2.1962\n",
      "Epoch [1/1], Step [10/245], Loss: 2.1794\n",
      "Epoch [1/1], Step [11/245], Loss: 2.1506\n",
      "Epoch [1/1], Step [12/245], Loss: 2.1901\n",
      "Epoch [1/1], Step [13/245], Loss: 2.1110\n",
      "Epoch [1/1], Step [14/245], Loss: 2.1609\n",
      "Epoch [1/1], Step [15/245], Loss: 2.1014\n",
      "Epoch [1/1], Step [16/245], Loss: 2.0721\n",
      "Epoch [1/1], Step [17/245], Loss: 2.0700\n",
      "Epoch [1/1], Step [18/245], Loss: 2.0313\n",
      "Epoch [1/1], Step [19/245], Loss: 2.0194\n",
      "Epoch [1/1], Step [20/245], Loss: 2.0380\n",
      "Epoch [1/1], Step [21/245], Loss: 1.9871\n",
      "Epoch [1/1], Step [22/245], Loss: 1.9960\n",
      "Epoch [1/1], Step [23/245], Loss: 2.0422\n",
      "Epoch [1/1], Step [24/245], Loss: 2.0081\n",
      "Epoch [1/1], Step [25/245], Loss: 1.9000\n",
      "Epoch [1/1], Step [26/245], Loss: 1.9709\n",
      "Epoch [1/1], Step [27/245], Loss: 1.9681\n",
      "Epoch [1/1], Step [28/245], Loss: 1.9724\n",
      "Epoch [1/1], Step [29/245], Loss: 1.9864\n",
      "Epoch [1/1], Step [30/245], Loss: 1.9322\n",
      "Epoch [1/1], Step [31/245], Loss: 1.9553\n",
      "Epoch [1/1], Step [32/245], Loss: 1.9684\n",
      "Epoch [1/1], Step [33/245], Loss: 1.9509\n",
      "Epoch [1/1], Step [34/245], Loss: 1.9612\n",
      "Epoch [1/1], Step [35/245], Loss: 2.0077\n",
      "Epoch [1/1], Step [36/245], Loss: 1.9094\n",
      "Epoch [1/1], Step [37/245], Loss: 1.8241\n",
      "Epoch [1/1], Step [38/245], Loss: 1.8570\n",
      "Epoch [1/1], Step [39/245], Loss: 1.8571\n",
      "Epoch [1/1], Step [40/245], Loss: 1.8684\n",
      "Epoch [1/1], Step [41/245], Loss: 1.9122\n",
      "Epoch [1/1], Step [42/245], Loss: 1.9274\n",
      "Epoch [1/1], Step [43/245], Loss: 1.8366\n",
      "Epoch [1/1], Step [44/245], Loss: 1.8010\n",
      "Epoch [1/1], Step [45/245], Loss: 1.7947\n",
      "Epoch [1/1], Step [46/245], Loss: 1.9885\n",
      "Epoch [1/1], Step [47/245], Loss: 1.8951\n",
      "Epoch [1/1], Step [48/245], Loss: 1.8621\n",
      "Epoch [1/1], Step [49/245], Loss: 1.8605\n",
      "Epoch [1/1], Step [50/245], Loss: 1.9857\n",
      "Epoch [1/1], Step [51/245], Loss: 1.7820\n",
      "Epoch [1/1], Step [52/245], Loss: 1.8956\n",
      "Epoch [1/1], Step [53/245], Loss: 1.9125\n",
      "Epoch [1/1], Step [54/245], Loss: 1.8870\n",
      "Epoch [1/1], Step [55/245], Loss: 1.7954\n",
      "Epoch [1/1], Step [56/245], Loss: 1.8031\n",
      "Epoch [1/1], Step [57/245], Loss: 1.8997\n",
      "Epoch [1/1], Step [58/245], Loss: 1.7823\n",
      "Epoch [1/1], Step [59/245], Loss: 1.8908\n",
      "Epoch [1/1], Step [60/245], Loss: 1.8830\n",
      "Epoch [1/1], Step [61/245], Loss: 1.7897\n",
      "Epoch [1/1], Step [62/245], Loss: 1.8641\n",
      "Epoch [1/1], Step [63/245], Loss: 1.8064\n",
      "Epoch [1/1], Step [64/245], Loss: 1.7795\n",
      "Epoch [1/1], Step [65/245], Loss: 1.8211\n",
      "Epoch [1/1], Step [66/245], Loss: 1.8209\n",
      "Epoch [1/1], Step [67/245], Loss: 1.8151\n",
      "Epoch [1/1], Step [68/245], Loss: 1.7882\n",
      "Epoch [1/1], Step [69/245], Loss: 1.7902\n",
      "Epoch [1/1], Step [70/245], Loss: 1.7342\n",
      "Epoch [1/1], Step [71/245], Loss: 1.7383\n",
      "Epoch [1/1], Step [72/245], Loss: 1.9116\n",
      "Epoch [1/1], Step [73/245], Loss: 1.8596\n",
      "Epoch [1/1], Step [74/245], Loss: 1.8174\n",
      "Epoch [1/1], Step [75/245], Loss: 1.7701\n",
      "Epoch [1/1], Step [76/245], Loss: 1.7637\n",
      "Epoch [1/1], Step [77/245], Loss: 1.7914\n",
      "Epoch [1/1], Step [78/245], Loss: 1.7355\n",
      "Epoch [1/1], Step [79/245], Loss: 1.6787\n",
      "Epoch [1/1], Step [80/245], Loss: 1.7241\n",
      "Epoch [1/1], Step [81/245], Loss: 1.8939\n",
      "Epoch [1/1], Step [82/245], Loss: 1.8310\n",
      "Epoch [1/1], Step [83/245], Loss: 1.7545\n",
      "Epoch [1/1], Step [84/245], Loss: 1.7317\n",
      "Epoch [1/1], Step [85/245], Loss: 1.8213\n",
      "Epoch [1/1], Step [86/245], Loss: 1.7271\n",
      "Epoch [1/1], Step [87/245], Loss: 1.7331\n",
      "Epoch [1/1], Step [88/245], Loss: 1.8890\n",
      "Epoch [1/1], Step [89/245], Loss: 1.7639\n",
      "Epoch [1/1], Step [90/245], Loss: 1.7784\n",
      "Epoch [1/1], Step [91/245], Loss: 1.7019\n",
      "Epoch [1/1], Step [92/245], Loss: 1.7308\n",
      "Epoch [1/1], Step [93/245], Loss: 1.7172\n",
      "Epoch [1/1], Step [94/245], Loss: 1.7878\n",
      "Epoch [1/1], Step [95/245], Loss: 1.6764\n",
      "Epoch [1/1], Step [96/245], Loss: 1.6889\n",
      "Epoch [1/1], Step [97/245], Loss: 1.7550\n",
      "Epoch [1/1], Step [98/245], Loss: 1.7044\n",
      "Epoch [1/1], Step [99/245], Loss: 1.7791\n",
      "Epoch [1/1], Step [100/245], Loss: 1.8435\n",
      "Epoch [1/1], Step [101/245], Loss: 1.7247\n",
      "Epoch [1/1], Step [102/245], Loss: 1.6706\n",
      "Epoch [1/1], Step [103/245], Loss: 1.6908\n",
      "Epoch [1/1], Step [104/245], Loss: 1.6858\n",
      "Epoch [1/1], Step [105/245], Loss: 1.7016\n",
      "Epoch [1/1], Step [106/245], Loss: 1.6561\n",
      "Epoch [1/1], Step [107/245], Loss: 1.6184\n",
      "Epoch [1/1], Step [108/245], Loss: 1.6684\n",
      "Epoch [1/1], Step [109/245], Loss: 1.7955\n",
      "Epoch [1/1], Step [110/245], Loss: 1.7780\n",
      "Epoch [1/1], Step [111/245], Loss: 1.7437\n",
      "Epoch [1/1], Step [112/245], Loss: 1.7017\n",
      "Epoch [1/1], Step [113/245], Loss: 1.6652\n",
      "Epoch [1/1], Step [114/245], Loss: 1.8039\n",
      "Epoch [1/1], Step [115/245], Loss: 1.6916\n",
      "Epoch [1/1], Step [116/245], Loss: 1.7818\n",
      "Epoch [1/1], Step [117/245], Loss: 1.6096\n",
      "Epoch [1/1], Step [118/245], Loss: 1.7739\n",
      "Epoch [1/1], Step [119/245], Loss: 1.8513\n",
      "Epoch [1/1], Step [120/245], Loss: 1.8105\n",
      "Epoch [1/1], Step [121/245], Loss: 1.8064\n",
      "Epoch [1/1], Step [122/245], Loss: 1.7433\n",
      "Epoch [1/1], Step [123/245], Loss: 1.7185\n",
      "Epoch [1/1], Step [124/245], Loss: 1.7803\n",
      "Epoch [1/1], Step [125/245], Loss: 1.6804\n",
      "Epoch [1/1], Step [126/245], Loss: 1.5609\n",
      "Epoch [1/1], Step [127/245], Loss: 1.6337\n",
      "Epoch [1/1], Step [128/245], Loss: 1.7249\n",
      "Epoch [1/1], Step [129/245], Loss: 1.7558\n",
      "Epoch [1/1], Step [130/245], Loss: 1.7672\n",
      "Epoch [1/1], Step [131/245], Loss: 1.7732\n",
      "Epoch [1/1], Step [132/245], Loss: 1.5855\n",
      "Epoch [1/1], Step [133/245], Loss: 1.6708\n",
      "Epoch [1/1], Step [134/245], Loss: 1.7346\n",
      "Epoch [1/1], Step [135/245], Loss: 1.7485\n",
      "Epoch [1/1], Step [136/245], Loss: 1.6997\n",
      "Epoch [1/1], Step [137/245], Loss: 1.6337\n",
      "Epoch [1/1], Step [138/245], Loss: 1.6929\n",
      "Epoch [1/1], Step [139/245], Loss: 1.7081\n",
      "Epoch [1/1], Step [140/245], Loss: 1.6504\n",
      "Epoch [1/1], Step [141/245], Loss: 1.7322\n",
      "Epoch [1/1], Step [142/245], Loss: 1.7299\n",
      "Epoch [1/1], Step [143/245], Loss: 1.7439\n",
      "Epoch [1/1], Step [144/245], Loss: 1.7528\n",
      "Epoch [1/1], Step [145/245], Loss: 1.6222\n",
      "Epoch [1/1], Step [146/245], Loss: 1.6657\n",
      "Epoch [1/1], Step [147/245], Loss: 1.6639\n",
      "Epoch [1/1], Step [148/245], Loss: 1.5766\n",
      "Epoch [1/1], Step [149/245], Loss: 1.7933\n",
      "Epoch [1/1], Step [150/245], Loss: 1.6600\n",
      "Epoch [1/1], Step [151/245], Loss: 1.7443\n",
      "Epoch [1/1], Step [152/245], Loss: 1.6728\n",
      "Epoch [1/1], Step [153/245], Loss: 1.6378\n",
      "Epoch [1/1], Step [154/245], Loss: 1.5510\n",
      "Epoch [1/1], Step [155/245], Loss: 1.6911\n",
      "Epoch [1/1], Step [156/245], Loss: 1.6137\n",
      "Epoch [1/1], Step [157/245], Loss: 1.7904\n",
      "Epoch [1/1], Step [158/245], Loss: 1.7004\n",
      "Epoch [1/1], Step [159/245], Loss: 1.7373\n",
      "Epoch [1/1], Step [160/245], Loss: 1.7367\n",
      "Epoch [1/1], Step [161/245], Loss: 1.7408\n",
      "Epoch [1/1], Step [162/245], Loss: 1.6068\n",
      "Epoch [1/1], Step [163/245], Loss: 1.6811\n",
      "Epoch [1/1], Step [164/245], Loss: 1.6601\n",
      "Epoch [1/1], Step [165/245], Loss: 1.5863\n",
      "Epoch [1/1], Step [166/245], Loss: 1.6783\n",
      "Epoch [1/1], Step [167/245], Loss: 1.7331\n",
      "Epoch [1/1], Step [168/245], Loss: 1.6066\n",
      "Epoch [1/1], Step [169/245], Loss: 1.6471\n",
      "Epoch [1/1], Step [170/245], Loss: 1.6097\n",
      "Epoch [1/1], Step [171/245], Loss: 1.6792\n",
      "Epoch [1/1], Step [172/245], Loss: 1.5392\n",
      "Epoch [1/1], Step [173/245], Loss: 1.7373\n",
      "Epoch [1/1], Step [174/245], Loss: 1.6339\n",
      "Epoch [1/1], Step [175/245], Loss: 1.7292\n",
      "Epoch [1/1], Step [176/245], Loss: 1.6850\n",
      "Epoch [1/1], Step [177/245], Loss: 1.6352\n",
      "Epoch [1/1], Step [178/245], Loss: 1.6847\n",
      "Epoch [1/1], Step [179/245], Loss: 1.6912\n",
      "Epoch [1/1], Step [180/245], Loss: 1.6141\n",
      "Epoch [1/1], Step [181/245], Loss: 1.7126\n",
      "Epoch [1/1], Step [182/245], Loss: 1.6547\n",
      "Epoch [1/1], Step [183/245], Loss: 1.6639\n",
      "Epoch [1/1], Step [184/245], Loss: 1.6044\n",
      "Epoch [1/1], Step [185/245], Loss: 1.6398\n",
      "Epoch [1/1], Step [186/245], Loss: 1.6520\n",
      "Epoch [1/1], Step [187/245], Loss: 1.6895\n",
      "Epoch [1/1], Step [188/245], Loss: 1.8555\n",
      "Epoch [1/1], Step [189/245], Loss: 1.6553\n",
      "Epoch [1/1], Step [190/245], Loss: 1.5954\n",
      "Epoch [1/1], Step [191/245], Loss: 1.7333\n",
      "Epoch [1/1], Step [192/245], Loss: 1.6981\n",
      "Epoch [1/1], Step [193/245], Loss: 1.7885\n",
      "Epoch [1/1], Step [194/245], Loss: 1.7210\n",
      "Epoch [1/1], Step [195/245], Loss: 1.6871\n",
      "Epoch [1/1], Step [196/245], Loss: 1.6821\n",
      "Epoch [1/1], Step [197/245], Loss: 1.6681\n",
      "Epoch [1/1], Step [198/245], Loss: 1.6815\n",
      "Epoch [1/1], Step [199/245], Loss: 1.6662\n",
      "Epoch [1/1], Step [200/245], Loss: 1.7424\n",
      "Epoch [1/1], Step [201/245], Loss: 1.6359\n",
      "Epoch [1/1], Step [202/245], Loss: 1.7630\n",
      "Epoch [1/1], Step [203/245], Loss: 1.5393\n",
      "Epoch [1/1], Step [204/245], Loss: 1.5369\n",
      "Epoch [1/1], Step [205/245], Loss: 1.6338\n",
      "Epoch [1/1], Step [206/245], Loss: 1.6371\n",
      "Epoch [1/1], Step [207/245], Loss: 1.7078\n",
      "Epoch [1/1], Step [208/245], Loss: 1.6787\n",
      "Epoch [1/1], Step [209/245], Loss: 1.5810\n",
      "Epoch [1/1], Step [210/245], Loss: 1.6027\n",
      "Epoch [1/1], Step [211/245], Loss: 1.7526\n",
      "Epoch [1/1], Step [212/245], Loss: 1.7600\n",
      "Epoch [1/1], Step [213/245], Loss: 1.7892\n",
      "Epoch [1/1], Step [214/245], Loss: 1.7414\n",
      "Epoch [1/1], Step [215/245], Loss: 1.6409\n",
      "Epoch [1/1], Step [216/245], Loss: 1.5399\n",
      "Epoch [1/1], Step [217/245], Loss: 1.6763\n",
      "Epoch [1/1], Step [218/245], Loss: 1.5827\n",
      "Epoch [1/1], Step [219/245], Loss: 1.6400\n",
      "Epoch [1/1], Step [220/245], Loss: 1.6926\n",
      "Epoch [1/1], Step [221/245], Loss: 1.7150\n",
      "Epoch [1/1], Step [222/245], Loss: 1.7549\n",
      "Epoch [1/1], Step [223/245], Loss: 1.7466\n",
      "Epoch [1/1], Step [224/245], Loss: 1.7315\n",
      "Epoch [1/1], Step [225/245], Loss: 1.5988\n",
      "Epoch [1/1], Step [226/245], Loss: 1.7065\n",
      "Epoch [1/1], Step [227/245], Loss: 1.7052\n",
      "Epoch [1/1], Step [228/245], Loss: 1.6830\n",
      "Epoch [1/1], Step [229/245], Loss: 1.6014\n",
      "Epoch [1/1], Step [230/245], Loss: 1.6133\n",
      "Epoch [1/1], Step [231/245], Loss: 1.6400\n",
      "Epoch [1/1], Step [232/245], Loss: 1.7132\n",
      "Epoch [1/1], Step [233/245], Loss: 1.5622\n",
      "Epoch [1/1], Step [234/245], Loss: 1.6071\n",
      "Epoch [1/1], Step [235/245], Loss: 1.7145\n",
      "Epoch [1/1], Step [236/245], Loss: 1.6802\n",
      "Epoch [1/1], Step [237/245], Loss: 1.6524\n",
      "Epoch [1/1], Step [238/245], Loss: 1.6498\n",
      "Epoch [1/1], Step [239/245], Loss: 1.7257\n",
      "Epoch [1/1], Step [240/245], Loss: 1.6457\n",
      "Epoch [1/1], Step [241/245], Loss: 1.6775\n",
      "Epoch [1/1], Step [242/245], Loss: 1.7352\n",
      "Epoch [1/1], Step [243/245], Loss: 1.5314\n",
      "Epoch [1/1], Step [244/245], Loss: 1.5802\n",
      "Epoch [1/1], Step [245/245], Loss: 1.5841\n",
      "Train accuracy is: 36.589795918367344 %\n",
      "Validation accuracy is: 43.9 %\n"
     ]
    }
   ],
   "source": [
    "from client.model.perceptron import MultiLayerPerceptron\n",
    "from client.train import train\n",
    "from client.utils import weights_init, update_lr\n",
    "\n",
    "\n",
    "input_size = 32 * 32 * 3\n",
    "hidden_size = [50]\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "learning_rate_decay = 0.95\n",
    "reg = 0.001\n",
    "modelpath = 'client/models/'\n",
    "train_flag = True\n",
    "\n",
    "model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_loader,\n",
    "    'validation': val_loader,\n",
    "    'test': test_loader\n",
    "}\n",
    "\n",
    "# Training\n",
    "model.apply(weights_init)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "\n",
    "train(model, dataloaders, modelpath, criterion, optimizer,\n",
    "      learning_rate, learning_rate_decay, input_size, num_epochs, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 test images: 41.8 %\n"
     ]
    }
   ],
   "source": [
    "from os.path import join as pjoin\n",
    "modelpath = 'client/models/'\n",
    "\n",
    "# Run the test code once you have your by setting train flag to false\n",
    "# and loading the best model\n",
    "best_model = MultiLayerPerceptron(input_size, hidden_size, num_classes)\n",
    "best_model = torch.load(pjoin(modelpath, 'model.ckpt'))\n",
    "model.load_state_dict(best_model)\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        ####################################################\n",
    "\n",
    "        # reshape images to input size\n",
    "        images = images.reshape(-1, input_size).to(device)\n",
    "        # set the model for evaluation\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        if total == 1000:\n",
    "            break\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(\n",
    "        total, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample neural network code that checks if the tensors and model are running on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Elapsed time (in milliseconds): 0.2836480140686035\n",
      "Epoch 0, Loss: 0.7509689331054688\n",
      "Elapsed time (in milliseconds): 0.23996800184249878\n",
      "Epoch 1, Loss: 0.7505505681037903\n",
      "Elapsed time (in milliseconds): 0.1724800020456314\n",
      "Epoch 2, Loss: 0.7501339316368103\n",
      "Elapsed time (in milliseconds): 0.151296004652977\n",
      "Epoch 3, Loss: 0.7497190833091736\n",
      "Elapsed time (in milliseconds): 0.11884800344705582\n",
      "Epoch 4, Loss: 0.7493058443069458\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from client.model.perceptron import Perceptron\n",
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "n_features = 10  # Example number of input features\n",
    "# Instantiate the model (on the default device\n",
    "model = Perceptron(n_features).to('cuda')\n",
    "loss_function = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# Example (dummy) training data\n",
    "dummy_inputs = torch.randn(100, n_features)  # 100 samples, n_features each\n",
    "print(dummy_inputs.device)\n",
    "# Binary target values (0 or 1)\n",
    "dummy_targets = torch.randint(0, 2, (100, 1)).float()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):  # Number of epochs\n",
    "    optimizer.zero_grad()  # Clearing the gradients\n",
    "    start_event.record()\n",
    "    outputs = model(dummy_inputs)  # Forward pass\n",
    "    end_event.record()\n",
    "    torch.cuda.synchronize()  # Wait for the events to be recorded!\n",
    "    elapsed_time_ms = start_event.elapsed_time(end_event)\n",
    "    print(f\"Elapsed time (in milliseconds): {elapsed_time_ms}\")\n",
    "    loss = loss_function(outputs, dummy_targets)  # Compute loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
