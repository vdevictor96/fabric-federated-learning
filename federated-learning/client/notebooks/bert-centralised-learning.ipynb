{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running in colaboratory\n",
    "!git clone https://github.com/vdevictor96/fabric-federated-learning\n",
    "%cd fabric-federated-learning/federated-learning/\n",
    "!git pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Check if CUDA is available and set the default tensor type to CUDA\n",
    "# print('Using device: %s' % device)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_device('cuda')\n",
    "#     print(\"Cuda set as default device\")\n",
    "# else:\n",
    "#     torch.set_default_device('cpu')\n",
    "#     print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA drivers not working\n",
    "torch.set_default_device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_tokenizer\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 6e-05\n",
    "tokenizer = get_bert_tiny_tokenizer()\n",
    "root = 'client/data/datasets/dep1_cleaned.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Reddit Depression Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.data.reddit_dep import get_reddit_dep_dataloaders\n",
    "\n",
    "\n",
    "train_loader, eval_loader, test_loader = get_reddit_dep_dataloaders(root, tokenizer, \n",
    "                                                                    train_size=0.2,\n",
    "                                                                    eval_size=0.2,\n",
    "                                                                    test_size=0.6,\n",
    "                                                                    train_batch_size=TRAIN_BATCH_SIZE, \n",
    "                                                                    eval_batch_size=EVAL_BATCH_SIZE, \n",
    "                                                                    test_batch_size=TEST_BATCH_SIZE, \n",
    "                                                                    max_len=MAX_LEN,\n",
    "                                                                    seed=200, \n",
    "                                                                    device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bert Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_model\n",
    "from client.utils import set_seed\n",
    "\n",
    "set_seed(200)\n",
    "\n",
    "bert_tiny = get_bert_tiny_model(device=device)\n",
    "print(bert_tiny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(bert_tiny.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/155], Loss: 0.1488, Accuracy: 96.25 %\n",
      "-------------------------------\n",
      "Epoch [1/10], Loss: 0.1615, Accuracy: 95.15 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [2/10], Step [100/155], Loss: 0.1780, Accuracy: 93.75 %\n",
      "-------------------------------\n",
      "Epoch [2/10], Loss: 0.1607, Accuracy: 94.67 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [3/10], Step [100/155], Loss: 0.1667, Accuracy: 95.25 %\n",
      "-------------------------------\n",
      "Epoch [3/10], Loss: 0.1601, Accuracy: 95.80 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5046, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [4/10], Step [100/155], Loss: 0.1715, Accuracy: 95.25 %\n",
      "-------------------------------\n",
      "Epoch [4/10], Loss: 0.1651, Accuracy: 95.48 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5046, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [5/10], Step [100/155], Loss: 0.1401, Accuracy: 96.75 %\n",
      "-------------------------------\n",
      "Epoch [5/10], Loss: 0.1580, Accuracy: 95.48 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [6/10], Step [100/155], Loss: 0.1714, Accuracy: 95.00 %\n",
      "-------------------------------\n",
      "Epoch [6/10], Loss: 0.1630, Accuracy: 95.32 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [7/10], Step [100/155], Loss: 0.1749, Accuracy: 95.00 %\n",
      "-------------------------------\n",
      "Epoch [7/10], Loss: 0.1598, Accuracy: 95.64 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [8/10], Step [100/155], Loss: 0.1587, Accuracy: 95.25 %\n",
      "-------------------------------\n",
      "Epoch [8/10], Loss: 0.1558, Accuracy: 95.48 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [9/10], Step [100/155], Loss: 0.1427, Accuracy: 95.50 %\n",
      "-------------------------------\n",
      "Epoch [9/10], Loss: 0.1483, Accuracy: 95.32 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5045, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Epoch [10/10], Step [100/155], Loss: 0.1431, Accuracy: 96.25 %\n",
      "-------------------------------\n",
      "Epoch [10/10], Loss: 0.1663, Accuracy: 94.67 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5044, Validation Accuracy: 78.84 %\n",
      "-------------------------------\n",
      "Best model in epoch 1 saved with Validation Accuracy: 78.84 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bert.embeddings.word_embeddings.weight',\n",
       "              tensor([[-4.0998e-03, -3.0680e-02, -3.5279e-03,  ...,  1.8916e-02,\n",
       "                        3.7378e-03, -2.9220e-03],\n",
       "                      [-4.2728e-04, -3.6911e-02, -1.7160e-02,  ...,  2.9300e-02,\n",
       "                       -1.0393e-02,  2.6759e-02],\n",
       "                      [ 5.9389e-03,  4.2099e-03, -1.9557e-02,  ...,  1.6791e-02,\n",
       "                       -2.7789e-02, -6.8984e-03],\n",
       "                      ...,\n",
       "                      [ 3.5556e-02, -1.5883e-02,  4.9928e-03,  ...,  5.4046e-03,\n",
       "                       -1.1265e-02, -6.9495e-05],\n",
       "                      [-8.6977e-03, -2.2506e-02,  3.1978e-03,  ...,  2.7578e-02,\n",
       "                       -1.9545e-02,  2.4011e-03],\n",
       "                      [-7.8867e-02, -7.5372e-02, -4.6638e-03,  ..., -5.3315e-03,\n",
       "                       -4.4973e-02,  5.9813e-02]], device='cuda:0')),\n",
       "             ('bert.embeddings.position_embeddings.weight',\n",
       "              tensor([[ 0.0439, -0.0150, -0.5180,  ...,  0.0691,  0.0014, -0.0017],\n",
       "                      [-0.0352,  0.0131, -0.0387,  ..., -0.0369, -0.0141, -0.0465],\n",
       "                      [-0.0638, -0.0166, -0.0235,  ..., -0.0646,  0.0180, -0.0112],\n",
       "                      ...,\n",
       "                      [-0.0270,  0.0074,  0.0299,  ..., -0.0650,  0.0224, -0.0350],\n",
       "                      [-0.0347,  0.0288, -0.0370,  ..., -0.0120, -0.0217, -0.1000],\n",
       "                      [ 0.0833, -0.0865, -0.4168,  ...,  0.0410,  0.0132,  0.0483]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.embeddings.token_type_embeddings.weight',\n",
       "              tensor([[-7.4611e-03,  1.1369e-02, -1.0128e-04,  1.6493e-02,  2.3405e-02,\n",
       "                       -2.3238e-02, -6.3979e-03, -3.1070e-03, -1.5961e-02, -1.9160e-02,\n",
       "                       -4.7122e-03,  1.5115e-02, -8.2040e-03, -8.6757e-03,  4.4229e-03,\n",
       "                       -4.7806e-03,  2.6260e-03, -3.0876e-03, -1.4855e-02, -1.0273e-02,\n",
       "                       -2.5615e-03,  9.1881e-03,  9.3290e-03,  3.8770e-03,  1.7648e-03,\n",
       "                        1.1799e-03, -1.1928e-02,  1.5813e-02, -7.2794e-03, -9.6603e-03,\n",
       "                       -3.9885e-03,  4.0280e-03, -1.1672e-02, -9.1116e-03, -2.2565e-03,\n",
       "                       -2.1274e-02, -3.4074e-03, -3.5445e-03, -7.5323e-03,  3.7217e-03,\n",
       "                        1.1739e-02, -1.0340e-02, -3.3112e-02, -8.6662e-03, -1.0001e-02,\n",
       "                        1.1867e-03,  4.7203e-03, -5.4739e-03, -3.6934e-03, -6.4135e-03,\n",
       "                        6.5360e-03, -1.1622e-03,  3.5979e-03, -7.5100e-03, -2.4543e-03,\n",
       "                       -2.7987e-02,  9.8475e-03, -1.2350e-04, -2.2172e-03,  5.9758e-03,\n",
       "                        1.2183e-02, -1.4838e-02, -7.9544e-03, -6.7304e-03, -1.0499e-02,\n",
       "                       -9.9645e-03,  1.9701e-03, -1.4372e-02, -1.9526e-02, -1.3769e-03,\n",
       "                       -1.1780e-02,  1.2333e-03,  1.8321e-02, -1.2451e-01, -5.1721e-03,\n",
       "                       -5.7897e-03,  3.4086e-03,  8.3023e-03,  1.8194e-02,  1.0749e-01,\n",
       "                        1.0763e-03,  1.2580e-02,  4.1966e-03,  2.9287e-02, -1.0948e-03,\n",
       "                       -8.7474e-03, -9.5869e-03,  3.6039e-02,  6.6851e-03, -7.4479e-03,\n",
       "                       -4.7921e-03,  7.1873e-03, -1.4936e-02,  5.1856e-03,  3.6764e-03,\n",
       "                        1.5027e-05,  8.8691e-03,  8.0323e-04,  5.2593e-03,  1.2922e-02,\n",
       "                        2.1019e-03,  7.3915e-03, -1.4277e-02,  4.9964e-04,  1.7319e-02,\n",
       "                       -6.5153e-03, -1.3354e-02,  9.8240e-03, -4.3904e-03, -1.0787e-02,\n",
       "                       -8.7709e-04,  2.1244e-02,  3.1198e-03,  9.0597e-03, -7.1429e-03,\n",
       "                        3.3479e-03, -2.1796e-02, -7.5182e-03, -9.4943e-03, -8.1640e-03,\n",
       "                       -5.6360e-03, -1.3708e-03,  4.4702e-03,  5.5822e-03, -1.8030e-01,\n",
       "                       -7.6369e-03, -6.2455e-03,  5.6247e-03],\n",
       "                      [-7.3031e-03, -3.9352e-03,  4.4918e-04,  2.2993e-02,  3.1783e-03,\n",
       "                       -9.7617e-03, -5.9590e-03, -1.3000e-03, -1.4738e-02, -3.7574e-03,\n",
       "                        9.0615e-03,  1.0946e-02, -3.5242e-03, -2.9312e-02,  2.3128e-03,\n",
       "                       -2.3347e-03,  4.9730e-03,  1.3129e-03, -3.4286e-02, -1.9305e-02,\n",
       "                        1.2006e-02,  8.7464e-03,  1.1373e-02,  5.3316e-02, -1.1439e-02,\n",
       "                        9.3889e-03,  1.0345e-02,  6.7709e-03,  4.0722e-03,  1.8537e-03,\n",
       "                        3.2249e-03,  1.8806e-02, -1.8078e-02,  2.7620e-03,  1.1561e-02,\n",
       "                        6.4454e-03, -2.9377e-03,  7.8318e-03, -8.5071e-03,  7.2662e-03,\n",
       "                        1.2700e-02, -5.2207e-04,  1.7051e-01,  2.5106e-03,  6.5303e-03,\n",
       "                       -6.1295e-03,  7.3733e-03,  6.4083e-03,  1.4593e-02,  2.2714e-03,\n",
       "                       -3.9955e-03, -1.0179e-02,  3.0861e-03,  9.5585e-03, -1.0907e-02,\n",
       "                       -9.4995e-03,  3.7757e-03,  9.2053e-03,  4.0716e-03,  1.4434e-02,\n",
       "                        1.3629e-02, -6.5596e-03, -1.1784e-02,  1.2258e-02, -4.1929e-03,\n",
       "                       -1.6562e-02,  1.1745e-03, -5.8050e-03, -5.9453e-03, -3.2432e-03,\n",
       "                        3.3664e-03, -3.3323e-03,  2.3141e-02,  5.5351e-02, -5.9910e-04,\n",
       "                       -9.4415e-03, -1.4093e-02, -2.7653e-03,  1.5633e-02, -3.7557e-02,\n",
       "                        9.3926e-03, -4.6245e-03,  1.5648e-02, -1.3555e-02,  1.2282e-02,\n",
       "                       -9.5976e-03, -2.5403e-03, -7.5915e-03,  2.5872e-04,  4.4148e-03,\n",
       "                       -6.7180e-03, -3.4275e-02, -1.3336e-02,  1.3855e-03, -4.5274e-03,\n",
       "                        1.0764e-02,  9.0137e-03,  6.2946e-03,  9.9562e-03, -8.9658e-03,\n",
       "                       -1.1053e-02,  4.5373e-03, -1.9951e-02, -8.3717e-03,  6.0746e-03,\n",
       "                        1.5234e-03, -1.9515e-02, -6.4260e-03,  7.8800e-05, -1.6239e-02,\n",
       "                       -1.6481e-02, -2.2567e-03,  8.4660e-03,  1.4144e-02,  1.0666e-02,\n",
       "                       -1.6646e-02, -1.2548e-02, -1.4489e-02, -1.0212e-02, -8.9133e-03,\n",
       "                       -3.4497e-03,  2.4290e-03,  1.2694e-03,  1.8651e-03, -1.6149e-01,\n",
       "                       -1.4224e-02, -1.6985e-03,  1.3267e-02]], device='cuda:0')),\n",
       "             ('bert.embeddings.LayerNorm.weight',\n",
       "              tensor([1.4945, 1.2492, 1.0578, 1.0099, 1.3811, 1.3091, 1.2701, 1.2659, 1.4090,\n",
       "                      1.3722, 1.4219, 1.4062, 1.4378, 1.2875, 1.3663, 1.2102, 1.2477, 1.3642,\n",
       "                      1.2968, 1.4447, 1.4314, 1.2190, 1.2406, 1.2575, 1.4149, 1.3778, 1.3722,\n",
       "                      1.3034, 1.2989, 1.3234, 1.1617, 1.1706, 1.2921, 1.3981, 1.3591, 1.2811,\n",
       "                      1.2945, 1.4209, 1.2446, 1.2679, 1.3878, 1.3768, 0.7561, 1.4490, 1.3974,\n",
       "                      1.3273, 1.3070, 1.3749, 1.3189, 1.5009, 0.9894, 1.3477, 1.4378, 1.3183,\n",
       "                      1.2510, 1.2928, 1.3447, 1.5301, 1.3648, 1.4350, 1.4169, 1.4524, 1.3551,\n",
       "                      1.2067, 1.3706, 1.3235, 1.2533, 1.3157, 1.2446, 1.3202, 1.2396, 1.3083,\n",
       "                      1.2502, 0.9888, 1.3413, 1.3815, 1.3408, 1.2890, 1.3090, 0.9143, 1.2425,\n",
       "                      1.3173, 1.3706, 1.0794, 1.3116, 1.3689, 1.3334, 1.2794, 1.3936, 1.2821,\n",
       "                      1.5101, 1.2735, 1.3764, 1.2247, 1.3577, 1.4769, 1.1224, 1.3016, 1.3872,\n",
       "                      1.3858, 1.3066, 1.2623, 1.3781, 1.4399, 1.5260, 1.3684, 1.3100, 1.2638,\n",
       "                      1.4586, 1.4379, 1.2949, 1.4357, 1.2476, 1.3098, 1.2951, 1.3804, 1.2414,\n",
       "                      1.3260, 1.2535, 1.4369, 1.2756, 1.3678, 1.4474, 1.2923, 0.6062, 1.4699,\n",
       "                      1.2416, 1.2891], device='cuda:0')),\n",
       "             ('bert.embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.1465,  0.1412,  0.1144,  0.0079, -0.3835, -0.0467, -0.0066,  0.2534,\n",
       "                       0.0236, -0.1135,  0.0425, -0.0388, -0.1494, -0.0468, -0.0543, -0.1544,\n",
       "                       0.1134, -0.2287,  0.0202, -0.0016,  0.1207, -0.2725, -0.2316, -0.5942,\n",
       "                      -0.0184, -0.0053,  0.0901,  0.0147, -0.2179, -0.3327, -0.3479, -0.4735,\n",
       "                      -0.0366,  0.0103, -0.0079, -0.1557, -0.1216,  0.0916,  0.1593, -0.2495,\n",
       "                       0.0133, -0.0687, -0.4151,  0.1009, -0.0318,  0.2219,  0.0891,  0.2441,\n",
       "                      -0.2356,  0.0654,  0.1957,  0.1203, -0.0850,  0.2939,  0.2559,  0.0530,\n",
       "                       0.1800, -0.2803, -0.1447, -0.1213, -0.0808, -0.1995, -0.3774,  0.2438,\n",
       "                      -0.1927, -0.0854, -0.0326, -0.0402, -0.0502,  0.1092, -0.0857,  0.2239,\n",
       "                      -0.1515, -0.3105, -0.0729, -0.0201, -0.1130,  0.0661, -0.3671, -0.8064,\n",
       "                      -0.2156,  0.2180, -0.0452, -0.5452,  0.0356, -0.2027, -0.0527,  0.0769,\n",
       "                      -0.0731,  0.1356, -0.0893, -0.0539, -0.0629,  0.2636, -0.1559, -0.0768,\n",
       "                       0.0607,  0.0124,  0.2216,  0.2275, -0.0470,  0.0320, -0.1282,  0.0762,\n",
       "                      -0.0308, -0.1195,  0.0785,  0.1367, -0.1142,  0.3309,  0.3470,  0.0705,\n",
       "                      -0.2899, -0.1759, -0.0780,  0.1336,  0.2316, -0.2488, -0.1110, -0.0472,\n",
       "                       0.1128, -0.1164, -0.2543,  0.1527,  1.4904,  0.0596,  0.2929, -0.3926],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.query.weight',\n",
       "              tensor([[-0.0542, -0.0029, -0.0664,  ...,  0.0937,  0.2287, -0.0578],\n",
       "                      [ 0.0147, -0.1422, -0.0307,  ...,  0.0329, -0.0187,  0.0611],\n",
       "                      [-0.0054, -0.1485,  0.0211,  ...,  0.0226,  0.1355,  0.1028],\n",
       "                      ...,\n",
       "                      [ 0.0262,  0.0313, -0.0703,  ...,  0.0165,  0.0438, -0.0240],\n",
       "                      [ 0.0488,  0.0469,  0.0056,  ..., -0.0156, -0.0439, -0.0358],\n",
       "                      [-0.0338, -0.0063, -0.0420,  ...,  0.1037, -0.0772, -0.0520]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.query.bias',\n",
       "              tensor([-0.1340, -0.2150, -0.3606, -0.0681,  0.2451, -0.4624, -0.0316,  0.0728,\n",
       "                       0.2526, -0.3211, -0.3668,  0.2023, -0.1311,  0.0805,  0.3869, -0.1809,\n",
       "                       0.1552,  0.1992,  0.2216,  0.2507, -0.0204, -0.2601, -0.1239,  0.2905,\n",
       "                      -0.3458, -0.0335,  0.2978,  0.0090, -0.2566,  0.2606, -0.3114, -0.2570,\n",
       "                       0.2837,  0.0314,  0.1661,  0.3122,  0.1582,  0.1152, -0.0583,  0.3576,\n",
       "                       0.0910, -0.4545, -0.1439, -0.1119, -0.1145,  0.1907,  0.1596,  0.2466,\n",
       "                       0.2661, -0.3610,  0.2439,  0.1150,  0.3646,  0.3435, -0.3000,  0.3656,\n",
       "                       0.5228, -0.3588,  0.0706, -0.0489,  0.4386,  0.1186,  0.1915, -0.2486,\n",
       "                       0.2518, -0.2296, -0.4555, -0.3665,  0.1704, -0.3352,  0.0390,  0.1897,\n",
       "                       0.2821,  0.4308, -0.2134,  0.3162,  0.2343,  0.0269, -0.0194,  0.1619,\n",
       "                      -0.0975, -0.2383,  0.1104,  0.0908, -0.0269, -0.4689, -0.1780, -0.1821,\n",
       "                       0.3272,  0.1186,  0.2504, -0.1737,  0.1102,  0.0284, -0.0452,  0.0663,\n",
       "                       0.1999,  0.1637, -0.0851,  0.0671,  0.0350, -0.0510, -0.0431, -0.0300,\n",
       "                       0.3288, -0.0974,  0.0831,  0.1578, -0.3297,  0.1644, -0.0583, -0.0186,\n",
       "                      -0.3926, -0.2555, -0.0956,  0.2909,  0.1291, -0.1689,  0.2980,  0.1976,\n",
       "                      -0.2577,  0.2116, -0.3539, -0.1217,  0.1584,  0.0145,  0.1624, -0.1130],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.key.weight',\n",
       "              tensor([[-0.0114, -0.0268,  0.0080,  ...,  0.0616,  0.2157, -0.0558],\n",
       "                      [ 0.0140, -0.0601, -0.0459,  ...,  0.0091, -0.0513,  0.1547],\n",
       "                      [ 0.0272, -0.0031,  0.0819,  ...,  0.0267,  0.1310,  0.0363],\n",
       "                      ...,\n",
       "                      [-0.0894,  0.0931,  0.0583,  ...,  0.0177,  0.1059, -0.0095],\n",
       "                      [ 0.0159, -0.1251,  0.0036,  ..., -0.0180, -0.0759,  0.0044],\n",
       "                      [ 0.0582,  0.0460, -0.0712,  ..., -0.0045,  0.0822, -0.0790]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.key.bias',\n",
       "              tensor([-0.0660,  0.0570, -0.0458,  0.0142, -0.0241,  0.0059,  0.0015,  0.0484,\n",
       "                      -0.0658, -0.0442, -0.0135,  0.0329,  0.0010, -0.0190, -0.0212, -0.0484,\n",
       "                       0.0363,  0.0261,  0.0071, -0.0675,  0.0698,  0.0503, -0.1241,  0.0034,\n",
       "                       0.0131, -0.0401,  0.0526, -0.0419, -0.0166,  0.0462,  0.0344,  0.0294,\n",
       "                      -0.0057, -0.0746, -0.0135,  0.0293,  0.0687,  0.0163, -0.0724,  0.1024,\n",
       "                       0.0051, -0.0635,  0.0376, -0.0512,  0.0462,  0.0257, -0.0021,  0.0181,\n",
       "                       0.0826, -0.0236, -0.0136,  0.0949, -0.0544, -0.0195,  0.0206,  0.0354,\n",
       "                       0.0512, -0.0520,  0.1032, -0.0214, -0.0306,  0.0507,  0.0202,  0.0170,\n",
       "                      -0.0262,  0.0059, -0.0138, -0.0051, -0.0216,  0.0468,  0.0157,  0.0735,\n",
       "                       0.0487,  0.0367, -0.0280,  0.0102, -0.0305, -0.0253, -0.0759, -0.0014,\n",
       "                       0.0216,  0.0566, -0.0544,  0.0133, -0.0011,  0.0744, -0.0632,  0.0263,\n",
       "                      -0.0421, -0.0168,  0.0282, -0.0347, -0.0029, -0.0402,  0.0217, -0.0512,\n",
       "                       0.0062,  0.0675,  0.0179,  0.0118, -0.0287, -0.0444,  0.0207, -0.0751,\n",
       "                      -0.0147, -0.0243, -0.0270,  0.0433,  0.0392, -0.0677,  0.0070,  0.0494,\n",
       "                       0.0681,  0.0100,  0.0371, -0.0544, -0.0322,  0.0680, -0.0134,  0.0184,\n",
       "                       0.0505, -0.0052, -0.0568,  0.0118, -0.0125,  0.0103,  0.0345, -0.0154],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.value.weight',\n",
       "              tensor([[-0.1024,  0.1783,  0.0162,  ..., -0.0823,  0.0523,  0.0154],\n",
       "                      [-0.0859, -0.0072, -0.0286,  ...,  0.0042, -0.0475,  0.0491],\n",
       "                      [ 0.0048, -0.0815, -0.0427,  ..., -0.0211,  0.0020,  0.0096],\n",
       "                      ...,\n",
       "                      [-0.2884,  0.0798, -0.1038,  ...,  0.0019,  0.1663, -0.1998],\n",
       "                      [-0.0479,  0.1106, -0.1860,  ..., -0.1389, -0.0565, -0.3083],\n",
       "                      [-0.0509,  0.0805,  0.2165,  ...,  0.0657, -0.0058,  0.0009]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.self.value.bias',\n",
       "              tensor([-0.1210, -0.0348,  0.1992, -0.2716, -0.0777,  0.1284,  0.1698, -0.0205,\n",
       "                      -0.1994,  0.0712, -0.0642, -0.1208, -0.1282, -0.0128, -0.1123, -0.1275,\n",
       "                      -0.1618,  0.1492,  0.0897,  0.0985,  0.0559,  0.1138, -0.0671, -0.1440,\n",
       "                       0.1316,  0.0777,  0.2045,  0.1335,  0.0582, -0.0030,  0.0795, -0.1095,\n",
       "                       0.0359,  0.1037,  0.1582,  0.2352, -0.1031, -0.0021, -0.0978,  0.1268,\n",
       "                       0.1174,  0.0579, -0.0057,  0.2020,  0.1949,  0.0579,  0.0048,  0.0558,\n",
       "                       0.1295,  0.2414, -0.0429, -0.0360, -0.1665, -0.1062, -0.1021,  0.1866,\n",
       "                      -0.1453, -0.2128,  0.2887, -0.0880,  0.1021, -0.1285, -0.0638, -0.0178,\n",
       "                       0.1125, -0.0190, -0.0488,  0.1029,  0.0123, -0.0148,  0.0014, -0.0387,\n",
       "                       0.0535, -0.0270, -0.0830,  0.0128,  0.0371, -0.0511,  0.0036, -0.0497,\n",
       "                       0.0110,  0.0420,  0.0636,  0.0726, -0.0433, -0.0902, -0.0119, -0.0329,\n",
       "                      -0.0148, -0.0307,  0.0387, -0.0233,  0.0097,  0.0309,  0.0175,  0.0727,\n",
       "                       0.0605, -0.0839, -0.0615,  0.1002, -0.0301,  0.0431, -0.1126,  0.0364,\n",
       "                       0.0220, -0.0201, -0.1278,  0.0369, -0.0050,  0.0385, -0.0230,  0.0389,\n",
       "                      -0.0547, -0.0085, -0.0329, -0.0190, -0.0261, -0.0168,  0.0170,  0.0610,\n",
       "                       0.0220,  0.0010, -0.0952, -0.0115,  0.0232, -0.0302,  0.0427, -0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.output.dense.weight',\n",
       "              tensor([[-0.1566, -0.0836,  0.0024,  ..., -0.2386, -0.0741, -0.0690],\n",
       "                      [ 0.0580, -0.0643,  0.0464,  ...,  0.0437,  0.1021, -0.0650],\n",
       "                      [ 0.0628,  0.0672, -0.1150,  ...,  0.1292, -0.0415,  0.1058],\n",
       "                      ...,\n",
       "                      [-0.0028, -0.0048,  0.0140,  ..., -0.0407, -0.2409,  0.0394],\n",
       "                      [ 0.0866, -0.0101,  0.0340,  ...,  0.2114, -0.0473,  0.1660],\n",
       "                      [-0.0528, -0.0872, -0.0741,  ..., -0.3128, -0.0045,  0.1564]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.output.dense.bias',\n",
       "              tensor([ 2.3009e-02,  7.7679e-02,  8.7265e-02, -1.5284e-01, -7.7837e-02,\n",
       "                      -1.3305e-01, -1.4879e-01, -1.5712e-02,  1.8534e-02, -1.3501e-01,\n",
       "                      -9.8122e-03,  1.4752e-01,  3.7179e-02, -2.6897e-01, -1.0538e-04,\n",
       "                      -6.2918e-02,  8.7548e-02, -1.2433e-01, -1.8415e-01, -2.7071e-03,\n",
       "                       2.3069e-02, -1.5659e-02,  4.9435e-02, -1.1097e-01,  1.3783e-01,\n",
       "                       1.9059e-02, -4.5426e-02,  8.2395e-02, -4.5086e-02, -7.4461e-02,\n",
       "                      -1.1901e-01, -1.3130e-01,  6.9261e-02, -1.0633e-01, -7.5762e-02,\n",
       "                      -2.0960e-01, -4.8390e-02,  1.2332e-01,  4.5842e-03, -1.8473e-01,\n",
       "                       1.7132e-01,  4.3699e-02, -1.3549e-01,  2.3706e-01, -1.0110e-02,\n",
       "                       4.5767e-02,  1.0764e-01,  3.6295e-02, -5.6205e-02, -2.2451e-02,\n",
       "                       3.1709e-01,  3.2100e-02,  1.7581e-02,  1.1545e-01,  2.6434e-02,\n",
       "                      -1.3752e-01,  6.9100e-02,  1.1385e-01,  2.7354e-02,  9.4791e-02,\n",
       "                       1.1674e-01, -6.2156e-02, -1.4258e-02, -3.7780e-02, -1.4861e-01,\n",
       "                       1.3443e-01,  4.5197e-02, -6.2358e-02,  3.3538e-03,  1.7675e-02,\n",
       "                      -2.2230e-01,  1.4892e-01,  1.0038e-01, -1.0436e-01, -2.0230e-02,\n",
       "                      -1.3869e-01,  2.6944e-02,  6.8349e-02,  2.1015e-01,  7.8685e-02,\n",
       "                       6.5069e-02, -1.0410e-01,  9.2827e-02, -4.2718e-02,  5.4781e-02,\n",
       "                      -1.4382e-01, -1.0368e-01, -1.0903e-01,  4.8383e-02, -7.9413e-02,\n",
       "                       3.4719e-02,  7.3686e-02, -6.9934e-02,  5.7103e-02, -8.3334e-02,\n",
       "                      -5.4555e-02, -1.4027e-02,  8.1937e-02,  1.0393e-01,  2.6376e-02,\n",
       "                      -1.2125e-01,  1.1446e-01, -1.9508e-02,  4.5611e-02,  5.4701e-02,\n",
       "                      -5.0942e-02, -9.6386e-02,  1.5867e-01,  1.6393e-02, -3.2371e-02,\n",
       "                       9.8781e-02, -4.9515e-02,  7.8875e-02,  7.0550e-04,  2.2333e-02,\n",
       "                       4.8200e-02, -1.8052e-01,  1.2312e-02,  2.0883e-02,  1.6059e-02,\n",
       "                       1.9223e-01,  1.1847e-01,  2.2130e-02,  6.1990e-02, -9.3490e-02,\n",
       "                       3.9446e-02,  7.2871e-02, -3.7135e-02], device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.output.LayerNorm.weight',\n",
       "              tensor([1.2626, 1.1263, 1.8198, 1.7584, 1.1888, 1.1490, 1.0623, 1.1853, 1.2463,\n",
       "                      1.1206, 1.2027, 1.2909, 1.1702, 1.2199, 1.1300, 1.1502, 1.0754, 1.1609,\n",
       "                      1.1825, 1.2081, 1.1669, 1.1063, 1.4067, 1.3239, 1.1972, 1.1445, 1.1834,\n",
       "                      1.1501, 1.1181, 1.1410, 1.1720, 1.2269, 1.4368, 1.1887, 1.2235, 1.0927,\n",
       "                      1.1380, 1.2198, 1.1314, 1.1349, 1.1754, 1.1961, 1.5530, 1.1729, 1.1615,\n",
       "                      1.2380, 1.1321, 1.1925, 1.1730, 1.1706, 1.1031, 1.1936, 1.1757, 1.1652,\n",
       "                      1.1096, 1.3179, 1.1639, 1.1901, 1.2632, 1.1962, 1.1918, 1.2453, 1.3269,\n",
       "                      1.1431, 1.1566, 1.1491, 1.1775, 1.1266, 1.0924, 1.1120, 1.1005, 1.2104,\n",
       "                      1.0956, 1.7265, 1.1346, 1.2313, 1.1135, 1.1612, 1.2147, 1.4321, 1.1698,\n",
       "                      1.2664, 1.2004, 1.2170, 1.1865, 1.2172, 1.2073, 1.2419, 1.1920, 1.0570,\n",
       "                      1.2237, 1.2408, 1.1072, 1.1484, 1.1318, 1.2316, 1.0827, 1.0995, 1.2022,\n",
       "                      1.2007, 1.1748, 1.1254, 1.1016, 1.1664, 1.2187, 1.1661, 1.1618, 1.1986,\n",
       "                      1.2160, 1.2418, 1.2427, 1.2018, 1.1201, 1.1823, 1.1150, 1.1878, 1.0579,\n",
       "                      1.2024, 1.1532, 1.2182, 1.1586, 1.1163, 1.2270, 1.2046, 1.2739, 1.2874,\n",
       "                      1.1429, 1.2073], device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.7619,  0.0885, -0.0193, -0.3458,  0.5172, -0.0768,  0.1099, -0.4622,\n",
       "                      -1.5492,  0.9073, -0.0078, -0.2389,  0.4338, -0.3482,  0.3516, -0.1890,\n",
       "                      -0.2753, -0.1028, -0.7025,  0.6184,  0.1796, -0.3012, -0.1998,  1.6155,\n",
       "                       1.5209,  0.0237,  0.1132,  0.5983,  0.7381, -0.0948, -0.4357, -0.1305,\n",
       "                       0.0049, -0.1809,  0.1506, -0.1994,  0.3303, -0.3853, -0.1333, -0.2044,\n",
       "                       0.5388, -0.0888,  0.9275, -0.9763,  0.7363,  0.0632,  0.1003,  0.7406,\n",
       "                       0.3360,  0.1458, -0.0193,  1.0419,  0.3644, -0.1329, -0.0645,  0.0522,\n",
       "                      -0.1789, -0.0169,  0.3289,  0.8115,  0.6182, -0.6484, -1.0481, -0.4511,\n",
       "                      -0.2466,  0.2076,  0.1618,  0.0749, -0.1616,  0.4031, -0.0441,  0.1314,\n",
       "                      -0.1893, -1.6337, -0.6424,  0.1416,  0.0835, -0.3451,  1.9709,  0.3197,\n",
       "                       0.3398, -0.6246, -0.4639, -0.0289,  0.9660, -0.2871, -0.2798,  0.7875,\n",
       "                       0.2064, -0.3686,  1.2481,  0.2519, -0.0163,  0.1560,  0.5425,  1.0165,\n",
       "                       0.3555, -0.5723,  0.6938, -0.2978,  0.3212,  0.2221,  0.2587, -0.3611,\n",
       "                       0.2462, -0.5898, -0.7116,  0.6351,  0.7002, -0.3369, -0.8910,  0.9510,\n",
       "                       0.5832,  0.2787, -0.1356,  0.1441,  0.4456, -0.8663, -0.1534,  0.3371,\n",
       "                      -0.0105,  0.5320,  0.3382, -0.6075, -0.0086, -2.0409, -0.1111,  0.5956],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.intermediate.dense.weight',\n",
       "              tensor([[ 0.0975,  0.0296,  0.0195,  ...,  0.0079, -0.0260, -0.1168],\n",
       "                      [ 0.0449,  0.0527,  0.0174,  ...,  0.0389, -0.0548, -0.1527],\n",
       "                      [ 0.0266, -0.0046,  0.0091,  ...,  0.0086,  0.0200, -0.0765],\n",
       "                      ...,\n",
       "                      [ 0.0118, -0.0246, -0.0416,  ...,  0.0229,  0.1126, -0.0243],\n",
       "                      [-0.0044,  0.0436,  0.0354,  ...,  0.0841,  0.1203, -0.0285],\n",
       "                      [ 0.2898, -0.1520,  0.1883,  ...,  0.2139,  0.0167,  0.1621]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.intermediate.dense.bias',\n",
       "              tensor([-9.3201e-02, -9.4787e-02,  9.4442e-02, -2.5346e-01, -8.6846e-02,\n",
       "                       9.1870e-02,  1.6152e-02,  1.9514e-01, -1.2090e-01, -1.1658e-01,\n",
       "                       5.3011e-02, -2.4346e-01, -1.3607e-02, -2.8765e-01,  3.0139e-02,\n",
       "                      -2.3532e-01, -3.3975e-01, -8.0794e-02, -3.0582e-02, -2.4867e-01,\n",
       "                      -4.5007e-01, -2.1447e-02, -3.4292e-01,  2.2950e-01, -1.3063e-01,\n",
       "                      -2.0441e-02, -3.9491e-02,  1.2190e-01, -3.0959e-01, -3.3902e-02,\n",
       "                       2.7387e-01, -1.7039e-01, -3.8350e-01, -5.7955e-01,  8.6508e-02,\n",
       "                      -5.5580e-01, -3.6306e-01,  3.1675e-01, -7.2133e-02, -2.0857e-01,\n",
       "                      -1.7934e-01,  2.1202e-02, -4.6973e-02, -9.3508e-02, -2.1154e-01,\n",
       "                      -2.2168e-01, -1.0389e-01,  1.0539e-01,  1.7720e-01, -3.9368e-01,\n",
       "                       6.0561e-02, -5.0657e-01,  2.0548e-01, -3.0023e-01, -4.2912e-02,\n",
       "                      -2.2874e-01, -4.2195e-01,  3.2211e-02,  2.4633e-02, -7.6234e-02,\n",
       "                       2.4758e-02, -3.1180e-02, -5.2351e-01, -1.4982e-01, -6.6095e-02,\n",
       "                      -4.4741e-01, -4.8467e-01,  1.1415e-01, -9.9288e-02,  1.5863e-01,\n",
       "                      -2.9864e-02, -1.6666e-01, -1.5296e-01, -2.2689e-01,  1.2510e-01,\n",
       "                      -3.8194e-01, -3.6617e-01,  1.6934e-01, -8.3391e-02, -1.1105e-01,\n",
       "                      -1.2357e-01,  4.4872e-02, -9.4829e-02, -2.0108e-01, -2.6947e-01,\n",
       "                      -1.9624e-01, -7.0285e-02,  1.7850e-01, -1.5506e-02,  7.5604e-03,\n",
       "                      -2.6685e-01,  4.8063e-03,  9.4452e-03, -4.9405e-01, -1.5484e-01,\n",
       "                      -4.5023e-01, -1.2436e-01,  1.7004e-02, -1.0809e-01, -8.6395e-02,\n",
       "                      -3.7537e-01, -2.9980e-01,  3.9037e-01, -6.0314e-02, -1.9062e-01,\n",
       "                      -3.2355e-01, -3.4817e-02, -3.5997e-01, -2.2018e-01, -1.4031e-01,\n",
       "                      -1.3485e-01, -8.5534e-02,  5.8501e-02, -2.1306e-01,  1.0596e-01,\n",
       "                       1.7298e-01, -2.0111e-01, -2.1192e-01, -1.1925e-01,  3.1903e-01,\n",
       "                       3.8430e-03,  1.8761e-01, -1.2569e-01, -5.4880e-02, -3.3783e-02,\n",
       "                      -3.2724e-01, -1.0625e-01, -5.8391e-02, -2.1762e-02, -5.1399e-02,\n",
       "                       2.7218e-01, -3.9241e-01,  5.9180e-02, -3.5430e-02, -1.7262e-01,\n",
       "                       8.9772e-04,  3.0070e-02,  2.0365e-02, -3.8529e-02, -1.9036e-01,\n",
       "                       6.4777e-02, -2.5346e-02,  3.6784e-01,  1.7543e-02, -3.1723e-01,\n",
       "                       2.0101e-01, -3.9251e-01,  9.3201e-04,  1.5302e-01, -4.8005e-01,\n",
       "                      -9.2073e-01,  1.3926e-01, -1.1222e-01, -2.7367e-02,  1.8034e-01,\n",
       "                      -3.8901e-01,  2.0071e-01,  3.5612e-03,  1.3593e-01,  3.9900e-01,\n",
       "                       6.6136e-02, -2.6666e-01,  3.6213e-02, -1.6309e-01,  5.1501e-02,\n",
       "                      -5.3205e-01, -2.2755e-02, -9.3810e-02, -5.4140e-01, -3.2041e-01,\n",
       "                       2.0818e-01, -1.2953e-02, -5.3236e-01, -8.6239e-04, -3.5979e-02,\n",
       "                      -1.4836e-01, -1.1368e-01, -2.3476e-01, -1.6736e-01,  1.2021e-01,\n",
       "                       5.7614e-03,  9.6607e-02, -1.2660e-01,  1.5257e-02,  6.8635e-02,\n",
       "                      -8.1732e-02, -6.5491e-01, -4.3354e-01,  6.3700e-02, -4.4565e-01,\n",
       "                       1.5654e-01,  3.9546e-02,  8.7667e-02, -7.9203e-02,  1.2184e-01,\n",
       "                      -2.9724e-01,  3.9917e-02, -3.2089e-02, -2.3059e-01, -3.2857e-01,\n",
       "                      -3.2594e-01, -2.8506e-01,  1.7420e-02, -1.2102e-01, -4.3526e-01,\n",
       "                      -1.7426e-01,  1.0032e-01, -3.0194e-01, -3.7298e-01, -3.1962e-01,\n",
       "                       3.2006e-02, -6.0901e-01,  4.1590e-02, -1.2881e-01, -3.3826e-02,\n",
       "                      -1.4664e-01, -2.8801e-01, -2.0890e-01,  9.2109e-02,  2.4752e-01,\n",
       "                      -1.3847e-01, -2.0200e-01, -1.5298e-01, -1.4642e-01, -3.2641e-02,\n",
       "                      -2.8345e-01, -1.3287e-01,  4.3534e-02,  7.3269e-02, -5.9964e-02,\n",
       "                       3.7874e-03, -9.5077e-02,  8.9882e-04, -4.6118e-02, -2.8265e-02,\n",
       "                      -3.8114e-01, -4.8271e-01, -6.5646e-02, -2.6580e-01, -1.8651e-01,\n",
       "                       8.8453e-02, -2.8955e-01, -4.6496e-01, -8.5192e-02, -3.5163e-01,\n",
       "                      -8.7960e-01, -6.9396e-01, -3.3447e-01, -4.2427e-01, -1.3958e-01,\n",
       "                      -1.2499e-01,  2.5680e-02, -2.5655e-01, -4.4670e-02, -4.6132e-03,\n",
       "                       1.4016e-01, -4.2341e-01, -3.5712e-01, -3.6958e-02, -1.2647e-01,\n",
       "                      -2.3974e-01, -4.2097e-01, -5.1891e-01, -1.0120e-01, -5.1469e-01,\n",
       "                      -1.5216e-02, -5.9874e-01, -3.9419e-02,  3.5939e-02, -2.5880e-02,\n",
       "                       5.2844e-02,  2.2921e-01, -5.2358e-01,  1.1922e-01, -7.8473e-02,\n",
       "                      -2.2517e-02, -3.3126e-01, -3.1137e-01, -1.8024e-01, -6.1782e-02,\n",
       "                      -7.5355e-02, -1.2629e-01, -2.3867e-01,  1.6874e-03, -2.4032e-01,\n",
       "                       3.8225e-02,  2.1916e-01, -3.6933e-01, -4.6233e-01, -5.0162e-02,\n",
       "                      -7.2145e-02, -5.0706e-01, -7.8762e-02, -8.9306e-02, -1.0044e-01,\n",
       "                      -1.9894e-01,  1.7903e-01, -4.2346e-01, -2.4220e-01, -1.6660e-01,\n",
       "                      -1.1334e-02,  1.7179e-02,  8.0420e-03, -2.2536e-02, -5.0024e-01,\n",
       "                      -2.1119e-01, -3.7159e-01, -2.2521e-01, -2.9283e-02, -3.5725e-01,\n",
       "                       1.0658e-02, -6.6199e-02,  8.6826e-02,  2.6006e-02, -2.5556e-01,\n",
       "                       1.4292e-01,  5.5663e-02,  7.4272e-02,  6.6704e-02, -2.5861e-01,\n",
       "                      -3.9633e-02, -4.8852e-01, -1.0148e-01, -3.5537e-03,  2.5933e-02,\n",
       "                      -2.0008e-01,  4.5647e-02, -3.9331e-01, -1.9278e-01,  1.0986e-01,\n",
       "                      -2.5389e-01, -2.1334e-01, -2.0536e-01, -8.6105e-03, -4.6133e-02,\n",
       "                      -2.3403e-01, -4.7473e-01, -2.9066e-01,  8.7391e-02,  1.5646e-01,\n",
       "                      -2.2656e-01, -4.3979e-01, -7.1388e-02,  4.4340e-02, -2.7896e-01,\n",
       "                      -3.8039e-01,  2.3128e-02, -2.2323e-01, -3.3392e-01, -8.4164e-03,\n",
       "                       1.1570e-01, -1.1236e-04,  2.9088e-02, -5.6238e-02, -1.8493e-01,\n",
       "                      -1.7589e-01,  2.0974e-01, -2.7691e-01, -9.1098e-02, -1.4898e-01,\n",
       "                      -1.4525e-01, -4.2475e-03, -4.1760e-02, -5.3763e-02,  3.6863e-02,\n",
       "                      -2.8080e-01,  4.4969e-02, -1.8337e-01,  4.2022e-02, -3.3991e-01,\n",
       "                      -4.4273e-01, -5.5648e-01, -2.4637e-01,  5.2407e-01, -1.7006e-01,\n",
       "                      -6.8110e-02, -3.5214e-01, -7.7779e-02, -4.2183e-02, -3.1716e-01,\n",
       "                      -4.2561e-01,  1.8120e-02, -5.4618e-01, -2.0241e-01, -1.4605e-01,\n",
       "                      -1.3466e-01, -1.0272e-02, -3.8375e-01, -5.5542e-01, -8.5086e-02,\n",
       "                       1.6344e-01, -6.1612e-02, -3.5070e-01, -5.1617e-01,  1.2545e-01,\n",
       "                      -8.7645e-02, -4.1172e-01, -1.4183e-01,  8.3745e-02, -4.0214e-01,\n",
       "                       5.0908e-02, -4.5906e-01,  1.0614e-02,  1.0684e-02, -2.1867e-01,\n",
       "                       8.3233e-02, -1.9276e-01,  3.5015e-01,  9.2921e-03, -3.1876e-01,\n",
       "                      -3.8457e-01, -1.0548e-01,  1.2357e-02, -2.2762e-01, -2.2566e-01,\n",
       "                      -6.9922e-02,  1.2760e-01, -1.2946e-02, -3.2765e-01, -9.1238e-02,\n",
       "                      -1.6657e-01, -2.1580e-03, -4.2983e-02, -1.5476e-01, -1.9771e-01,\n",
       "                      -4.2059e-01, -2.2421e-02, -6.1777e-02,  4.3993e-02,  7.7565e-03,\n",
       "                      -1.0337e-01,  8.0951e-02, -1.2142e-01, -1.4410e-01, -3.8768e-01,\n",
       "                      -2.4379e-02,  1.5139e-01, -5.7571e-01, -7.0826e-02, -7.9003e-02,\n",
       "                      -2.1120e-01,  2.2169e-02, -6.1007e-02,  6.3970e-03, -2.5472e-01,\n",
       "                      -3.0816e-01, -3.4543e-01,  2.1510e-01,  8.3190e-02, -9.3634e-02,\n",
       "                      -5.8649e-01, -8.1033e-02, -6.2416e-02, -2.2322e-01,  8.8087e-02,\n",
       "                      -1.2106e-01, -1.8507e-01,  1.6524e-01, -3.2525e-01, -9.9859e-02,\n",
       "                       8.3951e-02,  4.8166e-02, -2.6399e-01, -2.4466e-01, -1.8384e-01,\n",
       "                      -3.4032e-01, -1.3795e-01,  1.6450e-01,  7.5189e-02, -1.2093e-01,\n",
       "                      -8.1717e-02,  1.0748e-01,  2.3210e-01, -2.3412e-01,  1.7137e-01,\n",
       "                      -8.3537e-02,  2.9189e-01, -1.0395e-01, -3.1390e-01,  1.1649e-02,\n",
       "                      -5.0237e-01, -2.9680e-02,  1.1228e-01, -1.5585e-01, -1.2932e-01,\n",
       "                      -3.7244e-01, -8.4961e-02, -2.0303e-01, -4.1358e-01, -7.7519e-02,\n",
       "                       4.0972e-02,  3.3292e-02,  4.5174e-02, -5.5334e-01,  9.8777e-02,\n",
       "                      -2.9594e-01,  2.1356e-02, -3.6036e-02, -1.5633e-01, -1.0066e-01,\n",
       "                      -1.3204e-01, -3.2302e-01, -4.6366e-02, -5.6621e-01, -1.6712e-01,\n",
       "                       6.9323e-02, -1.9010e-02, -1.2487e-02, -1.2824e-01, -1.5592e-02,\n",
       "                       1.3911e-01,  2.9297e-01], device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.output.dense.weight',\n",
       "              tensor([[ 0.0132, -0.0536, -0.0508,  ...,  0.0172, -0.0753,  0.1232],\n",
       "                      [-0.0180, -0.0497, -0.0699,  ...,  0.0082,  0.0299, -0.0610],\n",
       "                      [-0.0012, -0.0217,  0.0072,  ...,  0.0197,  0.0007,  0.0193],\n",
       "                      ...,\n",
       "                      [ 0.0507, -0.0360,  0.0113,  ..., -0.0533, -0.0760,  0.1277],\n",
       "                      [ 0.0046,  0.0452,  0.0198,  ...,  0.1031,  0.0427,  0.0726],\n",
       "                      [-0.0017, -0.0247, -0.0448,  ...,  0.0444,  0.0091,  0.0028]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.output.dense.bias',\n",
       "              tensor([ 0.1060, -0.0781, -0.4397,  0.3658, -0.0455, -0.0181,  0.0011,  0.0058,\n",
       "                       0.0486, -0.0515, -0.0370,  0.0652, -0.0875,  0.3782,  0.0283,  0.0646,\n",
       "                       0.0485,  0.1662,  0.1481, -0.0171,  0.0451, -0.0492,  0.1848, -0.3195,\n",
       "                      -0.2235, -0.0016, -0.0559, -0.0894, -0.0446,  0.0845,  0.0624,  0.0176,\n",
       "                      -0.2556,  0.1339, -0.0688, -0.1123, -0.1209,  0.0825, -0.0631, -0.0447,\n",
       "                      -0.0639,  0.0031, -0.2192,  0.1654, -0.0466,  0.0049, -0.0504, -0.1012,\n",
       "                       0.0526,  0.0206, -0.0342, -0.2381,  0.0714, -0.0930, -0.0139,  0.0409,\n",
       "                       0.0233,  0.0161, -0.1001, -0.1099, -0.0524,  0.1913,  0.1411, -0.0395,\n",
       "                       0.1417, -0.0006,  0.0666,  0.0661,  0.1657, -0.0223, -0.0999, -0.0805,\n",
       "                       0.0260,  0.5038,  0.0458, -0.0419,  0.1300,  0.0334, -0.1998, -0.2341,\n",
       "                       0.1058, -0.0534, -0.0348,  0.1018, -0.0952,  0.0530,  0.0721, -0.0431,\n",
       "                       0.1154, -0.0619, -0.2063,  0.0375, -0.1171, -0.0668, -0.0240, -0.1054,\n",
       "                      -0.0989,  0.1162, -0.0578,  0.1914,  0.2233, -0.0455,  0.0583, -0.0157,\n",
       "                       0.0149,  0.1203,  0.1465, -0.1301, -0.1135, -0.1249, -0.0149, -0.0197,\n",
       "                      -0.0950,  0.0378,  0.0619, -0.0491,  0.1862,  0.1151,  0.0239, -0.1391,\n",
       "                      -0.0764, -0.1252, -0.0150, -0.0156,  0.0261,  0.0597, -0.0482,  0.0789],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.output.LayerNorm.weight',\n",
       "              tensor([1.1586, 1.2934, 0.7486, 0.4997, 1.2751, 1.2683, 1.2924, 1.2540, 1.2178,\n",
       "                      1.2856, 1.2014, 1.0891, 1.2649, 1.1968, 1.3523, 1.3607, 1.4336, 1.2238,\n",
       "                      1.3013, 1.2608, 1.2649, 1.4023, 0.9807, 1.0935, 1.3254, 1.2754, 1.2758,\n",
       "                      1.2245, 1.4146, 1.3849, 1.3023, 1.3034, 0.7928, 1.2672, 1.2690, 1.3625,\n",
       "                      1.2518, 1.2457, 1.4628, 1.3544, 1.2041, 1.2500, 0.6375, 1.3756, 1.2722,\n",
       "                      1.2037, 1.3637, 1.1855, 1.2769, 1.1999, 1.3732, 1.2270, 1.2732, 1.3387,\n",
       "                      1.3618, 1.0996, 1.1960, 1.2852, 1.1273, 1.3032, 1.2512, 1.2116, 1.2254,\n",
       "                      1.4642, 1.2364, 1.1890, 1.2804, 1.3311, 1.4070, 1.3771, 1.4110, 1.1803,\n",
       "                      1.3145, 0.5564, 1.3010, 1.2225, 1.2779, 1.3003, 1.2219, 0.7984, 1.3148,\n",
       "                      1.1482, 1.2656, 1.1777, 1.2793, 1.2496, 1.2509, 1.0152, 1.2654, 1.4497,\n",
       "                      1.2968, 1.2436, 1.3835, 1.2177, 1.3144, 1.2481, 1.3027, 1.3934, 1.2433,\n",
       "                      1.1621, 1.2941, 1.3479, 1.2920, 1.2455, 1.1806, 1.3602, 1.2899, 1.2195,\n",
       "                      1.1699, 1.2065, 1.1697, 1.2615, 1.3444, 1.2885, 1.2393, 1.2490, 1.4447,\n",
       "                      1.2643, 1.2624, 1.0707, 1.3421, 1.4127, 1.2663, 1.2757, 0.9968, 1.2556,\n",
       "                      1.2976, 1.2823], device='cuda:0')),\n",
       "             ('bert.encoder.layer.0.output.LayerNorm.bias',\n",
       "              tensor([ 0.1100, -0.0652,  0.1714,  0.0316,  0.1925,  0.1514,  0.0129, -0.1375,\n",
       "                      -0.3082,  0.1778, -0.0434,  0.0362, -0.0170, -0.0681,  0.0025, -0.0483,\n",
       "                      -0.1881,  0.0112,  0.0641,  0.2083, -0.0261, -0.0486, -0.1140,  0.2099,\n",
       "                       0.3411, -0.0207, -0.0198,  0.1157,  0.1661,  0.0729, -0.0309,  0.1492,\n",
       "                       0.2320, -0.1783, -0.0214, -0.0360,  0.1648, -0.0462, -0.0138, -0.1342,\n",
       "                      -0.0382, -0.0445, -0.0423, -0.2565,  0.0987,  0.1570, -0.1391,  0.0375,\n",
       "                       0.0923, -0.0197, -0.2782,  0.1125,  0.0421, -0.2080, -0.1000,  0.0520,\n",
       "                      -0.1883,  0.0552,  0.0984,  0.0701,  0.0676, -0.1003, -0.0940, -0.2551,\n",
       "                      -0.2086,  0.1593,  0.0642,  0.1007,  0.0073,  0.1106, -0.0516, -0.3732,\n",
       "                      -0.2684,  0.6122, -0.0674,  0.0745, -0.0429, -0.0183,  0.4194, -0.2466,\n",
       "                       0.3498, -0.0886, -0.2123,  0.0173,  0.1271, -0.1665,  0.0645,  0.0319,\n",
       "                      -0.0766, -0.0953,  0.2018,  0.3563, -0.0532, -0.1843,  0.4038, -0.1800,\n",
       "                      -0.1629, -0.2650,  0.0694, -0.1212,  0.2170, -0.1074,  0.1934, -0.0106,\n",
       "                       0.0433, -0.1738, -0.0462,  0.0722,  0.0424, -0.2156, -0.1698,  0.3659,\n",
       "                       0.0797,  0.0149, -0.1855,  0.0198,  0.3783, -0.0543,  0.1056,  0.1130,\n",
       "                      -0.2780,  0.1364,  0.0709, -0.2066,  0.0823, -0.4427,  0.0436,  0.1449],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.query.weight',\n",
       "              tensor([[ 0.0251, -0.0100,  0.0030,  ..., -0.0241,  0.1288, -0.0211],\n",
       "                      [ 0.0115,  0.0509, -0.0858,  ...,  0.1342,  0.1412, -0.0497],\n",
       "                      [ 0.0060,  0.0057, -0.1130,  ...,  0.0141,  0.0053, -0.0226],\n",
       "                      ...,\n",
       "                      [ 0.1184,  0.0034, -0.0202,  ...,  0.2035, -0.1249,  0.1378],\n",
       "                      [-0.0886,  0.0144,  0.0713,  ..., -0.1151,  0.0408,  0.0582],\n",
       "                      [-0.1081, -0.0780, -0.0744,  ...,  0.1179, -0.1120,  0.1772]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.query.bias',\n",
       "              tensor([-3.4983e-02,  4.0668e-02, -1.4841e-01, -1.7657e-01, -4.1470e-01,\n",
       "                       1.5597e-02,  8.2787e-02, -7.2648e-02,  1.5790e-02, -9.8937e-02,\n",
       "                       1.2943e-01, -1.2053e-01, -4.4853e-01,  8.8695e-02, -1.0619e-01,\n",
       "                       2.2810e-01,  3.8556e-01,  1.2784e-01,  2.1953e-01,  8.6709e-02,\n",
       "                       2.3328e-01,  1.1095e-01, -9.9788e-02,  2.3710e-01,  2.4063e-01,\n",
       "                      -8.7650e-02,  1.1035e-01,  6.5152e-02,  1.2990e-01, -3.8723e-01,\n",
       "                      -1.3062e-02, -4.3362e-01,  4.3608e-03,  1.1492e-01, -7.5665e-02,\n",
       "                      -3.1291e-01, -1.3167e-01, -1.6393e-01,  6.9103e-02, -3.6989e-03,\n",
       "                      -1.5107e-02,  1.3021e-01,  1.0112e-01,  3.0380e-01, -3.9959e-01,\n",
       "                      -4.3425e-01,  9.0108e-02, -1.5907e-02,  2.2185e-01, -2.0867e-01,\n",
       "                       1.3879e-03,  3.1037e-01,  2.4171e-01, -2.8712e-02, -1.3773e-01,\n",
       "                       1.6048e-01,  1.0610e-01, -1.3301e-01, -1.8026e-01, -1.4007e-01,\n",
       "                       4.6987e-02,  2.6491e-01, -3.2227e-01, -4.3514e-01, -1.0937e-01,\n",
       "                      -3.6598e-01, -1.9473e-01, -2.8244e-01,  3.5041e-01,  8.0119e-05,\n",
       "                       7.4052e-02,  1.3924e-01,  4.0945e-03, -2.0786e-01, -3.3736e-02,\n",
       "                       5.7397e-02, -2.2464e-01, -7.3330e-02, -1.5106e-01, -8.1620e-02,\n",
       "                      -4.8274e-01,  2.0638e-01,  3.8449e-02,  1.0735e-03, -3.1721e-01,\n",
       "                      -2.4424e-01, -4.8312e-01,  4.2982e-02, -5.4441e-02, -1.1155e-01,\n",
       "                      -4.1897e-01, -1.6315e-01,  4.9358e-01, -3.4584e-01,  6.2847e-02,\n",
       "                      -2.9119e-02,  4.6642e-01, -9.4305e-02, -7.6044e-02, -8.6684e-02,\n",
       "                      -2.8187e-01,  2.7693e-01,  2.0552e-02, -4.7557e-01, -2.2752e-01,\n",
       "                       3.3246e-01,  1.5081e-01, -1.3009e-02,  4.9678e-01,  1.9794e-02,\n",
       "                       2.5555e-01, -1.3107e-01, -3.3932e-01, -1.8389e-01,  3.1604e-01,\n",
       "                      -8.8595e-02,  9.4666e-03, -4.2698e-01, -1.7769e-01, -3.2134e-01,\n",
       "                      -1.5491e-01, -1.6748e-01, -1.2883e-01,  6.0045e-01, -2.8189e-01,\n",
       "                       3.1826e-01, -2.4806e-01,  7.8168e-03], device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.key.weight',\n",
       "              tensor([[ 0.1845, -0.1373,  0.0732,  ...,  0.0609, -0.0724, -0.0036],\n",
       "                      [-0.0085, -0.0421,  0.0924,  ...,  0.0024,  0.0523,  0.1654],\n",
       "                      [ 0.0532,  0.1303,  0.1492,  ..., -0.0707,  0.0399,  0.0399],\n",
       "                      ...,\n",
       "                      [ 0.0231,  0.0357, -0.0862,  ..., -0.0449, -0.0503,  0.0613],\n",
       "                      [ 0.1648,  0.0181,  0.0009,  ...,  0.1190,  0.0786,  0.0433],\n",
       "                      [-0.0390, -0.0465,  0.0472,  ..., -0.0358,  0.0138,  0.0350]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.key.bias',\n",
       "              tensor([ 0.0383,  0.0257,  0.0054,  0.0688,  0.0442,  0.0251,  0.0354,  0.0586,\n",
       "                       0.0130,  0.0018, -0.0353,  0.0556,  0.0008,  0.0057,  0.0087, -0.0202,\n",
       "                      -0.0273, -0.0746, -0.0484,  0.0085, -0.0251,  0.0228,  0.0127, -0.0462,\n",
       "                      -0.0507, -0.0246,  0.0164,  0.0114, -0.0434, -0.0513,  0.0238,  0.0701,\n",
       "                       0.0354,  0.0566,  0.0086,  0.0528, -0.0854,  0.0013, -0.0460, -0.0117,\n",
       "                      -0.0035, -0.0319,  0.0072, -0.0105, -0.0012,  0.0110, -0.0357, -0.0585,\n",
       "                       0.0067,  0.0249,  0.0348, -0.0242, -0.0271,  0.0211, -0.0092, -0.0146,\n",
       "                      -0.0621,  0.0550,  0.0288,  0.0419,  0.0408,  0.0119,  0.0660,  0.0376,\n",
       "                      -0.0152,  0.0221, -0.0260, -0.0170, -0.0113, -0.0087,  0.0334, -0.0402,\n",
       "                       0.0296, -0.0625,  0.0766, -0.0169, -0.0033,  0.0313,  0.0625,  0.0364,\n",
       "                      -0.0438,  0.0437, -0.0748, -0.0126, -0.0017,  0.0056, -0.0180, -0.0780,\n",
       "                      -0.0446,  0.0051, -0.0121,  0.0431,  0.0237, -0.0363,  0.0227,  0.0145,\n",
       "                       0.0710, -0.0412,  0.0433, -0.0383, -0.0254,  0.0461, -0.0224,  0.0225,\n",
       "                       0.0452,  0.0239,  0.0216, -0.0144, -0.0233,  0.0010, -0.0058, -0.0238,\n",
       "                       0.0309,  0.0534,  0.0236,  0.0366, -0.0063,  0.0293,  0.0141, -0.0112,\n",
       "                       0.0074,  0.0344,  0.0296,  0.0132,  0.0878, -0.0364,  0.0136,  0.0217],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.value.weight',\n",
       "              tensor([[-0.0201,  0.0031, -0.0074,  ...,  0.0396, -0.1448,  0.1115],\n",
       "                      [-0.0377, -0.0035, -0.1272,  ...,  0.0486,  0.0363, -0.1194],\n",
       "                      [ 0.0452,  0.0053,  0.0297,  ..., -0.1243,  0.1023,  0.1457],\n",
       "                      ...,\n",
       "                      [-0.1161,  0.0767, -0.0288,  ..., -0.0270,  0.1181,  0.0807],\n",
       "                      [ 0.0211, -0.0842,  0.1463,  ..., -0.0347,  0.0021,  0.1659],\n",
       "                      [ 0.0423, -0.1023,  0.0540,  ..., -0.0598,  0.1960, -0.0213]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.self.value.bias',\n",
       "              tensor([-0.0562,  0.0135, -0.0503,  0.1113,  0.0603,  0.0437, -0.0261,  0.0893,\n",
       "                      -0.0172,  0.0740, -0.0708, -0.0677, -0.0246, -0.0389, -0.0277,  0.1031,\n",
       "                       0.1069,  0.0526,  0.0806,  0.0299,  0.0698, -0.0893,  0.0241, -0.0051,\n",
       "                       0.0824, -0.0917,  0.0353,  0.0215,  0.0496, -0.0666, -0.0601, -0.0305,\n",
       "                      -0.0842,  0.0200, -0.0262,  0.0185,  0.0011, -0.0175, -0.0787,  0.0745,\n",
       "                       0.0866, -0.0689, -0.1387,  0.0338,  0.0626, -0.0404, -0.1243, -0.1959,\n",
       "                       0.0698,  0.0617,  0.0771, -0.0893,  0.0547,  0.0261,  0.1347,  0.0439,\n",
       "                      -0.0410,  0.0366, -0.0723, -0.0273, -0.0722,  0.0526,  0.0164, -0.1094,\n",
       "                      -0.0476,  0.0769, -0.0802,  0.0620,  0.0056, -0.0128, -0.1941,  0.0611,\n",
       "                       0.0363,  0.0661, -0.0305,  0.0280,  0.0494,  0.0545,  0.0140,  0.0389,\n",
       "                      -0.0351,  0.0422, -0.0153, -0.1363, -0.1236, -0.1071, -0.0639, -0.0058,\n",
       "                       0.0055,  0.0236,  0.0247, -0.0766, -0.0565, -0.0284, -0.0448, -0.0230,\n",
       "                      -0.0377, -0.0834,  0.0300,  0.1143, -0.0171,  0.0263,  0.0083, -0.0851,\n",
       "                       0.0043,  0.0400,  0.0783,  0.0761,  0.0046,  0.0760, -0.0093,  0.0122,\n",
       "                       0.0479,  0.0052,  0.0039,  0.0567, -0.0671,  0.0683, -0.0718, -0.0634,\n",
       "                       0.0667, -0.0297,  0.0151,  0.1087,  0.1313, -0.0811, -0.0117, -0.0064],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.output.dense.weight',\n",
       "              tensor([[ 0.0115, -0.0159, -0.0788,  ...,  0.1296,  0.1262,  0.0809],\n",
       "                      [-0.1265,  0.1981,  0.0361,  ..., -0.0045, -0.1021, -0.0482],\n",
       "                      [-0.2641, -0.3341, -0.1508,  ...,  0.3328,  0.0386, -0.1884],\n",
       "                      ...,\n",
       "                      [-0.2050,  0.2195, -0.0171,  ..., -0.1561, -0.0455,  0.1710],\n",
       "                      [-0.2425,  0.1940,  0.0145,  ...,  0.1737, -0.1126,  0.1641],\n",
       "                      [ 0.0538, -0.0059,  0.2101,  ..., -0.0085,  0.2858, -0.0902]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.output.dense.bias',\n",
       "              tensor([ 0.5174, -0.4080, -0.4970,  0.0018,  0.2968,  0.4753, -0.8994, -0.7092,\n",
       "                      -0.6933,  0.1564,  0.3874, -0.0045,  0.2077,  0.1544, -0.4777,  0.1043,\n",
       "                       0.0623,  0.5688,  0.0899,  0.2094,  0.1174, -0.3283,  0.2563, -0.2038,\n",
       "                      -0.1437, -0.5432,  0.4293, -0.9949,  0.3085, -0.0732,  0.1975,  0.1527,\n",
       "                       0.7652, -0.5286, -0.2296, -0.3620,  0.1702,  0.3142, -0.1068, -0.2260,\n",
       "                      -0.1423, -0.0333,  0.1050,  0.6175,  1.0039,  0.8211, -0.1726, -0.3838,\n",
       "                       0.5128, -0.2075, -0.7417, -0.1751,  0.4371, -0.4465,  0.5045,  0.0494,\n",
       "                       0.0698,  0.0754, -0.2707, -0.6191, -0.4633,  0.3533,  0.3388, -0.2221,\n",
       "                      -0.2681,  0.9743,  0.2145,  0.0798, -0.3115,  0.2352, -0.3109, -0.5863,\n",
       "                      -1.0810,  0.0111,  0.6548,  0.6126, -0.5797,  0.9115,  0.1036,  0.2853,\n",
       "                       0.4180,  0.2043, -0.2763, -0.7412, -0.1375, -0.0153, -0.1124,  0.2065,\n",
       "                      -0.3828, -0.0281, -0.4395,  0.5515, -0.5402, -1.1092,  0.5638, -0.1006,\n",
       "                      -0.7362,  0.0432, -0.1775, -0.3866,  0.8428,  0.5876,  0.7425, -0.3707,\n",
       "                       0.0103, -0.4642, -0.4499, -1.0781,  0.0063,  0.1099, -0.2204,  0.4078,\n",
       "                      -0.1280,  0.0915, -0.0349, -0.4176,  0.5457,  0.7609,  0.5919, -0.3836,\n",
       "                       0.1891,  0.3123,  0.0257, -0.2471,  1.2480, -0.1442,  0.5964,  0.1205],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9597, 0.9528, 0.7374, 1.6744, 0.9871, 1.1143, 1.1879, 1.0905, 0.9411,\n",
       "                      0.9534, 0.9731, 0.9500, 1.0597, 0.9396, 1.0857, 1.2015, 1.0761, 1.0580,\n",
       "                      0.9465, 1.0090, 0.9773, 1.0623, 0.8789, 0.8419, 0.9650, 1.0804, 0.8765,\n",
       "                      1.1395, 1.0554, 1.0699, 1.0580, 1.2103, 0.8622, 0.9929, 0.9143, 1.1101,\n",
       "                      1.0021, 1.0430, 1.1739, 1.0237, 0.9656, 1.0771, 1.4499, 1.0613, 1.0856,\n",
       "                      0.9841, 1.0858, 1.0108, 0.8835, 1.0062, 1.3303, 1.1013, 0.9499, 0.9407,\n",
       "                      0.9447, 1.1500, 1.0997, 1.0422, 1.0401, 0.9183, 1.0057, 1.0218, 0.9262,\n",
       "                      1.1516, 0.9207, 1.0312, 1.0234, 1.0014, 1.2275, 1.1006, 1.1113, 1.1733,\n",
       "                      1.1749, 0.4344, 1.0582, 0.9212, 1.0171, 1.0898, 1.1681, 0.9198, 1.3060,\n",
       "                      1.2081, 1.0003, 1.0969, 0.9139, 1.0060, 0.9623, 0.9335, 1.0370, 1.0840,\n",
       "                      0.9560, 1.0541, 1.0254, 1.0611, 1.2028, 0.9995, 1.0115, 1.0555, 0.9434,\n",
       "                      0.9569, 1.2272, 1.0557, 1.0197, 0.7943, 1.0443, 1.0346, 1.0698, 1.1035,\n",
       "                      0.9353, 0.9824, 1.0639, 1.0370, 0.9919, 1.1275, 1.0732, 0.9650, 1.1754,\n",
       "                      1.1867, 0.9771, 1.0751, 1.1631, 1.0068, 1.0010, 1.0277, 0.8015, 1.0412,\n",
       "                      1.0698, 1.0401], device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0607,  0.0034, -0.0436, -0.2559,  0.1933, -0.2172,  0.1141,  0.0286,\n",
       "                      -0.2460, -0.3645,  0.5720,  0.1110, -0.1705, -0.0571,  0.6434, -0.1032,\n",
       "                      -0.0549, -0.0989, -0.4564, -0.0352,  0.4167,  0.4684,  0.6363,  0.2157,\n",
       "                       0.6640, -0.2089,  0.0747,  0.4437,  0.0583, -0.2646, -0.0680, -0.2975,\n",
       "                      -0.2163,  0.1778,  0.3631, -0.0320, -0.1717,  0.3936, -1.0307, -0.2450,\n",
       "                      -0.0977,  0.0674,  0.0439, -0.3985,  0.4127, -1.1571,  0.0816,  0.0679,\n",
       "                       0.3267,  0.0604,  0.3406,  0.4674,  0.3380,  0.2447, -0.2865, -0.0697,\n",
       "                       0.0940, -0.0198,  0.2931,  0.6682,  0.3282, -0.0943,  0.0235, -0.3389,\n",
       "                      -0.0366,  0.3244, -0.4572, -0.0274, -0.2571, -0.3054, -0.3730, -0.0688,\n",
       "                       0.1701,  0.3806, -0.4049, -0.0708,  0.3180,  0.1469,  0.5043,  0.2509,\n",
       "                       0.1441, -0.0431,  0.0997,  0.0532,  0.1346,  0.0134, -0.2786, -0.1046,\n",
       "                       0.4870, -0.3747,  0.6511, -0.2387, -0.5600,  0.8255, -0.1492,  0.6006,\n",
       "                       0.2637,  0.2137,  0.1547,  0.4406,  0.0959,  0.0136, -0.0741, -0.6233,\n",
       "                       0.2201, -0.6086, -0.2819,  0.3844,  0.0305, -0.0254, -0.0533,  0.2227,\n",
       "                       0.9778, -0.3802, -0.1660,  0.0472, -0.1894,  0.1585, -0.2709,  0.0254,\n",
       "                       0.3379,  0.9834,  0.8069, -0.2044, -0.4827, -0.2225, -0.5660,  0.7909],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.intermediate.dense.weight',\n",
       "              tensor([[-0.1005, -0.0410,  0.0002,  ...,  0.0641,  0.0750,  0.0156],\n",
       "                      [-0.0356, -0.0260, -0.0307,  ...,  0.1240,  0.0676, -0.0494],\n",
       "                      [-0.1691,  0.0866,  0.1604,  ...,  0.0007, -0.1637, -0.0601],\n",
       "                      ...,\n",
       "                      [-0.0560, -0.0082,  0.0189,  ...,  0.0419,  0.0167,  0.0035],\n",
       "                      [ 0.0196, -0.0295, -0.0652,  ...,  0.0268,  0.0056, -0.0875],\n",
       "                      [-0.0678,  0.0301,  0.0918,  ..., -0.0315, -0.0310, -0.0490]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.intermediate.dense.bias',\n",
       "              tensor([-8.5947e-02, -1.8592e-01, -3.7212e-02,  2.8148e-02,  9.5536e-02,\n",
       "                      -2.8564e-01,  1.5412e-03,  6.2263e-03,  2.4772e-01, -4.0657e-01,\n",
       "                      -2.1937e-01,  1.5570e-01, -3.1101e-01,  7.2428e-02,  1.9239e-01,\n",
       "                      -8.8389e-02,  1.6956e-01, -1.7728e-01, -7.5434e-02, -5.0649e-01,\n",
       "                      -1.3292e-01, -9.2281e-02, -1.4182e-01, -1.6387e-01, -1.0096e-01,\n",
       "                      -3.5216e-01, -1.9764e-01, -2.3690e-01, -1.6024e-01, -1.3963e-01,\n",
       "                      -7.5213e-02,  2.2006e-01, -6.0928e-01, -1.3126e-01, -2.4662e-01,\n",
       "                      -8.0129e-02, -1.6783e-01, -3.5740e-01, -1.4939e-01,  2.3158e-01,\n",
       "                       6.3235e-02, -1.3011e-02,  2.1869e-02, -3.1445e-01, -4.3853e-01,\n",
       "                      -1.8234e-01, -2.2945e-01, -1.1052e-01, -2.5840e-01,  1.3838e-01,\n",
       "                      -7.3160e-02,  5.5821e-02,  6.4181e-02, -1.0619e-01, -8.1168e-02,\n",
       "                       7.4817e-02, -8.1653e-02, -8.0479e-01, -3.0403e-01, -9.1286e-02,\n",
       "                      -1.4108e-01,  3.8967e-02, -1.3060e-01, -8.4731e-01, -1.8431e-01,\n",
       "                       2.6521e-02, -2.3171e-01, -2.3104e-01,  2.5062e-03, -5.5500e-01,\n",
       "                       2.0295e-01, -2.6509e-01,  4.8878e-02, -3.5512e-02,  1.8044e-01,\n",
       "                       1.6714e-01, -7.8845e-02, -3.2761e-01, -6.2255e-02, -7.0298e-02,\n",
       "                      -3.5772e-01,  7.7549e-02, -7.1010e-02, -6.7956e-02,  1.8036e-01,\n",
       "                      -1.5128e-01,  1.1013e-01,  2.9370e-03, -9.0721e-02, -2.2632e-01,\n",
       "                      -2.6905e-01, -6.3903e-03, -2.8502e-01,  7.5885e-02, -8.1240e-02,\n",
       "                      -1.9910e-02, -1.2736e-02, -4.0585e-01,  2.7899e-01, -1.4878e-01,\n",
       "                      -9.2781e-02, -3.3703e-01,  1.7049e-01, -1.6198e-01, -3.5101e-01,\n",
       "                       1.7063e-01, -3.8917e-03, -9.5945e-02, -2.3598e-01,  3.9667e-02,\n",
       "                      -6.1604e-01, -1.5434e-02, -2.3469e-01,  6.2190e-02, -4.2812e-02,\n",
       "                      -6.5488e-01,  7.2915e-02, -1.1990e-01, -3.0589e-01,  5.8287e-02,\n",
       "                      -1.6922e-01, -2.9330e-02, -5.3514e-02,  2.2583e-01, -3.6074e-01,\n",
       "                      -1.8642e-01, -1.4267e-01,  3.6801e-01, -1.0614e-01, -4.5221e-01,\n",
       "                       1.6099e-01, -5.7990e-02, -5.7129e-02,  1.4270e-01, -9.5393e-02,\n",
       "                       6.4412e-02, -2.3434e-01, -1.1842e-01, -4.1007e-02, -2.3240e-01,\n",
       "                      -6.3285e-02, -1.0727e+00,  1.8271e-01, -2.0717e-01,  1.4377e-01,\n",
       "                       2.4057e-01,  1.4438e-01, -3.8476e-02,  8.4333e-02, -1.1412e-01,\n",
       "                      -7.1910e-02, -2.7893e-01,  2.5510e-01, -2.9684e-02,  6.2599e-03,\n",
       "                      -1.6201e-01, -9.0579e-02, -8.0255e-02, -3.9809e-02,  3.9303e-02,\n",
       "                       3.5732e-03, -2.4996e-01, -4.0174e-02,  1.2408e-01, -2.4436e-01,\n",
       "                      -4.9311e-01, -1.0838e-01, -1.2309e-01, -5.7986e-01, -8.8511e-02,\n",
       "                       8.5968e-02, -2.6164e-02,  3.0185e-01,  1.7677e-01, -9.7588e-02,\n",
       "                       6.3254e-02,  6.5613e-02,  1.3824e-01, -4.5919e-01, -7.1744e-02,\n",
       "                      -7.4226e-03,  3.3061e-01,  1.0818e-01,  1.7589e-01, -6.2778e-02,\n",
       "                       2.1000e-02, -7.6395e-03, -2.3955e-01,  4.4116e-02,  1.0742e-01,\n",
       "                      -1.5318e-01,  1.0210e-01, -8.1240e-02, -1.6220e-01, -3.3003e-01,\n",
       "                       4.0673e-02, -2.3471e-01, -2.1631e-01, -6.8493e-02,  2.9000e-02,\n",
       "                      -8.9367e-02, -2.9795e-01, -5.0967e-02, -4.9921e-01,  2.1700e-01,\n",
       "                      -3.1792e-01,  3.0072e-02, -6.8520e-02, -1.7961e-01,  2.6310e-02,\n",
       "                      -1.0393e-02, -5.2593e-01, -8.7057e-02, -3.4344e-02, -3.3164e-02,\n",
       "                      -1.2342e-01, -1.2814e-02, -1.2572e-01, -1.2898e-01,  1.7911e-01,\n",
       "                      -5.0314e-01,  1.4532e-02, -3.3609e-02,  2.5881e-02,  3.2116e-02,\n",
       "                      -2.1325e-01, -3.4302e-01, -9.4646e-02, -1.8818e-01, -8.4348e-02,\n",
       "                       1.5303e-01, -1.7121e-01, -1.6976e-01, -2.0810e-01, -3.4709e-02,\n",
       "                       5.1195e-02, -1.0198e-01, -3.0360e-02, -2.2614e-01, -4.3600e-01,\n",
       "                      -2.9477e-01, -2.9486e-01, -2.7536e-01, -3.6420e-05, -5.9924e-01,\n",
       "                      -2.3625e-01, -1.6571e-01,  9.0988e-02, -7.1197e-02, -2.5678e-01,\n",
       "                      -1.8456e-01, -7.3585e-02,  1.2286e-01, -5.5603e-02, -6.2425e-01,\n",
       "                      -4.6672e-01, -6.4844e-01, -2.9273e-01, -1.7326e-02, -4.2303e-02,\n",
       "                      -1.5301e-01,  1.3123e-01, -1.0800e-02,  7.9933e-02,  3.5254e-02,\n",
       "                       2.1246e-01, -4.5320e-02, -7.8001e-01, -3.0017e-01, -6.4675e-03,\n",
       "                      -2.3215e-01, -2.9601e-02, -9.9738e-02, -4.4874e-02,  2.2641e-02,\n",
       "                      -1.6447e-02, -4.1666e-02, -1.2880e-01, -4.6702e-01, -1.0889e-01,\n",
       "                      -2.6976e-01, -2.3355e-02, -1.7642e-01, -3.6664e-02, -8.4514e-01,\n",
       "                      -2.0405e-01, -1.0413e-01,  1.8583e-01, -5.4258e-02, -1.2383e-01,\n",
       "                       4.4660e-02, -1.7240e-01,  3.3117e-02, -3.9690e-01,  7.2659e-03,\n",
       "                      -3.2866e-01, -5.1962e-01,  2.2289e-02,  4.4177e-03, -1.7918e-01,\n",
       "                       7.1406e-02, -3.3589e-01, -7.2272e-02, -5.7148e-01, -1.9809e-01,\n",
       "                      -9.5906e-03,  1.1220e-01, -2.3626e-01, -7.4381e-02,  4.1470e-02,\n",
       "                       6.4732e-02, -1.7990e-01, -2.5757e-01, -3.9943e-01, -5.6694e-02,\n",
       "                      -3.3112e-01, -4.8544e-02, -7.7369e-02,  7.8485e-02, -1.5377e-01,\n",
       "                      -2.2612e-01, -2.5931e-01, -3.2350e-01, -1.6373e-01, -2.5046e-02,\n",
       "                       5.1575e-02, -8.5525e-02, -8.0547e-02, -4.9590e-01, -4.4277e-01,\n",
       "                      -3.8947e-01, -1.3934e-01,  1.3395e-01, -1.1758e-01, -4.0826e-02,\n",
       "                      -6.6339e-02,  5.4325e-02, -6.0765e-01, -2.8889e-01, -5.7420e-02,\n",
       "                       1.4340e-01, -3.6522e-01, -3.0694e-01,  9.9105e-03,  1.8120e-02,\n",
       "                      -1.6040e-01,  1.1120e-01, -1.1416e-01, -1.5463e-01, -2.7342e-01,\n",
       "                      -4.0631e-01,  1.2103e-01, -5.4932e-02,  6.9446e-02, -8.7657e-01,\n",
       "                      -1.7280e-01, -1.3349e-01, -6.5653e-01, -6.8742e-01, -4.0605e-01,\n",
       "                      -3.9470e-03, -2.1185e-01, -1.1880e-01, -1.2533e-02,  1.2770e-01,\n",
       "                      -1.4462e-01, -7.1491e-01, -4.1171e-02,  1.3265e-01, -1.5455e-02,\n",
       "                      -1.0582e-01, -1.2712e-01,  1.2216e-01, -8.0419e-02, -5.3280e-01,\n",
       "                       8.1068e-02, -1.3268e-01, -2.3971e-01, -9.5241e-04,  2.2829e-02,\n",
       "                       1.6264e-01, -1.8830e-01, -6.1950e-01,  2.3591e-01, -2.7380e-01,\n",
       "                      -9.8049e-02,  1.4747e-01, -2.6821e-01, -6.2272e-02, -3.0070e-02,\n",
       "                       1.4127e-01,  3.3642e-02, -3.9489e-02,  6.1885e-03, -4.1900e-01,\n",
       "                       1.1655e-01,  9.1772e-03,  3.8714e-02, -2.8668e-03, -1.3079e-01,\n",
       "                      -1.8007e-01, -1.3918e-01, -5.9746e-01,  2.2467e-02, -4.8004e-02,\n",
       "                      -4.5667e-01, -2.7313e-01, -1.9916e-01, -2.1173e-01, -8.9609e-02,\n",
       "                      -3.7420e-01, -8.2124e-02, -5.8880e-02, -2.4034e-02,  1.0847e-01,\n",
       "                      -1.3977e-03, -4.8966e-01, -7.7771e-02, -6.2226e-01,  8.7508e-03,\n",
       "                      -2.6944e-02,  2.1520e-03, -1.6037e-01,  7.6260e-02, -1.0210e+00,\n",
       "                       4.1948e-02, -8.1655e-02, -2.1308e-02, -5.4540e-01, -7.3219e-02,\n",
       "                       3.9549e-02, -7.7769e-02, -8.0184e-02, -2.2433e-01, -1.3202e-02,\n",
       "                      -8.2519e-02,  1.7188e-02, -3.4847e-01,  8.4852e-02, -5.4483e-02,\n",
       "                      -1.6466e-01, -4.0061e-01,  1.7077e-01, -2.3415e-01,  8.6898e-03,\n",
       "                      -1.8732e-01, -2.8973e-02,  8.9409e-02, -4.9759e-01,  1.1618e-01,\n",
       "                      -1.9513e-01, -7.1434e-02, -1.9812e-01, -2.3230e-01, -8.2087e-02,\n",
       "                      -4.5454e-01, -9.6227e-01,  1.7322e-01, -2.8179e-02, -1.9854e-01,\n",
       "                      -1.0102e-01,  9.0405e-02, -3.1167e-01,  7.5568e-03, -1.2258e-01,\n",
       "                      -2.3692e-01, -1.7725e-03, -1.7844e-01, -4.5010e-01,  3.7940e-02,\n",
       "                      -1.3318e-01, -3.6240e-03, -3.1700e-01, -8.6942e-02, -2.0484e-01,\n",
       "                      -6.9468e-01, -4.9476e-01, -1.9773e-01, -5.9733e-01, -4.2586e-01,\n",
       "                      -1.3941e-01,  1.0018e-01, -6.0970e-02,  9.7456e-05, -1.5122e-01,\n",
       "                       9.2256e-02,  3.4853e-02, -1.1318e-01, -1.4379e-01, -8.0079e-02,\n",
       "                      -3.8361e-01,  2.4078e-01,  3.9778e-02, -2.1608e-01,  4.6168e-02,\n",
       "                      -2.9954e-01, -2.9873e-01, -1.3694e-01, -3.3596e-02, -2.7049e-01,\n",
       "                       1.4144e-01,  2.0381e-01, -1.2394e-01, -1.1249e+00, -1.1003e-03,\n",
       "                      -7.2855e-02, -2.7357e-01,  1.6067e-01,  4.6901e-02, -3.2679e-02,\n",
       "                      -2.4902e-01,  8.2386e-02], device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.output.dense.weight',\n",
       "              tensor([[ 0.0812,  0.0308,  0.0161,  ...,  0.1487, -0.0416,  0.0822],\n",
       "                      [ 0.0099, -0.0499,  0.0219,  ...,  0.0320, -0.0023, -0.0724],\n",
       "                      [-0.0723, -0.0447, -0.0706,  ...,  0.0109, -0.0631, -0.0825],\n",
       "                      ...,\n",
       "                      [ 0.0927, -0.0044, -0.0239,  ...,  0.0213,  0.1219,  0.0745],\n",
       "                      [ 0.0946, -0.0340,  0.0518,  ...,  0.0019, -0.0263, -0.0610],\n",
       "                      [-0.0588, -0.0549, -0.0068,  ..., -0.2017,  0.0414,  0.0197]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.output.dense.bias',\n",
       "              tensor([ 1.1981e-01, -1.3800e-02, -3.0788e-02, -3.9188e-02, -5.3584e-02,\n",
       "                       8.2958e-02, -2.1648e-02, -2.5319e-02, -8.3569e-02, -1.4910e-02,\n",
       "                      -2.8693e-02,  1.7824e-02, -1.1061e-01, -4.0341e-02, -9.3337e-03,\n",
       "                       1.3897e-01, -4.0807e-02, -4.7348e-02, -5.4381e-02,  3.3287e-02,\n",
       "                      -9.2398e-03, -1.1160e-01, -1.9134e-01,  9.7408e-02, -1.1098e-01,\n",
       "                      -3.2864e-02,  1.7954e-03,  1.5146e-02,  1.9102e-01,  3.9343e-02,\n",
       "                      -4.6692e-02, -1.0301e-02, -9.7459e-03,  1.0440e-01, -6.0623e-03,\n",
       "                      -6.4058e-02, -1.8488e-03, -6.5824e-02, -8.6192e-02, -7.8426e-02,\n",
       "                       6.4239e-02,  6.3069e-02,  4.5655e-02, -1.7911e-02,  1.6206e-01,\n",
       "                      -3.1362e-02, -2.0379e-01,  4.0304e-02,  7.1965e-02,  7.9670e-03,\n",
       "                      -9.2377e-02,  8.8006e-02, -7.5899e-02, -8.6506e-02, -7.7670e-02,\n",
       "                      -1.8609e-03,  1.3245e-02,  7.3726e-02, -5.8303e-03, -1.8441e-02,\n",
       "                      -1.3155e-02, -1.3464e-02, -9.5649e-02, -1.7088e-01,  5.7573e-02,\n",
       "                       5.9499e-02,  5.8560e-02,  1.0571e-01, -3.4286e-02,  8.2972e-02,\n",
       "                       7.9365e-02, -1.0083e-01, -5.1725e-02,  9.1746e-02,  2.3694e-02,\n",
       "                       6.2368e-02, -4.1149e-02, -4.3788e-02,  1.4222e-01,  2.4015e-01,\n",
       "                       7.8389e-02, -7.1360e-03,  4.0890e-05, -2.0480e-01,  1.1392e-01,\n",
       "                       3.6302e-04, -8.9268e-02,  1.1872e-01, -6.7973e-02, -4.9677e-02,\n",
       "                       1.0824e-01,  1.1778e-01,  1.9030e-02,  1.4041e-03,  1.0395e-01,\n",
       "                      -5.3157e-02, -5.0308e-02, -9.2324e-02, -1.1342e-01, -1.2047e-01,\n",
       "                       7.4601e-03,  5.4218e-02,  7.8557e-02,  1.4316e-01, -2.7513e-02,\n",
       "                      -1.1922e-01, -6.8485e-02,  4.5750e-02, -2.1239e-02, -6.9478e-02,\n",
       "                       2.0389e-02,  1.2363e-01, -1.1474e-01,  2.2748e-02,  2.9835e-02,\n",
       "                       2.7867e-02,  9.0436e-03,  8.6562e-02,  1.1704e-01,  3.6817e-02,\n",
       "                       4.8458e-02, -2.0416e-02, -5.4918e-02, -1.1916e-01,  1.8639e-01,\n",
       "                      -2.5244e-02,  5.4084e-02, -6.5201e-02], device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.output.LayerNorm.weight',\n",
       "              tensor([0.9712, 0.9481, 1.0699, 0.9939, 0.9686, 0.9764, 0.9382, 0.9051, 1.0027,\n",
       "                      0.9767, 1.0371, 1.0281, 1.0821, 0.9349, 1.0580, 0.9751, 0.9942, 0.9979,\n",
       "                      1.0875, 0.8775, 0.9622, 0.9798, 1.1188, 0.9727, 1.1071, 0.9462, 1.0059,\n",
       "                      1.0652, 0.8826, 0.9776, 1.0138, 1.0987, 1.0872, 0.9562, 1.0446, 0.9483,\n",
       "                      0.9907, 0.8830, 1.3766, 1.0126, 0.9477, 0.9912, 1.0212, 1.1339, 0.8816,\n",
       "                      1.2022, 0.8369, 1.0488, 1.0590, 0.9845, 1.1095, 0.9917, 0.9714, 0.9767,\n",
       "                      1.0277, 1.0768, 1.1172, 0.9710, 1.2052, 1.1217, 0.9639, 1.0913, 0.9134,\n",
       "                      1.0292, 1.0386, 1.0839, 0.9788, 0.9783, 0.9710, 0.9448, 1.0968, 1.0878,\n",
       "                      0.9119, 1.0366, 1.0682, 0.9580, 0.9059, 0.9495, 1.0390, 0.9306, 0.9714,\n",
       "                      1.1352, 1.0331, 0.8758, 0.9003, 0.9768, 1.0716, 1.0701, 1.0838, 1.0731,\n",
       "                      1.0639, 0.9132, 1.0565, 0.9857, 0.9762, 0.9911, 1.1545, 0.9676, 0.9558,\n",
       "                      0.9783, 0.9602, 0.9708, 0.9271, 1.0795, 1.1882, 1.0112, 0.9637, 0.9790,\n",
       "                      1.0688, 0.9319, 1.1118, 1.0021, 1.1382, 1.0096, 1.0992, 0.9853, 0.9693,\n",
       "                      1.0010, 1.0419, 1.0275, 1.0095, 1.1015, 1.1330, 1.0016, 1.3317, 1.0706,\n",
       "                      1.0951, 1.0735], device='cuda:0')),\n",
       "             ('bert.encoder.layer.1.output.LayerNorm.bias',\n",
       "              tensor([-7.4250e-02,  5.4007e-02, -2.5708e-01, -2.2276e-01, -6.4310e-02,\n",
       "                      -2.6127e-02, -2.6043e-01,  2.2914e-01, -3.9798e-02, -5.9628e-02,\n",
       "                       3.6053e-02,  2.8452e-01, -1.5218e-01,  1.9089e-02,  1.9358e-01,\n",
       "                      -2.9411e-02, -2.0431e-01,  5.0934e-02, -8.5447e-02,  7.4544e-02,\n",
       "                      -1.3919e-01, -2.1342e-01,  1.6389e-01,  7.2596e-02,  1.8876e-01,\n",
       "                      -2.4697e-01,  1.5642e-02,  7.3130e-02, -1.7944e-01, -1.4896e-01,\n",
       "                      -1.4782e-01, -3.7735e-01, -2.1300e-01,  2.2031e-04, -1.3787e-02,\n",
       "                      -1.2775e-01, -9.0995e-02, -4.7501e-02, -4.6013e-01, -6.0582e-02,\n",
       "                      -1.5525e-01, -1.7091e-02,  4.5545e-02, -7.0155e-02, -2.1718e-01,\n",
       "                      -3.1527e-01, -2.9463e-01, -5.1133e-02, -4.5690e-02, -1.1341e-01,\n",
       "                       1.5037e-01,  1.6420e-01,  9.4169e-02,  4.7556e-02, -1.4253e-01,\n",
       "                      -3.7573e-02,  1.0665e-01, -2.7781e-01, -4.1716e-02,  2.8311e-01,\n",
       "                      -1.1912e-01, -1.9012e-01, -1.8732e-01, -2.1846e-02, -2.1758e-01,\n",
       "                       1.5874e-01, -8.4974e-03,  1.0471e-01, -3.0744e-02,  8.1104e-02,\n",
       "                      -2.8522e-01, -1.9342e-02,  1.3169e-01,  6.4877e-02, -1.4653e-01,\n",
       "                       1.6144e-02, -9.8944e-02,  6.2720e-02,  1.8285e-02, -4.6596e-02,\n",
       "                      -1.5233e-01,  2.8520e-02, -2.2962e-02,  1.2550e-01, -1.0361e-01,\n",
       "                      -4.4585e-02, -2.2739e-01, -2.2828e-01, -3.8708e-02, -2.1819e-01,\n",
       "                       5.8623e-02,  8.3903e-02, -2.0320e-01,  1.4783e-02, -3.7326e-02,\n",
       "                      -1.6326e-02,  1.5317e-01,  3.4477e-02,  7.1747e-02,  1.8386e-01,\n",
       "                       1.3612e-02, -6.0285e-02,  5.1600e-02, -2.1603e-01,  1.9729e-01,\n",
       "                      -2.9280e-01,  7.3322e-03,  1.8539e-02, -1.4388e-01,  1.2183e-02,\n",
       "                       5.8524e-02, -1.3177e-01, -4.3001e-02, -1.3376e-01, -8.6899e-02,\n",
       "                       6.1230e-02, -4.5044e-02, -1.3669e-01, -1.6471e-01,  4.1869e-02,\n",
       "                       6.8314e-02, -1.4933e-01,  1.2996e-01, -2.6785e-01, -3.0876e-01,\n",
       "                       1.1397e-01, -1.5904e-01,  1.1627e-01], device='cuda:0')),\n",
       "             ('bert.pooler.dense.weight',\n",
       "              tensor([[ 0.0582,  0.0434, -0.0053,  ...,  0.1904,  0.2441, -0.0372],\n",
       "                      [-0.0466,  0.0060, -0.0005,  ...,  0.0284,  0.0139, -0.0126],\n",
       "                      [ 0.2036, -0.0771,  0.0187,  ...,  0.0770,  0.0823,  0.0269],\n",
       "                      ...,\n",
       "                      [ 0.0530,  0.0045, -0.0019,  ..., -0.1551, -0.2952,  0.0638],\n",
       "                      [ 0.0212, -0.0787, -0.0067,  ...,  0.0896, -0.0922, -0.0945],\n",
       "                      [-0.1269,  0.0245, -0.0271,  ...,  0.0251,  0.0763,  0.1454]],\n",
       "                     device='cuda:0')),\n",
       "             ('bert.pooler.dense.bias',\n",
       "              tensor([-0.1627, -0.0007, -0.1104,  0.0116, -0.1451,  0.0545, -0.0957, -0.0156,\n",
       "                       0.0132,  0.0344,  0.0136, -0.0014, -0.0029,  0.1049, -0.1048,  0.0498,\n",
       "                       0.0420,  0.0018, -0.0932,  0.0236,  0.0926,  0.0107,  0.0335, -0.0448,\n",
       "                      -0.0956, -0.0009, -0.1589,  0.0666,  0.0699,  0.0064,  0.0076,  0.0110,\n",
       "                      -0.0529, -0.0403, -0.0151,  0.1439, -0.0958, -0.0100, -0.0328, -0.1491,\n",
       "                       0.0337,  0.1454, -0.1420,  0.0727, -0.0471,  0.0051, -0.1334,  0.1113,\n",
       "                       0.0502,  0.0520,  0.0248, -0.0059, -0.0099,  0.0603,  0.0943,  0.0578,\n",
       "                      -0.0412,  0.0226,  0.0568, -0.0040,  0.0175, -0.0758,  0.0341,  0.0356,\n",
       "                       0.0550, -0.1391,  0.0538, -0.0624,  0.0892,  0.0561,  0.1565,  0.0051,\n",
       "                      -0.1608,  0.0084,  0.0844, -0.0162,  0.0206, -0.0010, -0.0018,  0.0189,\n",
       "                       0.0535,  0.0039, -0.0711, -0.1156,  0.1521, -0.0379, -0.0042, -0.0468,\n",
       "                       0.0165, -0.0162, -0.0294,  0.0741, -0.0008,  0.1196,  0.0439,  0.0598,\n",
       "                      -0.1343, -0.0665, -0.1556, -0.0434, -0.0604,  0.0026, -0.1325, -0.0709,\n",
       "                      -0.0681,  0.0103, -0.1512, -0.1260, -0.0037,  0.0194,  0.1457,  0.0318,\n",
       "                      -0.1009,  0.1468, -0.0590,  0.0045,  0.0194,  0.0183, -0.0031,  0.0105,\n",
       "                      -0.0083, -0.1584, -0.0731,  0.0804, -0.1331,  0.0782,  0.0902,  0.1118],\n",
       "                     device='cuda:0')),\n",
       "             ('classifier.weight',\n",
       "              tensor([[-2.5462e-02, -2.8985e-02, -4.4174e-03,  8.3396e-03, -1.7302e-02,\n",
       "                       -5.3997e-02,  1.7367e-02,  3.0315e-02, -3.1723e-02,  2.7731e-02,\n",
       "                       -7.6822e-02, -2.7425e-02, -8.1087e-03, -1.1106e-02, -2.8316e-02,\n",
       "                        3.8024e-02, -2.9922e-02,  6.7412e-02, -1.0443e-02,  1.6052e-02,\n",
       "                        3.6338e-04, -5.4913e-02,  2.5465e-02,  1.9128e-02,  3.0374e-02,\n",
       "                       -3.6839e-02, -2.5005e-02, -3.5046e-02, -9.0144e-03, -6.5770e-03,\n",
       "                        1.5527e-02, -2.8204e-02, -1.4879e-02, -2.3028e-02, -1.3366e-02,\n",
       "                        3.9943e-02, -2.7626e-02, -1.9563e-02,  2.5673e-02, -4.2580e-02,\n",
       "                        1.1678e-02, -6.4547e-03, -1.7303e-02,  1.5101e-02, -2.5270e-02,\n",
       "                        4.4093e-03,  3.2908e-03,  2.4433e-02,  8.5834e-03, -1.3815e-02,\n",
       "                        1.5699e-02, -1.4950e-02, -2.6031e-02,  1.7884e-02,  1.2748e-02,\n",
       "                       -2.1901e-02, -2.1981e-02,  2.9545e-03, -7.4390e-03,  2.7444e-02,\n",
       "                        3.4526e-02,  6.0772e-03,  6.0667e-02, -1.5586e-02,  6.8396e-02,\n",
       "                        9.5739e-03, -2.7692e-02, -5.5787e-02,  2.7183e-02,  1.9993e-02,\n",
       "                        3.5672e-02, -1.1843e-02,  1.2582e-02, -6.8422e-02,  1.0107e-02,\n",
       "                       -4.3048e-03,  3.6897e-02, -2.8046e-02, -7.9466e-03, -1.1353e-03,\n",
       "                        1.4108e-03, -1.9917e-02,  5.8358e-04, -2.4255e-02, -1.8917e-02,\n",
       "                       -2.3904e-02,  2.4172e-02, -3.0517e-02, -1.9020e-02, -7.4123e-03,\n",
       "                       -2.4231e-02,  1.2264e-02,  1.9978e-02, -9.9901e-03,  2.8078e-02,\n",
       "                        1.5231e-02,  1.6929e-02, -9.9508e-03, -2.3005e-02, -1.2744e-02,\n",
       "                       -4.9224e-03, -6.3255e-03, -3.9321e-03, -1.6801e-02,  1.6206e-02,\n",
       "                        1.1743e-02,  1.6312e-02, -3.7772e-02,  1.7686e-02, -4.3626e-02,\n",
       "                       -3.2714e-02, -2.9413e-02, -1.3477e-02,  2.3547e-02, -1.7042e-02,\n",
       "                        2.3723e-02, -3.4937e-02, -9.7999e-03,  1.3953e-02, -1.5579e-02,\n",
       "                        4.1836e-02,  1.1991e-02, -2.7830e-03, -2.3917e-02, -1.7222e-02,\n",
       "                        4.8845e-02, -1.5905e-02,  6.5693e-02],\n",
       "                      [ 1.3326e-02,  3.2213e-02, -3.9464e-02, -1.0009e-02,  2.9162e-02,\n",
       "                        6.9145e-03, -4.7527e-03, -2.1055e-02,  1.1587e-03, -2.5262e-02,\n",
       "                        4.2086e-02,  2.3856e-02,  2.4771e-02,  9.0459e-03,  6.8307e-03,\n",
       "                        1.2569e-02,  2.7945e-02, -2.1417e-02,  1.0302e-02, -1.1666e-02,\n",
       "                        2.4163e-03,  4.7929e-02, -1.5368e-02,  2.2373e-03,  9.5951e-03,\n",
       "                        1.4156e-02, -1.2780e-02,  3.8204e-02,  1.5489e-02, -3.6993e-02,\n",
       "                       -2.8021e-02,  4.1005e-02,  9.2663e-06,  2.3800e-03,  2.9158e-02,\n",
       "                       -1.9848e-02, -2.9058e-03, -1.7926e-03,  2.6372e-02, -1.5737e-03,\n",
       "                       -1.6607e-02,  5.5642e-03,  2.7900e-02,  2.1004e-03,  1.7060e-02,\n",
       "                       -3.9061e-02,  2.9921e-02, -2.3626e-03, -4.1074e-02, -1.9333e-03,\n",
       "                       -1.4827e-02,  4.6067e-03,  2.6636e-02, -9.6401e-03,  1.7147e-03,\n",
       "                       -3.5586e-03,  3.4417e-02,  9.6050e-04, -8.5165e-03, -7.7367e-03,\n",
       "                       -2.2004e-03,  1.9261e-02,  9.5223e-03, -7.9383e-03, -3.2056e-02,\n",
       "                       -8.3905e-03,  3.6640e-02,  3.0863e-02, -1.2129e-02, -6.3448e-03,\n",
       "                        2.1815e-02,  2.2586e-03,  2.8480e-02,  1.8694e-02,  3.2161e-04,\n",
       "                       -3.1539e-02, -2.7898e-02,  5.2030e-02,  1.1568e-02, -2.6834e-02,\n",
       "                       -3.0392e-02,  2.2374e-02,  3.3211e-02, -7.1300e-03,  1.6212e-02,\n",
       "                        1.6121e-02, -1.2183e-02,  2.2180e-02,  2.8091e-02, -4.8116e-02,\n",
       "                        2.6331e-02, -1.1954e-02, -4.2723e-02,  4.9436e-03, -1.9881e-02,\n",
       "                        3.9107e-03,  3.2807e-02,  2.8464e-02,  2.4116e-02,  1.4661e-02,\n",
       "                        8.8628e-03, -5.0246e-02, -1.0572e-02,  1.8052e-02,  1.1021e-02,\n",
       "                       -4.1897e-02,  5.3296e-03, -8.8792e-03,  4.6689e-03, -5.3256e-03,\n",
       "                       -1.7456e-02,  2.6898e-02, -3.0442e-02, -5.6475e-03, -2.2513e-03,\n",
       "                       -6.7337e-03,  4.4479e-02, -5.5317e-03, -3.6184e-02, -1.3256e-02,\n",
       "                        6.3826e-03, -9.5382e-03, -4.9872e-03,  8.9543e-03,  2.3372e-02,\n",
       "                       -1.6391e-02,  6.6209e-02,  1.6792e-02]], device='cuda:0')),\n",
       "             ('classifier.bias', tensor([ 0.0037, -0.0037], device='cuda:0'))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from client.train import train_text_class\n",
    "modelpath = 'client/models/bert-tiny'\n",
    "modelname = 'bert_tiny'\n",
    "train_text_class(bert_tiny, modelpath, modelname, train_loader, eval_loader, optimizer, LEARNING_RATE, lr_scheduler, NUM_EPOCHS, device, eval_flag=True, progress_bar_flag=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.model.bert_tiny import load_bert_tiny_model\n",
    "\n",
    "best_bert_tiny = load_bert_tiny_model('client/models/bert-tiny/bert_tiny_best.ckpt', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1858 test sentences: 77.07 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.07212055974165"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from client.test import test_text_class\n",
    "\n",
    "# Test the model\n",
    "test_text_class(best_bert_tiny, test_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
