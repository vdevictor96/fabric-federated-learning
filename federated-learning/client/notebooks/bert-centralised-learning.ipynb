{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Centralised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the module directory to import python files (RUN JUST ONCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/victor/_bcfl/fabric-federated-learning/federated-learning/client/notebooks', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python311.zip', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/lib-dynload', '', '/home/victor/anaconda3/envs/bcfl-fabric/lib/python3.11/site-packages', '/home/victor/_bcfl/fabric-federated-learning/federated-learning']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your project\n",
    "import sys\n",
    "sys.path.append('/home/victor/_bcfl/fabric-federated-learning/federated-learning')  # Replace with the path to your models directory\n",
    "print(sys.path)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running in colaboratory\n",
    "!git clone https://github.com/vdevictor96/fabric-federated-learning\n",
    "%cd fabric-federated-learning/federated-learning/\n",
    "!git pull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n",
      "NVIDIA GeForce MX150\n",
      "major and minor cuda capability of the device: (6, 1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "# Get the name of the CUDA device\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"major and minor cuda capability of the device: {torch.cuda.get_device_capability()}\")\n",
    "except Exception:\n",
    "    print(\"No Cuda available\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Check if CUDA is available and set the default tensor type to CUDA\n",
    "# print('Using device: %s' % device)\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_device('cuda')\n",
    "#     print(\"Cuda set as default device\")\n",
    "# else:\n",
    "#     torch.set_default_device('cpu')\n",
    "#     print(\"Cuda not available, CPU set as default device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA drivers not working\n",
    "torch.set_default_device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_tokenizer\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "EVAL_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 6e-05\n",
    "tokenizer = get_bert_tiny_tokenizer()\n",
    "root = 'client/data/datasets/reddit_dep/reddit_dep_train.csv'\n",
    "root_test = 'client/data/datasets/reddit_dep/reddit_dep_test.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Reddit Depression Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.data.reddit_dep import get_reddit_dep_dataloaders\n",
    "\n",
    "\n",
    "train_loader, eval_loader = get_reddit_dep_dataloaders(root, tokenizer, \n",
    "                                                                    train_size=0.2,\n",
    "                                                                    eval_size=0.8,\n",
    "                                                                    train_batch_size=TRAIN_BATCH_SIZE, \n",
    "                                                                    eval_batch_size=EVAL_BATCH_SIZE, \n",
    "                                                                    max_len=MAX_LEN,\n",
    "                                                                    seed=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Bert Tiny Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 128)\n",
      "      (token_type_embeddings): Embedding(2, 128)\n",
      "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-1): 2 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
      "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from client.model.bert_tiny import get_bert_tiny_model\n",
    "from client.utils import set_seed\n",
    "\n",
    "set_seed(200)\n",
    "\n",
    "bert_tiny = get_bert_tiny_model(device=device)\n",
    "print(bert_tiny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(bert_tiny.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = NUM_EPOCHS * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/124], Loss: 0.6160, Accuracy: 69.75 %\n",
      "-------------------------------\n",
      "Epoch [1/1] finished, Loss: 0.6059, Accuracy: 70.77 %\n",
      "-------------------------------\n",
      "Validation Loss: 0.5721, Validation Accuracy: 73.16 %\n",
      "-------------------------------\n",
      "Updated best model in epoch 1 saved with Validation Accuracy: 73.16 %\n",
      "-------------------------------\n",
      "Best model in epoch 1 saved with Validation Accuracy: 73.16 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from client.train import train_text_class\n",
    "modelpath = 'client/models/bert-tiny'\n",
    "modelname = 'bert_tiny'\n",
    "train_text_class(bert_tiny, modelpath, modelname, train_loader, eval_loader, optimizer, LEARNING_RATE, lr_scheduler, NUM_EPOCHS, device, eval_flag=True, progress_bar_flag=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from date 12-01-2024. Epoch 1, lr: 6e-05, optimizer: AdamW\n",
      "Train accuracy: 70.77 %, Validation accuracy: 73.16 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from client.model.bert_tiny import load_bert_tiny_model\n",
    "\n",
    "best_bert_tiny = load_bert_tiny_model('client/models/bert-tiny', 'bert_tiny_best.ckpt', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 618 test sentences: 72.82 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.81553398058253"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from client.data.reddit_dep import get_reddit_dep_test_dataloader\n",
    "from client.test import test_text_class\n",
    "\n",
    "# Test dataloader\n",
    "test_loader = get_reddit_dep_test_dataloader(root_test, tokenizer,       \n",
    "                                                    test_batch_size=TEST_BATCH_SIZE, \n",
    "                                                    max_len=MAX_LEN,\n",
    "                                                    seed=200)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "test_text_class(best_bert_tiny, test_loader, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcfl-fabric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
