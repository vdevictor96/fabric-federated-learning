Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "non_iid",
    "dataset": "acl_dep_sad",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 4,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "fl",
    "model": "bert_small",
    "model_name": "fl_bert_small_non_iid_0",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/4-ml_mode-model-data_dist-dp/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 3,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 4 layers.

Total parameters count: 28764674
Trainable parameters count: 6568450
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 2085 total sentences. 522 batches of size 4.
Eval Loader: 521 total sentences. 131 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Training --------
Training with Federated Learning technology.
Training without differential privacy.
Federated averaging algorithm selected.
Client 0: Label 0: 0, Label 1: 425
Client 1: Label 0: 0, Label 1: 425
Client 2: Label 0: 417, Label 1: 8
Client 3: Label 0: 417, Label 1: 7
Client 4: Label 0: 379, Label 1: 7

Round 1 of 4
-------------------------------
Client 1 of 5: Local Epoch [1/3] Loss: 0.0426, Accuracy: 98.82 %
Client 1 of 5: Local Epoch [2/3] Loss: 0.0022, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [3/3] Loss: 0.0014, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [1/3] Loss: 0.0429, Accuracy: 98.59 %
Client 2 of 5: Local Epoch [2/3] Loss: 0.0023, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [3/3] Loss: 0.0015, Accuracy: 100.00 %
Client 3 of 5: Local Epoch [1/3] Loss: 0.0995, Accuracy: 97.88 %
Client 3 of 5: Local Epoch [2/3] Loss: 0.0588, Accuracy: 98.12 %
Client 3 of 5: Local Epoch [3/3] Loss: 0.0377, Accuracy: 98.35 %
Client 4 of 5: Local Epoch [1/3] Loss: 0.1041, Accuracy: 98.35 %
Client 4 of 5: Local Epoch [2/3] Loss: 0.0669, Accuracy: 98.35 %
Client 4 of 5: Local Epoch [3/3] Loss: 0.0381, Accuracy: 99.29 %
Client 5 of 5: Local Epoch [1/3] Loss: 0.1076, Accuracy: 98.19 %
Client 5 of 5: Local Epoch [2/3] Loss: 0.0545, Accuracy: 98.19 %
Client 5 of 5: Local Epoch [3/3] Loss: 0.0297, Accuracy: 98.70 %
-------------------------------
Round [1/4] Average Local Loss: 0.0217, Average Local Accuracy: 99.27 %
-------------------------------
-------- Validation --------
Round [1/4] Global Model Validation Loss: 0.4437, Validation Accuracy: 84.45 %
-------- Validation finished --------
Updated best model in round 1 saved with Validation Accuracy: 84.45 %
-------------------------------

Round 2 of 4
-------------------------------
Client 1 of 5: Local Epoch [1/3] Loss: 0.0163, Accuracy: 99.53 %
Client 1 of 5: Local Epoch [2/3] Loss: 0.0009, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [3/3] Loss: 0.0006, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [1/3] Loss: 0.0192, Accuracy: 99.76 %
Client 2 of 5: Local Epoch [2/3] Loss: 0.0011, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [3/3] Loss: 0.0007, Accuracy: 100.00 %
Client 3 of 5: Local Epoch [1/3] Loss: 0.0758, Accuracy: 97.88 %
Client 3 of 5: Local Epoch [2/3] Loss: 0.0305, Accuracy: 99.29 %
Client 3 of 5: Local Epoch [3/3] Loss: 0.0203, Accuracy: 99.76 %
Client 4 of 5: Local Epoch [1/3] Loss: 0.0744, Accuracy: 97.88 %
Client 4 of 5: Local Epoch [2/3] Loss: 0.0327, Accuracy: 99.29 %
Client 4 of 5: Local Epoch [3/3] Loss: 0.0232, Accuracy: 99.53 %
Client 5 of 5: Local Epoch [1/3] Loss: 0.0820, Accuracy: 98.19 %
Client 5 of 5: Local Epoch [2/3] Loss: 0.0285, Accuracy: 98.96 %
Client 5 of 5: Local Epoch [3/3] Loss: 0.0105, Accuracy: 99.74 %
-------------------------------
Round [2/4] Average Local Loss: 0.0111, Average Local Accuracy: 99.81 %
-------------------------------
-------- Validation --------
Round [2/4] Global Model Validation Loss: 0.3067, Validation Accuracy: 86.76 %
-------- Validation finished --------
Updated best model in round 2 saved with Validation Accuracy: 86.76 %
-------------------------------

Round 3 of 4
-------------------------------
Client 1 of 5: Local Epoch [1/3] Loss: 0.0031, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [2/3] Loss: 0.0002, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [3/3] Loss: 0.0001, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [1/3] Loss: 0.0033, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [2/3] Loss: 0.0002, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [3/3] Loss: 0.0002, Accuracy: 100.00 %
Client 3 of 5: Local Epoch [1/3] Loss: 0.0620, Accuracy: 98.12 %
Client 3 of 5: Local Epoch [2/3] Loss: 0.0255, Accuracy: 99.29 %
Client 3 of 5: Local Epoch [3/3] Loss: 0.0177, Accuracy: 99.76 %
Client 4 of 5: Local Epoch [1/3] Loss: 0.0550, Accuracy: 98.35 %
Client 4 of 5: Local Epoch [2/3] Loss: 0.0191, Accuracy: 99.76 %
Client 4 of 5: Local Epoch [3/3] Loss: 0.0114, Accuracy: 99.76 %
Client 5 of 5: Local Epoch [1/3] Loss: 0.0682, Accuracy: 98.19 %
Client 5 of 5: Local Epoch [2/3] Loss: 0.0098, Accuracy: 100.00 %
Client 5 of 5: Local Epoch [3/3] Loss: 0.0061, Accuracy: 100.00 %
-------------------------------
Round [3/4] Average Local Loss: 0.0071, Average Local Accuracy: 99.91 %
-------------------------------
-------- Validation --------
Round [3/4] Global Model Validation Loss: 0.3614, Validation Accuracy: 86.18 %
-------- Validation finished --------

Round 4 of 4
-------------------------------
Client 1 of 5: Local Epoch [1/3] Loss: 0.0012, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [2/3] Loss: 0.0001, Accuracy: 100.00 %
Client 1 of 5: Local Epoch [3/3] Loss: 0.0001, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [1/3] Loss: 0.0017, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [2/3] Loss: 0.0001, Accuracy: 100.00 %
Client 2 of 5: Local Epoch [3/3] Loss: 0.0001, Accuracy: 100.00 %
Client 3 of 5: Local Epoch [1/3] Loss: 0.0679, Accuracy: 98.35 %
Client 3 of 5: Local Epoch [2/3] Loss: 0.0221, Accuracy: 99.53 %
Client 3 of 5: Local Epoch [3/3] Loss: 0.0147, Accuracy: 99.76 %
Client 4 of 5: Local Epoch [1/3] Loss: 0.0575, Accuracy: 98.58 %
Client 4 of 5: Local Epoch [2/3] Loss: 0.0222, Accuracy: 99.29 %
Client 4 of 5: Local Epoch [3/3] Loss: 0.0114, Accuracy: 99.76 %
Client 5 of 5: Local Epoch [1/3] Loss: 0.0352, Accuracy: 98.19 %
Client 5 of 5: Local Epoch [2/3] Loss: 0.0034, Accuracy: 100.00 %
Client 5 of 5: Local Epoch [3/3] Loss: 0.0018, Accuracy: 100.00 %
-------------------------------
Round [4/4] Average Local Loss: 0.0056, Average Local Accuracy: 99.91 %
-------------------------------
-------- Validation --------
Round [4/4] Global Model Validation Loss: 0.3538, Validation Accuracy: 87.52 %
-------- Validation finished --------
Updated best model in round 4 saved with Validation Accuracy: 87.52 %
-------------------------------
Best model in round 4 saved with Validation Accuracy: 87.52 %

-------- Training finished in 2:18 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 05-02-2024 14:03. Trained with Federated Learning technology.
Round 4, lr: 6e-05, optimizer: AdamW
Average train accuracy: 99.91 %, Validation accuracy: 87.52 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 650 total sentences. 82 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
NÂº of test samples: 650
Accuracy: 88.92%
Precision: 88.50%
Recall: 89.52%
F1 Score: 88.75%
-------- Testing finished --------
