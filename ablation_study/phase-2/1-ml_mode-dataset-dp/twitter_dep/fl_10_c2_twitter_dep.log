Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda:1",
    "dp_delta": 0.003,
    "dp_epsilon": 10,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.06,
    "max_length": 512,
    "ml_mode": "fl",
    "model": "bert_small",
    "model_name": "fl_10_c2_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-2/1-ml_mode-dataset-dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 2,
    "num_epochs": 3,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda:1 device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Training --------
Training with Federated Learning technology.
Training with differential privacy.
Federated averaging algorithm selected.
Client 0: Label 0: 706, Label 1: 285
Client 1: Label 0: 724, Label 1: 267

Round 1 of 4
-------------------------------
Predictions - 1s: 259, 0s: 732
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 5.7584, Accuracy: 58.63 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 244, 0s: 747
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 7.4387, Accuracy: 59.13 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 261, 0s: 730
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 5.8969, Accuracy: 59.43 %, Epsilon: 16.11, Delta: 0.0030
Predictions - 1s: 282, 0s: 709
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 4.9907, Accuracy: 59.94 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 222, 0s: 769
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 6.0951, Accuracy: 61.96 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 215, 0s: 776
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 6.9630, Accuracy: 61.65 %, Epsilon: 16.11, Delta: 0.0030
-------------------------------
Round [1/4] Average Local Loss: 6.4300, Average Local Accuracy: 60.54 %
-------------------------------
-------- Validation --------
Predictions - 1s: 7, 0s: 489
True Labels - 1s: 122, 0s: 374
Round [1/4] Global Model Validation Loss: 6.3271, Validation Accuracy: 74.40 %
-------- Validation finished --------
Updated best model in round 1 saved with Validation Loss: 6.3271 and Validation Accuracy: 74.40 %
-------------------------------

Round 2 of 4
-------------------------------
Predictions - 1s: 230, 0s: 761
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 7.1950, Accuracy: 60.54 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 284, 0s: 707
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 6.7861, Accuracy: 58.73 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 274, 0s: 717
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 7.1207, Accuracy: 57.11 %, Epsilon: 16.11, Delta: 0.0030
Predictions - 1s: 185, 0s: 806
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 5.9052, Accuracy: 64.08 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 248, 0s: 743
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 6.9044, Accuracy: 61.15 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 256, 0s: 735
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 6.4709, Accuracy: 63.57 %, Epsilon: 16.11, Delta: 0.0030
-------------------------------
Round [2/4] Average Local Loss: 6.7958, Average Local Accuracy: 60.34 %
-------------------------------
-------- Validation --------
Predictions - 1s: 490, 0s: 6
True Labels - 1s: 122, 0s: 374
Round [2/4] Global Model Validation Loss: 21.3834, Validation Accuracy: 25.81 %
-------- Validation finished --------

Round 3 of 4
-------------------------------
Predictions - 1s: 241, 0s: 750
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 7.3839, Accuracy: 61.86 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 230, 0s: 761
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 7.5556, Accuracy: 60.75 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 247, 0s: 744
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 7.8210, Accuracy: 60.85 %, Epsilon: 16.11, Delta: 0.0030
Predictions - 1s: 229, 0s: 762
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 7.3773, Accuracy: 62.66 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 233, 0s: 758
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 7.0386, Accuracy: 62.87 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 235, 0s: 756
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 7.7546, Accuracy: 61.25 %, Epsilon: 16.11, Delta: 0.0030
-------------------------------
Round [3/4] Average Local Loss: 7.7878, Average Local Accuracy: 61.05 %
-------------------------------
-------- Validation --------
Predictions - 1s: 82, 0s: 414
True Labels - 1s: 122, 0s: 374
Round [3/4] Global Model Validation Loss: 5.1285, Validation Accuracy: 67.34 %
-------- Validation finished --------
Updated best model in round 3 saved with Validation Loss: 5.1285 and Validation Accuracy: 67.34 %
-------------------------------

Round 4 of 4
-------------------------------
Predictions - 1s: 241, 0s: 750
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 8.2576, Accuracy: 60.04 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 280, 0s: 711
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 8.5195, Accuracy: 58.32 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 254, 0s: 737
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 8.3991, Accuracy: 59.94 %, Epsilon: 16.11, Delta: 0.0030
Predictions - 1s: 266, 0s: 725
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 7.6479, Accuracy: 59.33 %, Epsilon: 9.99, Delta: 0.0030
Predictions - 1s: 254, 0s: 737
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 7.5105, Accuracy: 59.94 %, Epsilon: 13.36, Delta: 0.0030
Predictions - 1s: 187, 0s: 804
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 7.7438, Accuracy: 67.10 %, Epsilon: 16.11, Delta: 0.0030
-------------------------------
Round [4/4] Average Local Loss: 8.0715, Average Local Accuracy: 63.52 %
-------------------------------
-------- Validation --------
Predictions - 1s: 86, 0s: 410
True Labels - 1s: 122, 0s: 374
Round [4/4] Global Model Validation Loss: 4.8817, Validation Accuracy: 68.95 %
-------- Validation finished --------
Updated best model in round 4 saved with Validation Loss: 4.8817 and Validation Accuracy: 68.95 %
-------------------------------
Best model in round 4 saved with Validation Loss: 4.8817 and Validation Accuracy: 68.95 %

-------- Training finished in 4:53 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 08-04-2024 13:20. Trained with Federated Learning technology.
Round 4, lr: 0.06, optimizer: AdamW
Average train accuracy: 63.52 %, Validation accuracy: 68.95 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 136, 0s: 482
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 62.14%
Accuracy 2 : 62.14%
Precision: 49.07%
Recall: 49.19%
F1 Score: 48.96%
Classification report:
              precision    recall  f1-score   support

           0     0.7241    0.7756    0.7489       450
           1     0.2574    0.2083    0.2303       168

    accuracy                         0.6214       618
   macro avg     0.4907    0.4919    0.4896       618
weighted avg     0.5972    0.6214    0.6079       618

-------- Testing finished --------
