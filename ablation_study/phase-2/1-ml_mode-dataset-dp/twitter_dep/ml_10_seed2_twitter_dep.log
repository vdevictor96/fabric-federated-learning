Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 10,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_10_seed2_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-2/1-ml_mode-dataset-dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 221,
    "test_flag": true,
    "train_batch_size": 2,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 991 batches of size 2.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
max_grad_norm:  0.1
Epoch [1/12], Step [100/991], Loss: 1.3774, Accuracy: 66.00 %, Epsilon: 1.24, Delta: 0.0030
Epoch [1/12], Step [200/991], Loss: 1.6383, Accuracy: 70.75 %, Epsilon: 1.87, Delta: 0.0030
Epoch [1/12], Step [300/991], Loss: 1.7934, Accuracy: 71.00 %, Epsilon: 2.27, Delta: 0.0030
Epoch [1/12], Step [400/991], Loss: 1.8220, Accuracy: 71.25 %, Epsilon: 2.56, Delta: 0.0030
Epoch [1/12], Step [500/991], Loss: 1.8294, Accuracy: 72.30 %, Epsilon: 2.80, Delta: 0.0030
Epoch [1/12], Step [600/991], Loss: 1.9054, Accuracy: 72.58 %, Epsilon: 2.99, Delta: 0.0030
Epoch [1/12], Step [700/991], Loss: 2.0102, Accuracy: 71.93 %, Epsilon: 3.17, Delta: 0.0030
