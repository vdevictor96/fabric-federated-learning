Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "fl",
    "model": "bert_tiny",
    "model_name": "fl_tiny_c2_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-2/3-accs/twitter_dep/",
    "mu": 0.5,
    "num_clients": 2,
    "num_epochs": 3,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 4386178
Trainable parameters count: 215042
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Training --------
Training with Federated Learning technology.
Training without differential privacy.
Federated averaging algorithm selected.
Client 0: Label 0: 706, Label 1: 285
Client 1: Label 0: 724, Label 1: 267

Round 1 of 4
-------------------------------
Predictions - 1s: 4, 0s: 987
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 0.5981, Accuracy: 70.84 %
Predictions - 1s: 5, 0s: 986
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 0.5485, Accuracy: 71.34 %
Predictions - 1s: 62, 0s: 929
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 0.5194, Accuracy: 74.67 %
Predictions - 1s: 6, 0s: 985
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 0.5814, Accuracy: 72.86 %
Predictions - 1s: 4, 0s: 987
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 0.5364, Accuracy: 73.26 %
Predictions - 1s: 20, 0s: 971
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 0.5114, Accuracy: 74.87 %
-------------------------------
Round [1/4] Average Local Loss: 0.5154, Average Local Accuracy: 74.77 %
-------------------------------
-------- Validation --------
Predictions - 1s: 23, 0s: 473
True Labels - 1s: 122, 0s: 374
Round [1/4] Global Model Validation Loss: 0.4956, Validation Accuracy: 78.02 %
-------- Validation finished --------
Updated best model in round 1 saved with Validation Loss: 0.4956 and Validation Accuracy: 78.02 %
-------------------------------

Round 2 of 4
-------------------------------
Predictions - 1s: 119, 0s: 872
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 0.5112, Accuracy: 74.57 %
Predictions - 1s: 174, 0s: 817
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 0.4879, Accuracy: 77.30 %
Predictions - 1s: 182, 0s: 809
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 0.4710, Accuracy: 78.51 %
Predictions - 1s: 103, 0s: 888
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 0.4917, Accuracy: 76.59 %
Predictions - 1s: 148, 0s: 843
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 0.4649, Accuracy: 79.11 %
Predictions - 1s: 165, 0s: 826
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 0.4556, Accuracy: 79.82 %
-------------------------------
Round [2/4] Average Local Loss: 0.4633, Average Local Accuracy: 79.16 %
-------------------------------
-------- Validation --------
Predictions - 1s: 112, 0s: 384
True Labels - 1s: 122, 0s: 374
Round [2/4] Global Model Validation Loss: 0.4794, Validation Accuracy: 76.21 %
-------- Validation finished --------
Updated best model in round 2 saved with Validation Loss: 0.4794 and Validation Accuracy: 76.21 %
-------------------------------

Round 3 of 4
-------------------------------
Predictions - 1s: 191, 0s: 800
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 0.4808, Accuracy: 77.40 %
Predictions - 1s: 214, 0s: 777
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 0.4675, Accuracy: 78.71 %
Predictions - 1s: 199, 0s: 792
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 0.4528, Accuracy: 79.21 %
Predictions - 1s: 179, 0s: 812
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 0.4618, Accuracy: 78.20 %
Predictions - 1s: 174, 0s: 817
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 0.4506, Accuracy: 78.51 %
Predictions - 1s: 181, 0s: 810
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 0.4372, Accuracy: 80.42 %
-------------------------------
Round [3/4] Average Local Loss: 0.4450, Average Local Accuracy: 79.82 %
-------------------------------
-------- Validation --------
Predictions - 1s: 128, 0s: 368
True Labels - 1s: 122, 0s: 374
Round [3/4] Global Model Validation Loss: 0.4794, Validation Accuracy: 75.40 %
-------- Validation finished --------
Updated best model in round 3 saved with Validation Loss: 0.4794 and Validation Accuracy: 75.40 %
-------------------------------

Round 4 of 4
-------------------------------
Predictions - 1s: 201, 0s: 790
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [1/3] Loss: 0.4725, Accuracy: 77.40 %
Predictions - 1s: 220, 0s: 771
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [2/3] Loss: 0.4500, Accuracy: 80.32 %
Predictions - 1s: 209, 0s: 782
True Labels - 1s: 285, 0s: 706
Client 1 of 2: Local Epoch [3/3] Loss: 0.4521, Accuracy: 77.60 %
Predictions - 1s: 187, 0s: 804
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [1/3] Loss: 0.4370, Accuracy: 79.41 %
Predictions - 1s: 209, 0s: 782
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [2/3] Loss: 0.4308, Accuracy: 80.22 %
Predictions - 1s: 190, 0s: 801
True Labels - 1s: 267, 0s: 724
Client 2 of 2: Local Epoch [3/3] Loss: 0.4212, Accuracy: 80.52 %
-------------------------------
Round [4/4] Average Local Loss: 0.4366, Average Local Accuracy: 79.06 %
-------------------------------
-------- Validation --------
Predictions - 1s: 135, 0s: 361
True Labels - 1s: 122, 0s: 374
Round [4/4] Global Model Validation Loss: 0.4800, Validation Accuracy: 75.20 %
-------- Validation finished --------
Best model in round 3 saved with Validation Loss: 0.4794 and Validation Accuracy: 75.40 %

-------- Training finished in 1:43 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-tiny from date 08-04-2024 13:17. Trained with Federated Learning technology.
Round 3, lr: 6e-05, optimizer: AdamW
Average train accuracy: 79.82 %, Validation accuracy: 75.40 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 148, 0s: 470
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 77.67%
Accuracy 2 : 77.67%
Precision: 71.66%
Recall: 69.93%
F1 Score: 70.66%
Classification report:
              precision    recall  f1-score   support

           0     0.8319    0.8689    0.8500       450
           1     0.6014    0.5298    0.5633       168

    accuracy                         0.7767       618
   macro avg     0.7166    0.6993    0.7066       618
weighted avg     0.7692    0.7767    0.7721       618

-------- Testing finished --------
