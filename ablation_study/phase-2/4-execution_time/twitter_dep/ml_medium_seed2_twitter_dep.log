Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_medium",
    "model_name": "ml_medium_seed2_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-2/4-execution_time/twitter_dep/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 221,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 41374210
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5518, Accuracy: 73.25 %
Epoch [1/12], Step [200/496], Loss: 0.5002, Accuracy: 76.12 %
Epoch [1/12], Step [300/496], Loss: 0.4863, Accuracy: 77.58 %
Epoch [1/12], Step [400/496], Loss: 0.4809, Accuracy: 77.62 %
Predictions - 1s: 362, 0s: 1620
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [1/12] Loss: 0.4721, Accuracy: 77.65 %
-------------------------------
-------- Validation --------
Predictions - 1s: 103, 0s: 393
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.4166, Validation Accuracy: 79.03 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.4166 and Validation Accuracy: 79.03 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.3804, Accuracy: 83.75 %
Epoch [2/12], Step [200/496], Loss: 0.3915, Accuracy: 82.75 %
Epoch [2/12], Step [300/496], Loss: 0.3960, Accuracy: 82.17 %
Epoch [2/12], Step [400/496], Loss: 0.3919, Accuracy: 82.06 %
Predictions - 1s: 450, 0s: 1532
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [2/12] Loss: 0.3859, Accuracy: 81.99 %
-------------------------------
-------- Validation --------
Predictions - 1s: 165, 0s: 331
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.4667, Validation Accuracy: 78.23 %
-------- Validation finished --------
Epoch [3/12], Step [100/496], Loss: 0.3069, Accuracy: 86.00 %
Epoch [3/12], Step [200/496], Loss: 0.3204, Accuracy: 86.38 %
Epoch [3/12], Step [300/496], Loss: 0.3320, Accuracy: 85.50 %
Epoch [3/12], Step [400/496], Loss: 0.3248, Accuracy: 85.69 %
Predictions - 1s: 500, 0s: 1482
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [3/12] Loss: 0.3258, Accuracy: 85.72 %
-------------------------------
-------- Validation --------
Predictions - 1s: 175, 0s: 321
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.4698, Validation Accuracy: 78.23 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 0.2271, Accuracy: 91.00 %
Epoch [4/12], Step [200/496], Loss: 0.2611, Accuracy: 89.75 %
Epoch [4/12], Step [300/496], Loss: 0.2517, Accuracy: 89.83 %
Epoch [4/12], Step [400/496], Loss: 0.2547, Accuracy: 89.38 %
Predictions - 1s: 524, 0s: 1458
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [4/12] Loss: 0.2532, Accuracy: 89.25 %
-------------------------------
-------- Validation --------
Predictions - 1s: 177, 0s: 319
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.5397, Validation Accuracy: 76.21 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 0.1912, Accuracy: 92.25 %
Epoch [5/12], Step [200/496], Loss: 0.1995, Accuracy: 91.25 %
Epoch [5/12], Step [300/496], Loss: 0.2042, Accuracy: 91.25 %
Epoch [5/12], Step [400/496], Loss: 0.2056, Accuracy: 91.06 %
Predictions - 1s: 541, 0s: 1441
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [5/12] Loss: 0.2095, Accuracy: 91.12 %
-------------------------------
-------- Validation --------
Predictions - 1s: 181, 0s: 315
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.5832, Validation Accuracy: 77.02 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 0.1389, Accuracy: 93.75 %
Epoch [6/12], Step [200/496], Loss: 0.1486, Accuracy: 93.50 %
Epoch [6/12], Step [300/496], Loss: 0.1530, Accuracy: 93.42 %
Epoch [6/12], Step [400/496], Loss: 0.1593, Accuracy: 93.12 %
Predictions - 1s: 547, 0s: 1435
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [6/12] Loss: 0.1543, Accuracy: 93.44 %
-------------------------------
-------- Validation --------
Predictions - 1s: 128, 0s: 368
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.6226, Validation Accuracy: 77.22 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.1089, Accuracy: 97.00 %
Epoch [7/12], Step [200/496], Loss: 0.1175, Accuracy: 96.25 %
Epoch [7/12], Step [300/496], Loss: 0.1154, Accuracy: 96.08 %
Epoch [7/12], Step [400/496], Loss: 0.1139, Accuracy: 95.69 %
Predictions - 1s: 553, 0s: 1429
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [7/12] Loss: 0.1133, Accuracy: 95.76 %
-------------------------------
-------- Validation --------
Predictions - 1s: 136, 0s: 360
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.6637, Validation Accuracy: 78.02 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.0946, Accuracy: 96.00 %
Epoch [8/12], Step [200/496], Loss: 0.0993, Accuracy: 96.00 %
Epoch [8/12], Step [300/496], Loss: 0.0915, Accuracy: 96.17 %
Epoch [8/12], Step [400/496], Loss: 0.0876, Accuracy: 96.19 %
Predictions - 1s: 558, 0s: 1424
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [8/12] Loss: 0.0836, Accuracy: 96.42 %
-------------------------------
-------- Validation --------
Predictions - 1s: 147, 0s: 349
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.7709, Validation Accuracy: 77.82 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.0562, Accuracy: 98.50 %
Epoch [9/12], Step [200/496], Loss: 0.0660, Accuracy: 97.75 %
Epoch [9/12], Step [300/496], Loss: 0.0623, Accuracy: 97.83 %
Epoch [9/12], Step [400/496], Loss: 0.0628, Accuracy: 97.81 %
Predictions - 1s: 561, 0s: 1421
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [9/12] Loss: 0.0659, Accuracy: 97.68 %
-------------------------------
-------- Validation --------
Predictions - 1s: 131, 0s: 365
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.7815, Validation Accuracy: 77.02 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.0428, Accuracy: 98.75 %
Epoch [10/12], Step [200/496], Loss: 0.0597, Accuracy: 97.62 %
Epoch [10/12], Step [300/496], Loss: 0.0611, Accuracy: 97.83 %
Epoch [10/12], Step [400/496], Loss: 0.0573, Accuracy: 98.00 %
Predictions - 1s: 561, 0s: 1421
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [10/12] Loss: 0.0577, Accuracy: 97.88 %
-------------------------------
-------- Validation --------
Predictions - 1s: 145, 0s: 351
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.8170, Validation Accuracy: 78.23 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.0392, Accuracy: 99.00 %
Epoch [11/12], Step [200/496], Loss: 0.0460, Accuracy: 98.75 %
Epoch [11/12], Step [300/496], Loss: 0.0437, Accuracy: 98.75 %
Epoch [11/12], Step [400/496], Loss: 0.0432, Accuracy: 98.69 %
Predictions - 1s: 552, 0s: 1430
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [11/12] Loss: 0.0435, Accuracy: 98.74 %
-------------------------------
-------- Validation --------
Predictions - 1s: 142, 0s: 354
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.8194, Validation Accuracy: 78.43 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.0423, Accuracy: 98.50 %
Epoch [12/12], Step [200/496], Loss: 0.0517, Accuracy: 97.88 %
Epoch [12/12], Step [300/496], Loss: 0.0477, Accuracy: 98.08 %
Epoch [12/12], Step [400/496], Loss: 0.0468, Accuracy: 98.31 %
Predictions - 1s: 559, 0s: 1423
True Labels - 1s: 555, 0s: 1427
-------------------------------
Epoch [12/12] Loss: 0.0449, Accuracy: 98.39 %
-------------------------------
-------- Validation --------
Predictions - 1s: 128, 0s: 368
True Labels - 1s: 119, 0s: 377
Validation Loss: 0.8244, Validation Accuracy: 78.02 %
-------- Validation finished --------
Best model in epoch 1 saved with with Validation Loss: 0.4166 and Validation Accuracy: 79.03 %

-------- Training finished in 2:12 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-medium from date 21-03-2024 13:52. Trained with Centralised Machine Learning technology.
Epoch 1, lr: 6e-05, optimizer: AdamW
Train accuracy: 77.65 %, Validation accuracy: 79.03 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 112, 0s: 506
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 82.20%
Accuracy 2 : 82.20%
Precision: 79.74%
Recall: 72.30%
F1 Score: 74.60%
Classification report:
              precision    recall  f1-score   support

           0     0.8360    0.9400    0.8849       450
           1     0.7589    0.5060    0.6071       168

    accuracy                         0.8220       618
   macro avg     0.7974    0.7230    0.7460       618
weighted avg     0.8150    0.8220    0.8094       618

-------- Testing finished --------
