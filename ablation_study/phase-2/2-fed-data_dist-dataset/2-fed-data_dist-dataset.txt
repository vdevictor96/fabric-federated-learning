
- PARAMETER TWEAKING
for non_iid 0.03
Mu 0.5  77
mu 0.1 - 84 ( 85.46 **2)
mu 0.001 ( 87.06 **2)
mu 1 - 74 - worse
mu 0 -  87.06 (//2 )


for non_iid 0.0
mu 0.5 76.24 ( 81.56 **2) 
mu 0.001 80.5 
mu 0.1 82.27 (83.16 **2) - better 
mu 1 69.33 - worse
mu 0 (fedavg) - 56.91



- try non_iid with clients with different sample size
varying samples 0.03 minumum_labels 0

fedavg 53.19
fedprox 0.01 55.67
fedprox 0.5 67.2
fedprox 1 65.96

varying samples minumum_labels 40

fedavg 84.22
fedprox 0.5 83.33



varying samples minumum_labels 15
fedavg 81
fedprox 0.5 78

varying samples minumum_labels 10
fedavg 82
fedprox 0.5 76 

varying samples minumum_labels 5
fedavg 71.63
fedprox 0.5 72.34








try smaller lr and more rounds - see if converges in a better optima

varying samples minumum_labels 20 
lr 6e-6 5x5
fedavg 74.84
fedprox 0.5 73.23

lr 1e-5 5x5
fedavg 79.08
fedprox 0.5 76.06

lr 3e-5 10x5
feavg - 83.87
fedprox 0.1 - 83.87
fedprox 0.5 - 82.62
 


dreaddit min 20
fedavg_iid : 74.64% +- 0.63
fedavg_non : 72.82% +- 2.00
fedprox_iid : 74.36% +- 0.57
fedprox_non : 70.26% +- 0.93

 dreaddit min 5
fedavg_iid : 74.64% +- 0.63
fedavg_non : 69.32% +- 2.10
fedprox_iid : 74.36% +- 0.57
fedprox_non : 64.38% +- 4.41

 dreaddit min 0
fedavg_iid : 74.64% +- 0.63
fedavg_non : 48.67% +- 0.48
fedprox_iid : 74.36% +- 0.57
fedprox_non : 53.71% +- 9.21

 dreaddit min 0 same data in each client





- conclusions fedprox
- FIXED using squared l2 norm instead of just l2 norm. Improved a bit 

- even with umbalanced data (clients with more data than others and some clients
    with few data samples (10%) of one class fedavg still performs almost like the balanced case
    baseline federated algorithm is already quite resistant to umbalanced data.
    fedprox does not worsen the performance, but cannot either improve upon the best accs (balanced or slightly umbalanced)
    for cases where some clients lack of samples of one class (this is not as typical in binary classfication, 
    but is the typical scenario for multiclass classification) fedavg gets wors and fedprox really stands out
    improving the accuracy of the model.
    Our framework could also be applied to datasets that classfily multiple classes of mental health diseases (depression, anxiety,
    pts, anorexia) and in that case fedprox would be a good choice to protect model performance against skewed data partitions among the clients

  - in paper benchmarking we see fedavg lossing accuracy in non_iid with twitter_dep dataset, but after
    analysing the code, we noticed that in the non_iid case the partitions for each client, apart from being umbalanced
    have 100 samples instead of 240, which makes the algorithm to work with less than half of the data than the iid version
    hence the lower values of accuracy.
    We tried their non_iid partitions respecting the 240 samples umbalanced and fed_avg does not lose accuracy
    - we tried doing the same and we got better performance for fedprox even with less extreme non_iid scenarios. Fedprox helps also when there is less data
    REDUCING THE SIZE of the samples dataset makes fedprox being better than fedavg when non_iid
    twitter_dep_balanced (less data) clients 20 min 10
    fedavg 79.29
    fedprox 79.94
    twitter_dep_balanced (less data) for non_iid 0.03
    fedavg all data 87.06 vs less data 61.88
    fedprox mu 0.1 85.46 vs less data 69.86

  - file:///home/victor/Downloads/CSE3000_Paper_1_.pdf we see in this paper how fedprox does have a similar accuracy as fedavg
    in many non-iid scenarios, even in extreme non_iid scenarios. 
    The only case where fedprox was standing up compared to iid was when they
    used a network of 50 clients instead of 9, but only 7 parties were contacted in each round, the data was evenly partitioned between the 50 clients 1/50
    which mean that every iteration was just trianed with 7/50 of the dataset
  - in all distribution cases, fedyogi was yielded better results than fedprox for non_iid, future work
  - another example of fedprox working worse than fedavg https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9619688/pdf/ocac188.pdf (page 8/10)

  - for our experiments we used non_iid scenario (some clients with only data from one class) with equal partitions between 5 clients

- https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9345723 proposes CSFedAvg. Is FedAvg but chooses the clients with more IID data.
  Their experiments have slight better accuracy for FedProx than FedAvg, but they also run them with extreme non_iid scenarios.
  Some clients containing only one class in Hybrid I and some clients containing only two classes (out of 10) in Hybrid IID
  https://ieeexplore.ieee.org/iel7/10370004/10370033/10370601.pdf In this paper they tried fedavg vs fedprox in iid scenarios and fedprox was worse
  for non_iid, they just tried fedprox so there is no comparsion possible with fedavg for non_iid

 fedprox and fedavg non_iid with twitter_dep balanced and min clients - non_iid 0.0
 fedavg 31.39
 fedprox 54.37


- with min label per client 0
dreaddit ok
mixed_depression ok
acl_dep_sad fedprox_non a bit worse than fedavg_non, but less standard deviation
twitter fedprox_non a bit worse than fedavg_non, but less standard deviation
fedprox works better for extreme scenarios of non_iid data, specially on datasets that were balanced at the beginnig


twitter_dep min 10 lr 3e-5 10x5
fedavg
fedprox

twitter_dep min 10 lr 6e-5 10x5
fedavg 79.29
fedprox 72.82

twitter_dep clients 20 min 0
fedavg 79.29
fedprox  77.18%

twitter_dep_balanced (less data) clients 20 min 0
fedavg 79.29
fedprox 79.94


twitter_dep clients 20 min 0
fedavg 79.29
fedprox 75.24



twitter_dep_balanced (less data) clients 20 min 10
fedavg 79.29
fedprox 79.94


acl_dep_sad clients 20 min 10
fedavg 87.08
fedprox 83.08

dreaddit clients 20 min 10
69.93
68.25
NO

