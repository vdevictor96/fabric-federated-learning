Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.0006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/6-ml_mode-data_dist-dp/6e-4/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 10,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Epoch [1/10], Step [100/496], Loss: 0.5513, Accuracy: 74.75 %
Epoch [1/10], Step [200/496], Loss: 0.5449, Accuracy: 74.25 %
Epoch [1/10], Step [300/496], Loss: 0.5591, Accuracy: 73.75 %
Epoch [1/10], Step [400/496], Loss: 0.5491, Accuracy: 74.06 %
-------------------------------
Epoch [1/10] Loss: 0.5398, Accuracy: 74.92 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4990, Validation Accuracy: 73.39 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Accuracy: 73.39 %
-------------------------------
Epoch [2/10], Step [100/496], Loss: 0.4632, Accuracy: 77.00 %
Epoch [2/10], Step [200/496], Loss: 0.4734, Accuracy: 77.75 %
Epoch [2/10], Step [300/496], Loss: 0.4729, Accuracy: 78.58 %
Epoch [2/10], Step [400/496], Loss: 0.4917, Accuracy: 76.81 %
-------------------------------
Epoch [2/10] Loss: 0.4913, Accuracy: 77.50 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5995, Validation Accuracy: 68.15 %
-------- Validation finished --------
Epoch [3/10], Step [100/496], Loss: 0.4489, Accuracy: 78.25 %
Epoch [3/10], Step [200/496], Loss: 0.4843, Accuracy: 77.62 %
Epoch [3/10], Step [300/496], Loss: 0.4574, Accuracy: 79.08 %
Epoch [3/10], Step [400/496], Loss: 0.4698, Accuracy: 78.62 %
-------------------------------
Epoch [3/10] Loss: 0.4534, Accuracy: 79.52 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5920, Validation Accuracy: 69.15 %
-------- Validation finished --------
Epoch [4/10], Step [100/496], Loss: 0.3805, Accuracy: 82.50 %
Epoch [4/10], Step [200/496], Loss: 0.4152, Accuracy: 80.00 %
Epoch [4/10], Step [300/496], Loss: 0.4090, Accuracy: 80.92 %
Epoch [4/10], Step [400/496], Loss: 0.4014, Accuracy: 81.62 %
-------------------------------
Epoch [4/10] Loss: 0.3959, Accuracy: 81.94 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5368, Validation Accuracy: 71.57 %
-------- Validation finished --------
Epoch [5/10], Step [100/496], Loss: 0.3857, Accuracy: 84.25 %
Epoch [5/10], Step [200/496], Loss: 0.3635, Accuracy: 85.38 %
Epoch [5/10], Step [300/496], Loss: 0.3599, Accuracy: 85.08 %
Epoch [5/10], Step [400/496], Loss: 0.3671, Accuracy: 84.88 %
-------------------------------
Epoch [5/10] Loss: 0.3675, Accuracy: 84.46 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4938, Validation Accuracy: 72.38 %
-------- Validation finished --------
Epoch [6/10], Step [100/496], Loss: 0.3275, Accuracy: 86.25 %
Epoch [6/10], Step [200/496], Loss: 0.2970, Accuracy: 87.25 %
Epoch [6/10], Step [300/496], Loss: 0.3171, Accuracy: 86.33 %
Epoch [6/10], Step [400/496], Loss: 0.3200, Accuracy: 86.31 %
-------------------------------
Epoch [6/10] Loss: 0.3166, Accuracy: 86.63 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5826, Validation Accuracy: 74.80 %
-------- Validation finished --------
Updated best model in epoch 6 saved with Validation Accuracy: 74.80 %
-------------------------------
Epoch [7/10], Step [100/496], Loss: 0.2833, Accuracy: 88.75 %
Epoch [7/10], Step [200/496], Loss: 0.3018, Accuracy: 87.75 %
Epoch [7/10], Step [300/496], Loss: 0.3124, Accuracy: 87.17 %
Epoch [7/10], Step [400/496], Loss: 0.3053, Accuracy: 87.25 %
-------------------------------
Epoch [7/10] Loss: 0.3084, Accuracy: 86.98 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4880, Validation Accuracy: 78.43 %
-------- Validation finished --------
Updated best model in epoch 7 saved with Validation Accuracy: 78.43 %
-------------------------------
Epoch [8/10], Step [100/496], Loss: 0.2286, Accuracy: 91.00 %
Epoch [8/10], Step [200/496], Loss: 0.2439, Accuracy: 90.12 %
Epoch [8/10], Step [300/496], Loss: 0.2412, Accuracy: 90.25 %
Epoch [8/10], Step [400/496], Loss: 0.2505, Accuracy: 89.69 %
-------------------------------
Epoch [8/10] Loss: 0.2494, Accuracy: 89.76 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6074, Validation Accuracy: 75.40 %
-------- Validation finished --------
Epoch [9/10], Step [100/496], Loss: 0.1913, Accuracy: 92.00 %
Epoch [9/10], Step [200/496], Loss: 0.1924, Accuracy: 92.38 %
Epoch [9/10], Step [300/496], Loss: 0.2036, Accuracy: 91.67 %
Epoch [9/10], Step [400/496], Loss: 0.2036, Accuracy: 91.50 %
-------------------------------
Epoch [9/10] Loss: 0.2113, Accuracy: 91.32 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5419, Validation Accuracy: 77.02 %
-------- Validation finished --------
Epoch [10/10], Step [100/496], Loss: 0.2036, Accuracy: 91.50 %
Epoch [10/10], Step [200/496], Loss: 0.2137, Accuracy: 91.75 %
Epoch [10/10], Step [300/496], Loss: 0.2103, Accuracy: 91.83 %
Epoch [10/10], Step [400/496], Loss: 0.2152, Accuracy: 91.69 %
-------------------------------
Epoch [10/10] Loss: 0.2083, Accuracy: 92.03 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5925, Validation Accuracy: 76.01 %
-------- Validation finished --------
Best model in epoch 7 saved with Validation Accuracy: 78.43 %

-------- Training finished in 18:45 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 06-02-2024 13:06. Trained with Centralised Machine Learning technology.
Epoch 7, lr: 0.0006, optimizer: AdamW
Train accuracy: 86.98 %, Validation accuracy: 78.43 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
NÂº of test samples: 618
Accuracy: 79.13%
Precision: 73.62%
Recall: 72.80%
F1 Score: 73.18%
-------- Testing finished --------
