Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "dreaddit",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 10,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_10_dreaddit",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/6-ml_mode-model-data_dist-dp/dreaddit",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 10,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 2270 total sentences. 568 batches of size 4.
Eval Loader: 568 total sentences. 142 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Epoch [1/10], Step [100/568], Loss: 0.7212, Accuracy: 49.00 %
Epoch [1/10], Step [200/568], Loss: 0.7237, Accuracy: 48.75 %
Epoch [1/10], Step [300/568], Loss: 0.7232, Accuracy: 48.92 %
Epoch [1/10], Step [400/568], Loss: 0.7171, Accuracy: 49.81 %
Epoch [1/10], Step [500/568], Loss: 0.7136, Accuracy: 50.05 %
-------------------------------
Epoch [1/10] Loss: 0.7123, Accuracy: 49.87 %
-------------------------------
-------- Validation --------
Validation Loss: 0.7017, Validation Accuracy: 45.95 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Accuracy: 45.95 %
-------------------------------
Epoch [2/10], Step [100/568], Loss: 0.6987, Accuracy: 49.00 %
Epoch [2/10], Step [200/568], Loss: 0.6889, Accuracy: 51.62 %
Epoch [2/10], Step [300/568], Loss: 0.6848, Accuracy: 53.25 %
Epoch [2/10], Step [400/568], Loss: 0.6829, Accuracy: 54.50 %
Epoch [2/10], Step [500/568], Loss: 0.6824, Accuracy: 54.80 %
-------------------------------
Epoch [2/10] Loss: 0.6819, Accuracy: 54.93 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6709, Validation Accuracy: 62.85 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Accuracy: 62.85 %
-------------------------------
Epoch [3/10], Step [100/568], Loss: 0.6852, Accuracy: 53.50 %
Epoch [3/10], Step [200/568], Loss: 0.6787, Accuracy: 57.62 %
Epoch [3/10], Step [300/568], Loss: 0.6758, Accuracy: 57.92 %
Epoch [3/10], Step [400/568], Loss: 0.6725, Accuracy: 59.06 %
Epoch [3/10], Step [500/568], Loss: 0.6747, Accuracy: 58.95 %
-------------------------------
Epoch [3/10] Loss: 0.6728, Accuracy: 59.07 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6536, Validation Accuracy: 61.97 %
-------- Validation finished --------
Epoch [4/10], Step [100/568], Loss: 0.6642, Accuracy: 58.25 %
Epoch [4/10], Step [200/568], Loss: 0.6685, Accuracy: 58.00 %
Epoch [4/10], Step [300/568], Loss: 0.6649, Accuracy: 58.92 %
Epoch [4/10], Step [400/568], Loss: 0.6691, Accuracy: 58.62 %
Epoch [4/10], Step [500/568], Loss: 0.6646, Accuracy: 59.50 %
-------------------------------
Epoch [4/10] Loss: 0.6642, Accuracy: 59.74 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6470, Validation Accuracy: 62.50 %
-------- Validation finished --------
Epoch [5/10], Step [100/568], Loss: 0.6712, Accuracy: 58.00 %
Epoch [5/10], Step [200/568], Loss: 0.6669, Accuracy: 58.62 %
Epoch [5/10], Step [300/568], Loss: 0.6610, Accuracy: 58.92 %
Epoch [5/10], Step [400/568], Loss: 0.6625, Accuracy: 58.62 %
Epoch [5/10], Step [500/568], Loss: 0.6668, Accuracy: 57.30 %
-------------------------------
Epoch [5/10] Loss: 0.6657, Accuracy: 57.53 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6461, Validation Accuracy: 61.09 %
-------- Validation finished --------
Epoch [6/10], Step [100/568], Loss: 0.6837, Accuracy: 55.75 %
Epoch [6/10], Step [200/568], Loss: 0.6760, Accuracy: 56.25 %
Epoch [6/10], Step [300/568], Loss: 0.6729, Accuracy: 57.25 %
Epoch [6/10], Step [400/568], Loss: 0.6745, Accuracy: 57.25 %
Epoch [6/10], Step [500/568], Loss: 0.6740, Accuracy: 57.75 %
-------------------------------
Epoch [6/10] Loss: 0.6766, Accuracy: 57.36 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6508, Validation Accuracy: 60.74 %
-------- Validation finished --------
Epoch [7/10], Step [100/568], Loss: 0.6969, Accuracy: 52.50 %
Epoch [7/10], Step [200/568], Loss: 0.6744, Accuracy: 55.88 %
Epoch [7/10], Step [300/568], Loss: 0.6636, Accuracy: 57.58 %
Epoch [7/10], Step [400/568], Loss: 0.6736, Accuracy: 56.25 %
Epoch [7/10], Step [500/568], Loss: 0.6787, Accuracy: 55.55 %
-------------------------------
Epoch [7/10] Loss: 0.6821, Accuracy: 55.20 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6567, Validation Accuracy: 60.04 %
-------- Validation finished --------
Epoch [8/10], Step [100/568], Loss: 0.6733, Accuracy: 56.25 %
Epoch [8/10], Step [200/568], Loss: 0.6795, Accuracy: 56.12 %
Epoch [8/10], Step [300/568], Loss: 0.6885, Accuracy: 54.92 %
Epoch [8/10], Step [400/568], Loss: 0.6978, Accuracy: 53.62 %
Epoch [8/10], Step [500/568], Loss: 0.6961, Accuracy: 53.80 %
-------------------------------
Epoch [8/10] Loss: 0.6950, Accuracy: 54.23 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6609, Validation Accuracy: 60.04 %
-------- Validation finished --------
Epoch [9/10], Step [100/568], Loss: 0.7140, Accuracy: 53.00 %
Epoch [9/10], Step [200/568], Loss: 0.7063, Accuracy: 54.12 %
Epoch [9/10], Step [300/568], Loss: 0.6962, Accuracy: 55.50 %
Epoch [9/10], Step [400/568], Loss: 0.6999, Accuracy: 55.12 %
Epoch [9/10], Step [500/568], Loss: 0.7006, Accuracy: 54.90 %
-------------------------------
Epoch [9/10] Loss: 0.6949, Accuracy: 55.29 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6633, Validation Accuracy: 60.04 %
-------- Validation finished --------
Epoch [10/10], Step [100/568], Loss: 0.7074, Accuracy: 53.25 %
Epoch [10/10], Step [200/568], Loss: 0.7069, Accuracy: 53.25 %
Epoch [10/10], Step [300/568], Loss: 0.7092, Accuracy: 53.42 %
Epoch [10/10], Step [400/568], Loss: 0.7082, Accuracy: 53.75 %
Epoch [10/10], Step [500/568], Loss: 0.6970, Accuracy: 55.00 %
-------------------------------
Epoch [10/10] Loss: 0.6965, Accuracy: 54.89 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6638, Validation Accuracy: 60.04 %
-------- Validation finished --------
Best model in epoch 2 saved with Validation Accuracy: 62.85 %

-------- Training finished in 14:57 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 06-02-2024 09:49. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 6e-05, optimizer: DPOptimizer
Train accuracy: 54.93 %, Validation accuracy: 62.85 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 715 total sentences. 90 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
NÂº of test samples: 715
Accuracy: 60.56%
Precision: 61.67%
Recall: 59.95%
F1 Score: 58.77%
-------- Testing finished --------
