Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda:1",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 4,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_bert_small_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/3-ml_mode-model-datasets/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 10,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda:1 device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 4 layers.

Total parameters count: 28764674
Trainable parameters count: 6568450
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Epoch [1/10], Step [100/496], Loss: 0.5278, Accuracy: 75.50 %
Epoch [1/10], Step [200/496], Loss: 0.5153, Accuracy: 75.75 %
Epoch [1/10], Step [300/496], Loss: 0.5112, Accuracy: 75.92 %
Epoch [1/10], Step [400/496], Loss: 0.4911, Accuracy: 77.00 %
-------------------------------
Epoch [1/10] Loss: 0.4887, Accuracy: 76.94 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4751, Validation Accuracy: 77.02 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Accuracy: 77.02 %
-------------------------------
Epoch [2/10], Step [100/496], Loss: 0.3518, Accuracy: 84.00 %
Epoch [2/10], Step [200/496], Loss: 0.3495, Accuracy: 84.00 %
Epoch [2/10], Step [300/496], Loss: 0.3548, Accuracy: 83.83 %
Epoch [2/10], Step [400/496], Loss: 0.3590, Accuracy: 83.88 %
-------------------------------
Epoch [2/10] Loss: 0.3574, Accuracy: 84.01 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5240, Validation Accuracy: 76.21 %
-------- Validation finished --------
Epoch [3/10], Step [100/496], Loss: 0.2744, Accuracy: 89.75 %
Epoch [3/10], Step [200/496], Loss: 0.2618, Accuracy: 89.88 %
Epoch [3/10], Step [300/496], Loss: 0.2501, Accuracy: 90.67 %
Epoch [3/10], Step [400/496], Loss: 0.2648, Accuracy: 89.31 %
-------------------------------
Epoch [3/10] Loss: 0.2538, Accuracy: 89.96 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6437, Validation Accuracy: 71.98 %
-------- Validation finished --------
Epoch [4/10], Step [100/496], Loss: 0.1240, Accuracy: 95.25 %
Epoch [4/10], Step [200/496], Loss: 0.1402, Accuracy: 94.62 %
Epoch [4/10], Step [300/496], Loss: 0.1500, Accuracy: 94.42 %
Epoch [4/10], Step [400/496], Loss: 0.1550, Accuracy: 94.12 %
-------------------------------
Epoch [4/10] Loss: 0.1448, Accuracy: 94.50 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6558, Validation Accuracy: 78.23 %
-------- Validation finished --------
Updated best model in epoch 4 saved with Validation Accuracy: 78.23 %
-------------------------------
Epoch [5/10], Step [100/496], Loss: 0.0670, Accuracy: 98.00 %
Epoch [5/10], Step [200/496], Loss: 0.0818, Accuracy: 97.00 %
Epoch [5/10], Step [300/496], Loss: 0.0861, Accuracy: 97.08 %
Epoch [5/10], Step [400/496], Loss: 0.0895, Accuracy: 96.69 %
-------------------------------
Epoch [5/10] Loss: 0.0883, Accuracy: 96.72 %
-------------------------------
-------- Validation --------
Validation Loss: 0.6772, Validation Accuracy: 80.24 %
-------- Validation finished --------
Updated best model in epoch 5 saved with Validation Accuracy: 80.24 %
-------------------------------
Epoch [6/10], Step [100/496], Loss: 0.0381, Accuracy: 98.50 %
Epoch [6/10], Step [200/496], Loss: 0.0402, Accuracy: 98.50 %
Epoch [6/10], Step [300/496], Loss: 0.0475, Accuracy: 98.08 %
Epoch [6/10], Step [400/496], Loss: 0.0561, Accuracy: 97.62 %
-------------------------------
Epoch [6/10] Loss: 0.0549, Accuracy: 97.73 %
-------------------------------
-------- Validation --------
Validation Loss: 0.8349, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [7/10], Step [100/496], Loss: 0.0192, Accuracy: 99.00 %
Epoch [7/10], Step [200/496], Loss: 0.0219, Accuracy: 99.38 %
Epoch [7/10], Step [300/496], Loss: 0.0259, Accuracy: 99.33 %
Epoch [7/10], Step [400/496], Loss: 0.0263, Accuracy: 99.19 %
-------------------------------
Epoch [7/10] Loss: 0.0249, Accuracy: 99.19 %
-------------------------------
-------- Validation --------
Validation Loss: 0.9638, Validation Accuracy: 78.83 %
-------- Validation finished --------
Epoch [8/10], Step [100/496], Loss: 0.0116, Accuracy: 99.75 %
Epoch [8/10], Step [200/496], Loss: 0.0248, Accuracy: 99.25 %
Epoch [8/10], Step [300/496], Loss: 0.0224, Accuracy: 99.42 %
Epoch [8/10], Step [400/496], Loss: 0.0241, Accuracy: 99.25 %
-------------------------------
Epoch [8/10] Loss: 0.0225, Accuracy: 99.34 %
-------------------------------
-------- Validation --------
Validation Loss: 1.0206, Validation Accuracy: 78.02 %
-------- Validation finished --------
Epoch [9/10], Step [100/496], Loss: 0.0156, Accuracy: 99.50 %
Epoch [9/10], Step [200/496], Loss: 0.0118, Accuracy: 99.62 %
Epoch [9/10], Step [300/496], Loss: 0.0181, Accuracy: 99.42 %
Epoch [9/10], Step [400/496], Loss: 0.0175, Accuracy: 99.38 %
-------------------------------
Epoch [9/10] Loss: 0.0170, Accuracy: 99.39 %
-------------------------------
-------- Validation --------
Validation Loss: 0.9970, Validation Accuracy: 79.23 %
-------- Validation finished --------
Epoch [10/10], Step [100/496], Loss: 0.0054, Accuracy: 100.00 %
Epoch [10/10], Step [200/496], Loss: 0.0102, Accuracy: 99.75 %
Epoch [10/10], Step [300/496], Loss: 0.0125, Accuracy: 99.67 %
Epoch [10/10], Step [400/496], Loss: 0.0152, Accuracy: 99.44 %
-------------------------------
Epoch [10/10] Loss: 0.0151, Accuracy: 99.45 %
-------------------------------
-------- Validation --------
Validation Loss: 1.0340, Validation Accuracy: 76.81 %
-------- Validation finished --------
Best model in epoch 5 saved with Validation Accuracy: 80.24 %

-------- Training finished in 6:12 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 12-03-2024 13:34. Trained with Centralised Machine Learning technology.
Epoch 5, lr: 6e-05, optimizer: AdamW
Train accuracy: 96.72 %, Validation accuracy: 80.24 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
NÂº of test samples: 618
Accuracy: 81.07%
Precision: 77.09%
Recall: 72.08%
F1 Score: 73.83%
-------- Testing finished --------
