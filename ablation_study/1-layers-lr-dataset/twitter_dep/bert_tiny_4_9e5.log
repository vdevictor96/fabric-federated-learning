Current configuration:
{
    "concurrency_flag": false,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 4,
    "learning_rate": 9e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_tiny",
    "model_name": "bert_tiny_4_9e5",
    "models_path": "/local/vpaloma/ablation_study/layers-lr/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 10,
    "num_rounds": 5,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": 0,
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 4 layers.

Total parameters count: 4386178
Trainable parameters count: 413314
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Epoch [1/10], Step [100/496], Loss: 0.6047, Accuracy: 71.25 %
Epoch [1/10], Step [200/496], Loss: 0.5906, Accuracy: 70.88 %
Epoch [1/10], Step [300/496], Loss: 0.5664, Accuracy: 72.58 %
Epoch [1/10], Step [400/496], Loss: 0.5489, Accuracy: 73.94 %
-------------------------------
Epoch [1/10] Loss: 0.5316, Accuracy: 74.72 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4997, Validation Accuracy: 77.82 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Accuracy: 77.82 %
-------------------------------
Epoch [2/10], Step [100/496], Loss: 0.4619, Accuracy: 80.50 %
Epoch [2/10], Step [200/496], Loss: 0.4602, Accuracy: 79.62 %
Epoch [2/10], Step [300/496], Loss: 0.4599, Accuracy: 79.33 %
Epoch [2/10], Step [400/496], Loss: 0.4572, Accuracy: 79.31 %
-------------------------------
Epoch [2/10] Loss: 0.4606, Accuracy: 78.51 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4906, Validation Accuracy: 75.40 %
-------- Validation finished --------
Epoch [3/10], Step [100/496], Loss: 0.4150, Accuracy: 81.00 %
Epoch [3/10], Step [200/496], Loss: 0.4356, Accuracy: 79.50 %
Epoch [3/10], Step [300/496], Loss: 0.4253, Accuracy: 80.92 %
Epoch [3/10], Step [400/496], Loss: 0.4143, Accuracy: 81.62 %
-------------------------------
Epoch [3/10] Loss: 0.4166, Accuracy: 81.43 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4704, Validation Accuracy: 76.21 %
-------- Validation finished --------
Epoch [4/10], Step [100/496], Loss: 0.3902, Accuracy: 81.50 %
Epoch [4/10], Step [200/496], Loss: 0.4034, Accuracy: 81.25 %
Epoch [4/10], Step [300/496], Loss: 0.4010, Accuracy: 81.17 %
Epoch [4/10], Step [400/496], Loss: 0.3929, Accuracy: 81.69 %
-------------------------------
Epoch [4/10] Loss: 0.3936, Accuracy: 81.53 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4694, Validation Accuracy: 78.02 %
-------- Validation finished --------
Updated best model in epoch 4 saved with Validation Accuracy: 78.02 %
-------------------------------
Epoch [5/10], Step [100/496], Loss: 0.3602, Accuracy: 83.00 %
Epoch [5/10], Step [200/496], Loss: 0.3883, Accuracy: 81.88 %
Epoch [5/10], Step [300/496], Loss: 0.3728, Accuracy: 82.75 %
Epoch [5/10], Step [400/496], Loss: 0.3673, Accuracy: 83.19 %
-------------------------------
Epoch [5/10] Loss: 0.3655, Accuracy: 83.91 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4598, Validation Accuracy: 79.44 %
-------- Validation finished --------
Updated best model in epoch 5 saved with Validation Accuracy: 79.44 %
-------------------------------
Epoch [6/10], Step [100/496], Loss: 0.3323, Accuracy: 86.50 %
Epoch [6/10], Step [200/496], Loss: 0.3377, Accuracy: 86.00 %
Epoch [6/10], Step [300/496], Loss: 0.3525, Accuracy: 84.92 %
Epoch [6/10], Step [400/496], Loss: 0.3597, Accuracy: 84.44 %
-------------------------------
Epoch [6/10] Loss: 0.3571, Accuracy: 84.21 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4883, Validation Accuracy: 77.02 %
-------- Validation finished --------
Epoch [7/10], Step [100/496], Loss: 0.4021, Accuracy: 81.00 %
Epoch [7/10], Step [200/496], Loss: 0.3642, Accuracy: 83.75 %
Epoch [7/10], Step [300/496], Loss: 0.3490, Accuracy: 84.00 %
Epoch [7/10], Step [400/496], Loss: 0.3385, Accuracy: 84.81 %
-------------------------------
Epoch [7/10] Loss: 0.3336, Accuracy: 85.22 %
-------------------------------
-------- Validation --------
Validation Loss: 0.4811, Validation Accuracy: 79.44 %
-------- Validation finished --------
Updated best model in epoch 7 saved with Validation Accuracy: 79.44 %
-------------------------------
Epoch [8/10], Step [100/496], Loss: 0.3206, Accuracy: 86.00 %
Epoch [8/10], Step [200/496], Loss: 0.3325, Accuracy: 84.75 %
Epoch [8/10], Step [300/496], Loss: 0.3170, Accuracy: 85.83 %
Epoch [8/10], Step [400/496], Loss: 0.3207, Accuracy: 86.25 %
-------------------------------
Epoch [8/10] Loss: 0.3173, Accuracy: 86.18 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5196, Validation Accuracy: 77.22 %
-------- Validation finished --------
Epoch [9/10], Step [100/496], Loss: 0.2961, Accuracy: 89.00 %
Epoch [9/10], Step [200/496], Loss: 0.2983, Accuracy: 88.50 %
Epoch [9/10], Step [300/496], Loss: 0.2995, Accuracy: 88.25 %
Epoch [9/10], Step [400/496], Loss: 0.2858, Accuracy: 88.25 %
-------------------------------
Epoch [9/10] Loss: 0.2889, Accuracy: 87.94 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5197, Validation Accuracy: 78.02 %
-------- Validation finished --------
Epoch [10/10], Step [100/496], Loss: 0.2716, Accuracy: 87.75 %
Epoch [10/10], Step [200/496], Loss: 0.2942, Accuracy: 86.75 %
Epoch [10/10], Step [300/496], Loss: 0.3009, Accuracy: 86.33 %
Epoch [10/10], Step [400/496], Loss: 0.3043, Accuracy: 86.44 %
-------------------------------
Epoch [10/10] Loss: 0.3012, Accuracy: 86.63 %
-------------------------------
-------- Validation --------
Validation Loss: 0.5065, Validation Accuracy: 77.82 %
-------- Validation finished --------
Best model in epoch 7 saved with Validation Accuracy: 79.44 %
-------- Training finished --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-tiny from date 01-02-2024 09:01. Trained with Centralised Machine Learning technology.
Epoch 7, lr: 9e-05, optimizer: AdamW
Train accuracy: 85.22 %, Validation accuracy: 79.44 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
NÂº of test samples: 618
Accuracy: 81.72%
Precision: 77.55%
Recall: 74.02%
F1 Score: 75.41%
-------- Testing finished --------
