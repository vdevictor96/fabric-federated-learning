Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_medium",
    "model_name": "ml_medium_seed7_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/accs-times/twitter_dep/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  260276
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 41374210
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5429, Accuracy: 73.25 %
Epoch [1/12], Step [200/496], Loss: 0.4832, Accuracy: 76.38 %
Epoch [1/12], Step [300/496], Loss: 0.4896, Accuracy: 76.33 %
Epoch [1/12], Step [400/496], Loss: 0.4793, Accuracy: 77.12 %
Predictions - 1s: 363, 0s: 1619
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [1/12] Loss: 0.4727, Accuracy: 77.25 %
-------------------------------
-------- Validation --------
Predictions - 1s: 119, 0s: 377
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.4378, Validation Accuracy: 78.02 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.4378 and Validation Accuracy: 78.02 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.3911, Accuracy: 82.00 %
Epoch [2/12], Step [200/496], Loss: 0.3984, Accuracy: 81.75 %
Epoch [2/12], Step [300/496], Loss: 0.4004, Accuracy: 81.50 %
Epoch [2/12], Step [400/496], Loss: 0.3830, Accuracy: 82.81 %
Predictions - 1s: 452, 0s: 1530
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [2/12] Loss: 0.3886, Accuracy: 82.44 %
-------------------------------
-------- Validation --------
Predictions - 1s: 116, 0s: 380
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.4186, Validation Accuracy: 81.05 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 0.4186 and Validation Accuracy: 81.05 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 0.3323, Accuracy: 88.00 %
Epoch [3/12], Step [200/496], Loss: 0.3431, Accuracy: 85.88 %
Epoch [3/12], Step [300/496], Loss: 0.3465, Accuracy: 85.42 %
Epoch [3/12], Step [400/496], Loss: 0.3316, Accuracy: 86.19 %
Predictions - 1s: 489, 0s: 1493
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [3/12] Loss: 0.3408, Accuracy: 85.42 %
-------------------------------
-------- Validation --------
Predictions - 1s: 69, 0s: 427
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.4246, Validation Accuracy: 81.25 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 0.2686, Accuracy: 88.75 %
Epoch [4/12], Step [200/496], Loss: 0.2818, Accuracy: 87.75 %
Epoch [4/12], Step [300/496], Loss: 0.2864, Accuracy: 87.50 %
Epoch [4/12], Step [400/496], Loss: 0.2867, Accuracy: 87.56 %
Predictions - 1s: 498, 0s: 1484
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [4/12] Loss: 0.2811, Accuracy: 87.59 %
-------------------------------
-------- Validation --------
Predictions - 1s: 104, 0s: 392
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.4702, Validation Accuracy: 81.85 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 0.2221, Accuracy: 90.75 %
Epoch [5/12], Step [200/496], Loss: 0.2076, Accuracy: 91.62 %
Epoch [5/12], Step [300/496], Loss: 0.2166, Accuracy: 90.33 %
Epoch [5/12], Step [400/496], Loss: 0.2103, Accuracy: 90.81 %
Predictions - 1s: 524, 0s: 1458
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [5/12] Loss: 0.2200, Accuracy: 90.11 %
-------------------------------
-------- Validation --------
Predictions - 1s: 106, 0s: 390
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.4734, Validation Accuracy: 80.65 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 0.1706, Accuracy: 93.25 %
Epoch [6/12], Step [200/496], Loss: 0.1735, Accuracy: 92.88 %
Epoch [6/12], Step [300/496], Loss: 0.1694, Accuracy: 93.17 %
Epoch [6/12], Step [400/496], Loss: 0.1668, Accuracy: 93.31 %
Predictions - 1s: 536, 0s: 1446
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [6/12] Loss: 0.1679, Accuracy: 93.34 %
-------------------------------
-------- Validation --------
Predictions - 1s: 117, 0s: 379
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.5396, Validation Accuracy: 79.23 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.1050, Accuracy: 96.25 %
Epoch [7/12], Step [200/496], Loss: 0.1299, Accuracy: 95.50 %
Epoch [7/12], Step [300/496], Loss: 0.1213, Accuracy: 95.92 %
Epoch [7/12], Step [400/496], Loss: 0.1174, Accuracy: 95.94 %
Predictions - 1s: 535, 0s: 1447
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [7/12] Loss: 0.1186, Accuracy: 95.61 %
-------------------------------
-------- Validation --------
Predictions - 1s: 146, 0s: 350
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.6487, Validation Accuracy: 77.42 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.0819, Accuracy: 97.75 %
Epoch [8/12], Step [200/496], Loss: 0.0892, Accuracy: 97.25 %
Epoch [8/12], Step [300/496], Loss: 0.0860, Accuracy: 97.42 %
Epoch [8/12], Step [400/496], Loss: 0.0834, Accuracy: 97.44 %
Predictions - 1s: 542, 0s: 1440
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [8/12] Loss: 0.0877, Accuracy: 96.97 %
-------------------------------
-------- Validation --------
Predictions - 1s: 171, 0s: 325
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.8677, Validation Accuracy: 76.41 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.0838, Accuracy: 96.75 %
Epoch [9/12], Step [200/496], Loss: 0.0868, Accuracy: 96.75 %
Epoch [9/12], Step [300/496], Loss: 0.0824, Accuracy: 96.75 %
Epoch [9/12], Step [400/496], Loss: 0.0783, Accuracy: 97.00 %
Predictions - 1s: 555, 0s: 1427
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [9/12] Loss: 0.0766, Accuracy: 97.12 %
-------------------------------
-------- Validation --------
Predictions - 1s: 129, 0s: 367
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.7507, Validation Accuracy: 79.23 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.0632, Accuracy: 97.75 %
Epoch [10/12], Step [200/496], Loss: 0.0608, Accuracy: 98.12 %
Epoch [10/12], Step [300/496], Loss: 0.0620, Accuracy: 97.92 %
Epoch [10/12], Step [400/496], Loss: 0.0660, Accuracy: 97.88 %
Predictions - 1s: 546, 0s: 1436
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [10/12] Loss: 0.0665, Accuracy: 97.78 %
-------------------------------
-------- Validation --------
Predictions - 1s: 137, 0s: 359
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.7486, Validation Accuracy: 77.62 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.0477, Accuracy: 98.50 %
Epoch [11/12], Step [200/496], Loss: 0.0491, Accuracy: 98.25 %
Epoch [11/12], Step [300/496], Loss: 0.0489, Accuracy: 98.33 %
Epoch [11/12], Step [400/496], Loss: 0.0491, Accuracy: 98.44 %
Predictions - 1s: 554, 0s: 1428
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [11/12] Loss: 0.0503, Accuracy: 98.28 %
-------------------------------
-------- Validation --------
Predictions - 1s: 122, 0s: 374
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.7598, Validation Accuracy: 79.03 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.0324, Accuracy: 99.00 %
Epoch [12/12], Step [200/496], Loss: 0.0413, Accuracy: 98.75 %
Epoch [12/12], Step [300/496], Loss: 0.0441, Accuracy: 98.58 %
Epoch [12/12], Step [400/496], Loss: 0.0429, Accuracy: 98.75 %
Predictions - 1s: 553, 0s: 1429
True Labels - 1s: 556, 0s: 1426
-------------------------------
Epoch [12/12] Loss: 0.0423, Accuracy: 98.64 %
-------------------------------
-------- Validation --------
Predictions - 1s: 132, 0s: 364
True Labels - 1s: 118, 0s: 378
Validation Loss: 0.7807, Validation Accuracy: 79.03 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 0.4186 and Validation Accuracy: 81.05 %

-------- Training finished in 2:24 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-medium from date 20-04-2024 09:37. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 6e-05, optimizer: AdamW
Train accuracy: 82.44 %, Validation accuracy: 81.05 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 156, 0s: 462
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 81.88%
Accuracy 2 : 81.88%
Precision: 77.26%
Recall: 75.99%
F1 Score: 76.58%
Classification report:
              precision    recall  f1-score   support

           0     0.8658    0.8889    0.8772       450
           1     0.6795    0.6310    0.6543       168

    accuracy                         0.8188       618
   macro avg     0.7726    0.7599    0.7658       618
weighted avg     0.8152    0.8188    0.8166       618

-------- Testing finished --------
