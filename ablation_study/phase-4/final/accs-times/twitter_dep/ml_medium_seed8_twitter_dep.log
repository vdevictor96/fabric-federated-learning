Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_medium",
    "model_name": "ml_medium_seed8_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/accs-times/twitter_dep/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  190264
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 41374210
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5505, Accuracy: 72.25 %
Epoch [1/12], Step [200/496], Loss: 0.5167, Accuracy: 74.25 %
Epoch [1/12], Step [300/496], Loss: 0.5058, Accuracy: 75.33 %
Epoch [1/12], Step [400/496], Loss: 0.4986, Accuracy: 75.00 %
Predictions - 1s: 321, 0s: 1661
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [1/12] Loss: 0.4891, Accuracy: 75.68 %
-------------------------------
-------- Validation --------
Predictions - 1s: 51, 0s: 445
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.4094, Validation Accuracy: 80.65 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.4094 and Validation Accuracy: 80.65 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.4087, Accuracy: 78.50 %
Epoch [2/12], Step [200/496], Loss: 0.3803, Accuracy: 81.12 %
Epoch [2/12], Step [300/496], Loss: 0.3782, Accuracy: 82.17 %
Epoch [2/12], Step [400/496], Loss: 0.4025, Accuracy: 81.19 %
Predictions - 1s: 419, 0s: 1563
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [2/12] Loss: 0.4055, Accuracy: 81.23 %
-------------------------------
-------- Validation --------
Predictions - 1s: 117, 0s: 379
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.3725, Validation Accuracy: 82.66 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 0.3725 and Validation Accuracy: 82.66 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 0.3612, Accuracy: 83.25 %
Epoch [3/12], Step [200/496], Loss: 0.3541, Accuracy: 84.38 %
Epoch [3/12], Step [300/496], Loss: 0.3551, Accuracy: 84.08 %
Epoch [3/12], Step [400/496], Loss: 0.3434, Accuracy: 84.31 %
Predictions - 1s: 460, 0s: 1522
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [3/12] Loss: 0.3382, Accuracy: 84.41 %
-------------------------------
-------- Validation --------
Predictions - 1s: 135, 0s: 361
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.3854, Validation Accuracy: 83.06 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 0.3103, Accuracy: 85.50 %
Epoch [4/12], Step [200/496], Loss: 0.3008, Accuracy: 86.12 %
Epoch [4/12], Step [300/496], Loss: 0.3010, Accuracy: 86.08 %
Epoch [4/12], Step [400/496], Loss: 0.2977, Accuracy: 86.19 %
Predictions - 1s: 493, 0s: 1489
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [4/12] Loss: 0.2944, Accuracy: 86.38 %
-------------------------------
-------- Validation --------
Predictions - 1s: 96, 0s: 400
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.3855, Validation Accuracy: 83.27 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 0.2009, Accuracy: 90.75 %
Epoch [5/12], Step [200/496], Loss: 0.2096, Accuracy: 90.00 %
Epoch [5/12], Step [300/496], Loss: 0.2143, Accuracy: 90.42 %
Epoch [5/12], Step [400/496], Loss: 0.2132, Accuracy: 90.31 %
Predictions - 1s: 504, 0s: 1478
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [5/12] Loss: 0.2183, Accuracy: 89.86 %
-------------------------------
-------- Validation --------
Predictions - 1s: 106, 0s: 390
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.4384, Validation Accuracy: 82.06 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 0.1821, Accuracy: 92.25 %
Epoch [6/12], Step [200/496], Loss: 0.1645, Accuracy: 93.25 %
Epoch [6/12], Step [300/496], Loss: 0.1605, Accuracy: 93.25 %
Epoch [6/12], Step [400/496], Loss: 0.1733, Accuracy: 92.12 %
Predictions - 1s: 525, 0s: 1457
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [6/12] Loss: 0.1733, Accuracy: 92.33 %
-------------------------------
-------- Validation --------
Predictions - 1s: 111, 0s: 385
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.4549, Validation Accuracy: 82.66 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.1507, Accuracy: 93.75 %
Epoch [7/12], Step [200/496], Loss: 0.1415, Accuracy: 93.50 %
Epoch [7/12], Step [300/496], Loss: 0.1408, Accuracy: 93.50 %
Epoch [7/12], Step [400/496], Loss: 0.1340, Accuracy: 94.25 %
Predictions - 1s: 533, 0s: 1449
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [7/12] Loss: 0.1292, Accuracy: 94.75 %
-------------------------------
-------- Validation --------
Predictions - 1s: 128, 0s: 368
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.5295, Validation Accuracy: 82.46 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.0863, Accuracy: 97.25 %
Epoch [8/12], Step [200/496], Loss: 0.0916, Accuracy: 96.75 %
Epoch [8/12], Step [300/496], Loss: 0.0945, Accuracy: 96.50 %
Epoch [8/12], Step [400/496], Loss: 0.0916, Accuracy: 96.69 %
Predictions - 1s: 532, 0s: 1450
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [8/12] Loss: 0.0959, Accuracy: 96.52 %
-------------------------------
-------- Validation --------
Predictions - 1s: 114, 0s: 382
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.5642, Validation Accuracy: 82.46 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.0654, Accuracy: 97.75 %
Epoch [9/12], Step [200/496], Loss: 0.0734, Accuracy: 97.12 %
Epoch [9/12], Step [300/496], Loss: 0.0786, Accuracy: 96.92 %
Epoch [9/12], Step [400/496], Loss: 0.0796, Accuracy: 96.75 %
Predictions - 1s: 544, 0s: 1438
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [9/12] Loss: 0.0783, Accuracy: 96.82 %
-------------------------------
-------- Validation --------
Predictions - 1s: 110, 0s: 386
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.6175, Validation Accuracy: 82.86 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.0765, Accuracy: 97.00 %
Epoch [10/12], Step [200/496], Loss: 0.0728, Accuracy: 97.25 %
Epoch [10/12], Step [300/496], Loss: 0.0683, Accuracy: 97.58 %
Epoch [10/12], Step [400/496], Loss: 0.0625, Accuracy: 97.88 %
Predictions - 1s: 539, 0s: 1443
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [10/12] Loss: 0.0602, Accuracy: 98.08 %
-------------------------------
-------- Validation --------
Predictions - 1s: 123, 0s: 373
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.6384, Validation Accuracy: 81.05 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.0442, Accuracy: 98.25 %
Epoch [11/12], Step [200/496], Loss: 0.0443, Accuracy: 98.38 %
Epoch [11/12], Step [300/496], Loss: 0.0447, Accuracy: 98.33 %
Epoch [11/12], Step [400/496], Loss: 0.0463, Accuracy: 98.19 %
Predictions - 1s: 540, 0s: 1442
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [11/12] Loss: 0.0496, Accuracy: 98.13 %
-------------------------------
-------- Validation --------
Predictions - 1s: 101, 0s: 395
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.6780, Validation Accuracy: 82.26 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.0489, Accuracy: 97.50 %
Epoch [12/12], Step [200/496], Loss: 0.0491, Accuracy: 97.62 %
Epoch [12/12], Step [300/496], Loss: 0.0444, Accuracy: 98.17 %
Epoch [12/12], Step [400/496], Loss: 0.0425, Accuracy: 98.38 %
Predictions - 1s: 534, 0s: 1448
True Labels - 1s: 543, 0s: 1439
-------------------------------
Epoch [12/12] Loss: 0.0494, Accuracy: 98.23 %
-------------------------------
-------- Validation --------
Predictions - 1s: 111, 0s: 385
True Labels - 1s: 131, 0s: 365
Validation Loss: 0.6623, Validation Accuracy: 82.66 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 0.3725 and Validation Accuracy: 82.66 %

-------- Training finished in 2:24 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-medium from date 20-04-2024 09:42. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 6e-05, optimizer: AdamW
Train accuracy: 81.23 %, Validation accuracy: 82.66 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 137, 0s: 481
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 83.33%
Accuracy 2 : 83.33%
Precision: 79.90%
Recall: 76.06%
F1 Score: 77.58%
Classification report:
              precision    recall  f1-score   support

           0     0.8607    0.9200    0.8894       450
           1     0.7372    0.6012    0.6623       168

    accuracy                         0.8333       618
   macro avg     0.7990    0.7606    0.7758       618
weighted avg     0.8271    0.8333    0.8276       618

-------- Testing finished --------
