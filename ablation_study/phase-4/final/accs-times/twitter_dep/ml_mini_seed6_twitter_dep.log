Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_mini",
    "model_name": "ml_mini_seed6_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/accs-times/twitter_dep/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  239903
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 11171074
Trainable parameters count: 856066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5876, Accuracy: 70.75 %
Epoch [1/12], Step [200/496], Loss: 0.5637, Accuracy: 72.12 %
Epoch [1/12], Step [300/496], Loss: 0.5291, Accuracy: 74.33 %
Epoch [1/12], Step [400/496], Loss: 0.5173, Accuracy: 75.38 %
Predictions - 1s: 186, 0s: 1796
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [1/12] Loss: 0.5086, Accuracy: 75.98 %
-------------------------------
-------- Validation --------
Predictions - 1s: 91, 0s: 405
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.4396, Validation Accuracy: 80.04 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.4396 and Validation Accuracy: 80.04 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.4475, Accuracy: 78.75 %
Epoch [2/12], Step [200/496], Loss: 0.4352, Accuracy: 79.62 %
Epoch [2/12], Step [300/496], Loss: 0.4242, Accuracy: 80.67 %
Epoch [2/12], Step [400/496], Loss: 0.4258, Accuracy: 80.69 %
Predictions - 1s: 385, 0s: 1597
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [2/12] Loss: 0.4391, Accuracy: 79.47 %
-------------------------------
-------- Validation --------
Predictions - 1s: 186, 0s: 310
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.4530, Validation Accuracy: 78.23 %
-------- Validation finished --------
Epoch [3/12], Step [100/496], Loss: 0.4046, Accuracy: 82.00 %
Epoch [3/12], Step [200/496], Loss: 0.4184, Accuracy: 80.38 %
Epoch [3/12], Step [300/496], Loss: 0.4143, Accuracy: 80.83 %
Epoch [3/12], Step [400/496], Loss: 0.4111, Accuracy: 80.75 %
Predictions - 1s: 400, 0s: 1582
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [3/12] Loss: 0.4106, Accuracy: 81.13 %
-------------------------------
-------- Validation --------
Predictions - 1s: 148, 0s: 348
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.4033, Validation Accuracy: 80.65 %
-------- Validation finished --------
Updated best model in epoch 3 saved with Validation Loss: 0.4033 and Validation Accuracy: 80.65 %
-------------------------------
Epoch [4/12], Step [100/496], Loss: 0.4152, Accuracy: 81.00 %
Epoch [4/12], Step [200/496], Loss: 0.3846, Accuracy: 82.62 %
Epoch [4/12], Step [300/496], Loss: 0.3884, Accuracy: 82.50 %
Epoch [4/12], Step [400/496], Loss: 0.3848, Accuracy: 82.31 %
Predictions - 1s: 411, 0s: 1571
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [4/12] Loss: 0.3844, Accuracy: 82.29 %
-------------------------------
-------- Validation --------
Predictions - 1s: 119, 0s: 377
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3923, Validation Accuracy: 81.25 %
-------- Validation finished --------
Updated best model in epoch 4 saved with Validation Loss: 0.3923 and Validation Accuracy: 81.25 %
-------------------------------
Epoch [5/12], Step [100/496], Loss: 0.3742, Accuracy: 82.75 %
Epoch [5/12], Step [200/496], Loss: 0.3797, Accuracy: 82.62 %
Epoch [5/12], Step [300/496], Loss: 0.3689, Accuracy: 83.58 %
Epoch [5/12], Step [400/496], Loss: 0.3755, Accuracy: 82.69 %
Predictions - 1s: 431, 0s: 1551
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [5/12] Loss: 0.3656, Accuracy: 82.69 %
-------------------------------
-------- Validation --------
Predictions - 1s: 134, 0s: 362
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3884, Validation Accuracy: 81.45 %
-------- Validation finished --------
Updated best model in epoch 5 saved with Validation Loss: 0.3884 and Validation Accuracy: 81.45 %
-------------------------------
Epoch [6/12], Step [100/496], Loss: 0.3167, Accuracy: 85.25 %
Epoch [6/12], Step [200/496], Loss: 0.3281, Accuracy: 84.75 %
Epoch [6/12], Step [300/496], Loss: 0.3361, Accuracy: 84.17 %
Epoch [6/12], Step [400/496], Loss: 0.3454, Accuracy: 83.69 %
Predictions - 1s: 464, 0s: 1518
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [6/12] Loss: 0.3472, Accuracy: 83.75 %
-------------------------------
-------- Validation --------
Predictions - 1s: 130, 0s: 366
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3901, Validation Accuracy: 79.84 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.3176, Accuracy: 85.75 %
Epoch [7/12], Step [200/496], Loss: 0.3222, Accuracy: 86.25 %
Epoch [7/12], Step [300/496], Loss: 0.3280, Accuracy: 85.33 %
Epoch [7/12], Step [400/496], Loss: 0.3257, Accuracy: 85.12 %
Predictions - 1s: 456, 0s: 1526
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [7/12] Loss: 0.3277, Accuracy: 85.37 %
-------------------------------
-------- Validation --------
Predictions - 1s: 141, 0s: 355
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3947, Validation Accuracy: 81.65 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.3124, Accuracy: 86.75 %
Epoch [8/12], Step [200/496], Loss: 0.3019, Accuracy: 86.75 %
Epoch [8/12], Step [300/496], Loss: 0.3061, Accuracy: 85.92 %
Epoch [8/12], Step [400/496], Loss: 0.3037, Accuracy: 86.25 %
Predictions - 1s: 480, 0s: 1502
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [8/12] Loss: 0.3064, Accuracy: 86.28 %
-------------------------------
-------- Validation --------
Predictions - 1s: 144, 0s: 352
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3949, Validation Accuracy: 82.26 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.2487, Accuracy: 90.50 %
Epoch [9/12], Step [200/496], Loss: 0.2634, Accuracy: 89.88 %
Epoch [9/12], Step [300/496], Loss: 0.2832, Accuracy: 88.33 %
Epoch [9/12], Step [400/496], Loss: 0.2913, Accuracy: 87.94 %
Predictions - 1s: 482, 0s: 1500
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [9/12] Loss: 0.2857, Accuracy: 88.19 %
-------------------------------
-------- Validation --------
Predictions - 1s: 130, 0s: 366
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3932, Validation Accuracy: 81.85 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.2600, Accuracy: 89.25 %
Epoch [10/12], Step [200/496], Loss: 0.2801, Accuracy: 88.25 %
Epoch [10/12], Step [300/496], Loss: 0.2850, Accuracy: 88.25 %
Epoch [10/12], Step [400/496], Loss: 0.2827, Accuracy: 88.62 %
Predictions - 1s: 482, 0s: 1500
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [10/12] Loss: 0.2835, Accuracy: 87.99 %
-------------------------------
-------- Validation --------
Predictions - 1s: 119, 0s: 377
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.3997, Validation Accuracy: 81.25 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.2309, Accuracy: 90.75 %
Epoch [11/12], Step [200/496], Loss: 0.2606, Accuracy: 89.00 %
Epoch [11/12], Step [300/496], Loss: 0.2724, Accuracy: 88.58 %
Epoch [11/12], Step [400/496], Loss: 0.2768, Accuracy: 88.31 %
Predictions - 1s: 467, 0s: 1515
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [11/12] Loss: 0.2769, Accuracy: 88.04 %
-------------------------------
-------- Validation --------
Predictions - 1s: 139, 0s: 357
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.4026, Validation Accuracy: 82.46 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.2588, Accuracy: 88.75 %
Epoch [12/12], Step [200/496], Loss: 0.2834, Accuracy: 87.50 %
Epoch [12/12], Step [300/496], Loss: 0.2796, Accuracy: 87.83 %
Epoch [12/12], Step [400/496], Loss: 0.2725, Accuracy: 88.25 %
Predictions - 1s: 499, 0s: 1483
True Labels - 1s: 534, 0s: 1448
-------------------------------
Epoch [12/12] Loss: 0.2736, Accuracy: 88.04 %
-------------------------------
-------- Validation --------
Predictions - 1s: 128, 0s: 368
True Labels - 1s: 140, 0s: 356
Validation Loss: 0.4024, Validation Accuracy: 81.05 %
-------- Validation finished --------
Best model in epoch 5 saved with with Validation Loss: 0.3884 and Validation Accuracy: 81.45 %

-------- Training finished in 1:25 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-mini from date 20-04-2024 11:14. Trained with Centralised Machine Learning technology.
Epoch 5, lr: 6e-05, optimizer: AdamW
Train accuracy: 82.69 %, Validation accuracy: 81.45 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 163, 0s: 455
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 78.80%
Accuracy 2 : 78.80%
Precision: 73.20%
Recall: 72.76%
F1 Score: 72.97%
Classification report:
              precision    recall  f1-score   support

           0     0.8505    0.8600    0.8552       450
           1     0.6135    0.5952    0.6042       168

    accuracy                         0.7880       618
   macro avg     0.7320    0.7276    0.7297       618
weighted avg     0.7861    0.7880    0.7870       618

-------- Testing finished --------
