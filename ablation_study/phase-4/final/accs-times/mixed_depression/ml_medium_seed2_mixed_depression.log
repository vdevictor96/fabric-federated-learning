Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "mixed_depression",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_medium",
    "model_name": "ml_medium_seed2_mixed_depression",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/accs-times/mixed_depression/",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  341846
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 41374210
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1806 total sentences. 452 batches of size 4.
Eval Loader: 452 total sentences. 113 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/452], Loss: 0.5799, Accuracy: 69.25 %
Epoch [1/12], Step [200/452], Loss: 0.5100, Accuracy: 75.12 %
Epoch [1/12], Step [300/452], Loss: 0.4650, Accuracy: 77.83 %
Epoch [1/12], Step [400/452], Loss: 0.4309, Accuracy: 80.38 %
Predictions - 1s: 956, 0s: 850
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [1/12] Loss: 0.4160, Accuracy: 81.28 %
-------------------------------
-------- Validation --------
Predictions - 1s: 223, 0s: 229
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.3520, Validation Accuracy: 87.17 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.3520 and Validation Accuracy: 87.17 %
-------------------------------
Epoch [2/12], Step [100/452], Loss: 0.3071, Accuracy: 87.00 %
Epoch [2/12], Step [200/452], Loss: 0.2846, Accuracy: 88.00 %
Epoch [2/12], Step [300/452], Loss: 0.2879, Accuracy: 87.58 %
Epoch [2/12], Step [400/452], Loss: 0.2905, Accuracy: 87.44 %
Predictions - 1s: 1000, 0s: 806
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [2/12] Loss: 0.2904, Accuracy: 87.82 %
-------------------------------
-------- Validation --------
Predictions - 1s: 260, 0s: 192
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.3004, Validation Accuracy: 88.27 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 0.3004 and Validation Accuracy: 88.27 %
-------------------------------
Epoch [3/12], Step [100/452], Loss: 0.2299, Accuracy: 91.00 %
Epoch [3/12], Step [200/452], Loss: 0.2207, Accuracy: 91.75 %
Epoch [3/12], Step [300/452], Loss: 0.2167, Accuracy: 91.67 %
Epoch [3/12], Step [400/452], Loss: 0.2340, Accuracy: 90.62 %
Predictions - 1s: 980, 0s: 826
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [3/12] Loss: 0.2339, Accuracy: 90.70 %
-------------------------------
-------- Validation --------
Predictions - 1s: 227, 0s: 225
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.3270, Validation Accuracy: 87.17 %
-------- Validation finished --------
Epoch [4/12], Step [100/452], Loss: 0.1543, Accuracy: 94.25 %
Epoch [4/12], Step [200/452], Loss: 0.1586, Accuracy: 93.88 %
Epoch [4/12], Step [300/452], Loss: 0.1703, Accuracy: 93.17 %
Epoch [4/12], Step [400/452], Loss: 0.1696, Accuracy: 93.25 %
Predictions - 1s: 973, 0s: 833
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [4/12] Loss: 0.1696, Accuracy: 93.30 %
-------------------------------
-------- Validation --------
Predictions - 1s: 249, 0s: 203
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.3066, Validation Accuracy: 88.50 %
-------- Validation finished --------
Epoch [5/12], Step [100/452], Loss: 0.1242, Accuracy: 95.75 %
Epoch [5/12], Step [200/452], Loss: 0.1229, Accuracy: 95.50 %
Epoch [5/12], Step [300/452], Loss: 0.1201, Accuracy: 95.83 %
Epoch [5/12], Step [400/452], Loss: 0.1228, Accuracy: 95.56 %
Predictions - 1s: 966, 0s: 840
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [5/12] Loss: 0.1241, Accuracy: 95.35 %
-------------------------------
-------- Validation --------
Predictions - 1s: 246, 0s: 206
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.3371, Validation Accuracy: 88.72 %
-------- Validation finished --------
Epoch [6/12], Step [100/452], Loss: 0.0724, Accuracy: 97.25 %
Epoch [6/12], Step [200/452], Loss: 0.0835, Accuracy: 96.88 %
Epoch [6/12], Step [300/452], Loss: 0.0979, Accuracy: 96.67 %
Epoch [6/12], Step [400/452], Loss: 0.1003, Accuracy: 96.50 %
Predictions - 1s: 961, 0s: 845
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [6/12] Loss: 0.1010, Accuracy: 96.40 %
-------------------------------
-------- Validation --------
Predictions - 1s: 225, 0s: 227
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.4187, Validation Accuracy: 87.61 %
-------- Validation finished --------
Epoch [7/12], Step [100/452], Loss: 0.0462, Accuracy: 98.75 %
Epoch [7/12], Step [200/452], Loss: 0.0543, Accuracy: 98.62 %
Epoch [7/12], Step [300/452], Loss: 0.0574, Accuracy: 98.17 %
Epoch [7/12], Step [400/452], Loss: 0.0639, Accuracy: 97.81 %
Predictions - 1s: 959, 0s: 847
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [7/12] Loss: 0.0662, Accuracy: 97.62 %
-------------------------------
-------- Validation --------
Predictions - 1s: 233, 0s: 219
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.4218, Validation Accuracy: 88.94 %
-------- Validation finished --------
Epoch [8/12], Step [100/452], Loss: 0.0493, Accuracy: 98.25 %
Epoch [8/12], Step [200/452], Loss: 0.0516, Accuracy: 98.12 %
Epoch [8/12], Step [300/452], Loss: 0.0535, Accuracy: 98.08 %
Epoch [8/12], Step [400/452], Loss: 0.0586, Accuracy: 97.81 %
Predictions - 1s: 946, 0s: 860
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [8/12] Loss: 0.0577, Accuracy: 97.79 %
-------------------------------
-------- Validation --------
Predictions - 1s: 239, 0s: 213
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.4089, Validation Accuracy: 88.94 %
-------- Validation finished --------
Epoch [9/12], Step [100/452], Loss: 0.0312, Accuracy: 99.00 %
Epoch [9/12], Step [200/452], Loss: 0.0377, Accuracy: 98.75 %
Epoch [9/12], Step [300/452], Loss: 0.0376, Accuracy: 98.83 %
Epoch [9/12], Step [400/452], Loss: 0.0369, Accuracy: 98.81 %
Predictions - 1s: 952, 0s: 854
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [9/12] Loss: 0.0377, Accuracy: 98.78 %
-------------------------------
-------- Validation --------
Predictions - 1s: 240, 0s: 212
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.4738, Validation Accuracy: 88.72 %
-------- Validation finished --------
Epoch [10/12], Step [100/452], Loss: 0.0136, Accuracy: 99.75 %
Epoch [10/12], Step [200/452], Loss: 0.0201, Accuracy: 99.50 %
Epoch [10/12], Step [300/452], Loss: 0.0236, Accuracy: 99.17 %
Epoch [10/12], Step [400/452], Loss: 0.0231, Accuracy: 99.25 %
Predictions - 1s: 952, 0s: 854
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [10/12] Loss: 0.0284, Accuracy: 99.00 %
-------------------------------
-------- Validation --------
Predictions - 1s: 246, 0s: 206
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.4684, Validation Accuracy: 88.72 %
-------- Validation finished --------
Epoch [11/12], Step [100/452], Loss: 0.0423, Accuracy: 98.50 %
Epoch [11/12], Step [200/452], Loss: 0.0329, Accuracy: 98.62 %
Epoch [11/12], Step [300/452], Loss: 0.0283, Accuracy: 98.92 %
Epoch [11/12], Step [400/452], Loss: 0.0251, Accuracy: 99.12 %
Predictions - 1s: 952, 0s: 854
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [11/12] Loss: 0.0264, Accuracy: 99.00 %
-------------------------------
-------- Validation --------
Predictions - 1s: 239, 0s: 213
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.5177, Validation Accuracy: 88.50 %
-------- Validation finished --------
Epoch [12/12], Step [100/452], Loss: 0.0263, Accuracy: 99.00 %
Epoch [12/12], Step [200/452], Loss: 0.0227, Accuracy: 99.12 %
Epoch [12/12], Step [300/452], Loss: 0.0293, Accuracy: 98.75 %
Epoch [12/12], Step [400/452], Loss: 0.0260, Accuracy: 99.06 %
Predictions - 1s: 946, 0s: 860
True Labels - 1s: 944, 0s: 862
-------------------------------
Epoch [12/12] Loss: 0.0247, Accuracy: 99.11 %
-------------------------------
-------- Validation --------
Predictions - 1s: 234, 0s: 218
True Labels - 1s: 241, 0s: 211
Validation Loss: 0.5233, Validation Accuracy: 89.16 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 0.3004 and Validation Accuracy: 88.27 %

-------- Training finished in 2:21 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-medium from date 20-04-2024 04:22. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 6e-05, optimizer: AdamW
Train accuracy: 87.82 %, Validation accuracy: 88.27 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 564 total sentences. 71 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 324, 0s: 240
True Labels - 1s: 296, 0s: 268
Nº of test samples: 564
Accuracy: 88.30%
Accuracy 2 : 88.30%
Precision: 88.79%
Recall: 88.02%
F1 Score: 88.18%
Classification report:
              precision    recall  f1-score   support

           0     0.9208    0.8246    0.8701       268
           1     0.8549    0.9358    0.8935       296

    accuracy                         0.8830       564
   macro avg     0.8879    0.8802    0.8818       564
weighted avg     0.8863    0.8830    0.8824       564

-------- Testing finished --------
