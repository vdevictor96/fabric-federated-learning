Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "non_iid",
    "dataset": "mixed_depression",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "bcfl",
    "model": "bert_small",
    "model_name": "fedavg_non_iid_mixed_depression",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/data-dist/mixed_depression",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 3,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  132740
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1806 total sentences. 452 batches of size 4.
Eval Loader: 452 total sentences. 113 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Training --------
Training with Blockchain-Based Federated Learning technology.
Training without differential privacy.
Federated averaging algorithm selected.
Client 0: Label 0: 0, Label 1: 408
Client 1: Label 0: 0, Label 1: 408
Client 2: Label 0: 361, Label 1: 47
Client 3: Label 0: 361, Label 1: 46
Client 4: Label 0: 129, Label 1: 46

Round 1 of 4
-------------------------------
Predictions - 1s: 8, 0s: 167
True Labels - 1s: 46, 0s: 129
Client 5 of 5: Local Epoch [1/3] Loss: 0.5444, Accuracy: 71.43 %
Predictions - 1s: 403, 0s: 5
True Labels - 1s: 408, 0s: 0
Client 2 of 5: Local Epoch [1/3] Loss: 0.0504, Accuracy: 98.77 %
Predictions - 1s: 2, 0s: 405
True Labels - 1s: 46, 0s: 361
Client 4 of 5: Local Epoch [1/3] Loss: 0.3243, Accuracy: 89.19 %
Predictions - 1s: 18, 0s: 157
True Labels - 1s: 46, 0s: 129
Client 5 of 5: Local Epoch [2/3] Loss: 0.4200, Accuracy: 80.57 %
Predictions - 1s: 404, 0s: 4
True Labels - 1s: 408, 0s: 0
Client 1 of 5: Local Epoch [1/3] Loss: 0.0480, Accuracy: 99.02 %
Predictions - 1s: 10, 0s: 398
True Labels - 1s: 47, 0s: 361
Client 3 of 5: Local Epoch [1/3] Loss: 0.3371, Accuracy: 87.50 %
Predictions - 1s: 31, 0s: 144
True Labels - 1s: 46, 0s: 129
Client 5 of 5: Local Epoch [3/3] Loss: 0.3507, Accuracy: 86.86 %
Predictions - 1s: 408, 0s: 0
True Labels - 1s: 408, 0s: 0
Client 2 of 5: Local Epoch [2/3] Loss: 0.0034, Accuracy: 100.00 %
Predictions - 1s: 6, 0s: 401
True Labels - 1s: 46, 0s: 361
Client 4 of 5: Local Epoch [2/3] Loss: 0.2564, Accuracy: 90.17 %
Predictions - 1s: 408, 0s: 0
True Labels - 1s: 408, 0s: 0
Client 1 of 5: Local Epoch [2/3] Loss: 0.0032, Accuracy: 100.00 %
Predictions - 1s: 14, 0s: 394
True Labels - 1s: 47, 0s: 361
Client 3 of 5: Local Epoch [2/3] Loss: 0.2538, Accuracy: 90.93 %
Predictions - 1s: 408, 0s: 0
True Labels - 1s: 408, 0s: 0
Client 2 of 5: Local Epoch [3/3] Loss: 0.0023, Accuracy: 100.00 %
Predictions - 1s: 17, 0s: 390
True Labels - 1s: 46, 0s: 361
Client 4 of 5: Local Epoch [3/3] Loss: 0.2188, Accuracy: 92.38 %
Predictions - 1s: 408, 0s: 0
True Labels - 1s: 408, 0s: 0
Client 1 of 5: Local Epoch [3/3] Loss: 0.0022, Accuracy: 100.00 %
Predictions - 1s: 26, 0s: 382
True Labels - 1s: 47, 0s: 361
Client 3 of 5: Local Epoch [3/3] Loss: 0.2059, Accuracy: 93.38 %
-------------------------------
Round [1/4] Average Local Loss: 0.1560, Average Local Accuracy: 94.52 %
-------------------------------
