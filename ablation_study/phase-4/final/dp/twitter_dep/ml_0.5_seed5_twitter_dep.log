Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.5,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0.5_seed5_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  471736
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
max_grad_norm:  1.5
Epoch [1/12], Step [100/496], Loss: 1.1064, Accuracy: 70.25 %, Epsilon: 0.04, Delta: 0.0030
Epoch [1/12], Step [200/496], Loss: 1.2194, Accuracy: 72.50 %, Epsilon: 0.07, Delta: 0.0030
Epoch [1/12], Step [300/496], Loss: 1.3158, Accuracy: 72.00 %, Epsilon: 0.08, Delta: 0.0030
Epoch [1/12], Step [400/496], Loss: 1.3536, Accuracy: 72.19 %, Epsilon: 0.10, Delta: 0.0030
Predictions - 1s: 27, 0s: 1955
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [1/12] Loss: 1.4008, Accuracy: 71.70 %, Epsilon: 0.11, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 1, 0s: 495
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.7072, Validation Accuracy: 73.19 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 1.7072 and Validation Accuracy: 73.19 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 1.6906, Accuracy: 72.50 %, Epsilon: 0.13, Delta: 0.0030
Epoch [2/12], Step [200/496], Loss: 1.7270, Accuracy: 72.75 %, Epsilon: 0.14, Delta: 0.0030
Epoch [2/12], Step [300/496], Loss: 1.7578, Accuracy: 70.67 %, Epsilon: 0.15, Delta: 0.0030
Epoch [2/12], Step [400/496], Loss: 1.7326, Accuracy: 69.44 %, Epsilon: 0.16, Delta: 0.0030
Predictions - 1s: 139, 0s: 1843
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [2/12] Loss: 1.6876, Accuracy: 69.68 %, Epsilon: 0.17, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 17, 0s: 479
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.5309, Validation Accuracy: 72.38 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 1.5309 and Validation Accuracy: 72.38 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 1.7478, Accuracy: 69.75 %, Epsilon: 0.18, Delta: 0.0030
Epoch [3/12], Step [200/496], Loss: 1.5820, Accuracy: 69.00 %, Epsilon: 0.19, Delta: 0.0030
Epoch [3/12], Step [300/496], Loss: 1.5664, Accuracy: 66.92 %, Epsilon: 0.20, Delta: 0.0030
Epoch [3/12], Step [400/496], Loss: 1.6173, Accuracy: 67.69 %, Epsilon: 0.21, Delta: 0.0030
Predictions - 1s: 249, 0s: 1733
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [3/12] Loss: 1.7579, Accuracy: 66.95 %, Epsilon: 0.22, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 6, 0s: 490
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.0574, Validation Accuracy: 73.79 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 1.9177, Accuracy: 73.25 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [200/496], Loss: 1.9219, Accuracy: 71.25 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [300/496], Loss: 1.9150, Accuracy: 69.50 %, Epsilon: 0.24, Delta: 0.0030
Epoch [4/12], Step [400/496], Loss: 1.9285, Accuracy: 67.81 %, Epsilon: 0.25, Delta: 0.0030
Predictions - 1s: 189, 0s: 1793
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [4/12] Loss: 1.9858, Accuracy: 68.26 %, Epsilon: 0.26, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 15, 0s: 481
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.1612, Validation Accuracy: 71.98 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 2.2609, Accuracy: 71.00 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [200/496], Loss: 2.4886, Accuracy: 68.12 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [300/496], Loss: 2.2629, Accuracy: 68.42 %, Epsilon: 0.28, Delta: 0.0030
Epoch [5/12], Step [400/496], Loss: 2.1967, Accuracy: 69.25 %, Epsilon: 0.29, Delta: 0.0030
Predictions - 1s: 168, 0s: 1814
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [5/12] Loss: 2.1699, Accuracy: 69.12 %, Epsilon: 0.29, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 30, 0s: 466
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.8725, Validation Accuracy: 71.37 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 2.0428, Accuracy: 70.75 %, Epsilon: 0.30, Delta: 0.0030
Epoch [6/12], Step [200/496], Loss: 1.9687, Accuracy: 71.12 %, Epsilon: 0.31, Delta: 0.0030
Epoch [6/12], Step [300/496], Loss: 2.0195, Accuracy: 69.25 %, Epsilon: 0.32, Delta: 0.0030
Epoch [6/12], Step [400/496], Loss: 2.0604, Accuracy: 68.44 %, Epsilon: 0.32, Delta: 0.0030
Predictions - 1s: 213, 0s: 1769
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [6/12] Loss: 2.0478, Accuracy: 68.77 %, Epsilon: 0.33, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 22, 0s: 474
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.0566, Validation Accuracy: 71.37 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 2.0742, Accuracy: 70.00 %, Epsilon: 0.33, Delta: 0.0030
Epoch [7/12], Step [200/496], Loss: 2.2715, Accuracy: 68.75 %, Epsilon: 0.34, Delta: 0.0030
Epoch [7/12], Step [300/496], Loss: 2.3140, Accuracy: 68.92 %, Epsilon: 0.35, Delta: 0.0030
Epoch [7/12], Step [400/496], Loss: 2.3033, Accuracy: 67.88 %, Epsilon: 0.35, Delta: 0.0030
Predictions - 1s: 190, 0s: 1792
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [7/12] Loss: 2.2952, Accuracy: 68.72 %, Epsilon: 0.36, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 18, 0s: 478
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.3619, Validation Accuracy: 70.56 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 2.5622, Accuracy: 68.00 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [200/496], Loss: 2.4057, Accuracy: 70.62 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [300/496], Loss: 2.3000, Accuracy: 69.33 %, Epsilon: 0.38, Delta: 0.0030
Epoch [8/12], Step [400/496], Loss: 2.3247, Accuracy: 67.62 %, Epsilon: 0.38, Delta: 0.0030
Predictions - 1s: 238, 0s: 1744
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [8/12] Loss: 2.2181, Accuracy: 67.41 %, Epsilon: 0.39, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 55, 0s: 441
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.9376, Validation Accuracy: 67.94 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 1.9250, Accuracy: 66.00 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [200/496], Loss: 2.0885, Accuracy: 65.88 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [300/496], Loss: 2.0400, Accuracy: 67.58 %, Epsilon: 0.41, Delta: 0.0030
Epoch [9/12], Step [400/496], Loss: 2.1020, Accuracy: 67.38 %, Epsilon: 0.41, Delta: 0.0030
Predictions - 1s: 278, 0s: 1704
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [9/12] Loss: 2.2110, Accuracy: 66.60 %, Epsilon: 0.42, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 27, 0s: 469
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.2126, Validation Accuracy: 71.57 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 2.1686, Accuracy: 70.25 %, Epsilon: 0.42, Delta: 0.0030
Epoch [10/12], Step [200/496], Loss: 2.2056, Accuracy: 67.75 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [300/496], Loss: 2.1573, Accuracy: 67.58 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [400/496], Loss: 2.1797, Accuracy: 67.62 %, Epsilon: 0.44, Delta: 0.0030
Predictions - 1s: 229, 0s: 1753
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [10/12] Loss: 2.1471, Accuracy: 68.47 %, Epsilon: 0.44, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 36, 0s: 460
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.9670, Validation Accuracy: 69.76 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 2.0160, Accuracy: 67.75 %, Epsilon: 0.45, Delta: 0.0030
Epoch [11/12], Step [200/496], Loss: 2.0192, Accuracy: 67.88 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [300/496], Loss: 2.0193, Accuracy: 68.42 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [400/496], Loss: 2.0625, Accuracy: 68.69 %, Epsilon: 0.47, Delta: 0.0030
Predictions - 1s: 216, 0s: 1766
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [11/12] Loss: 2.1251, Accuracy: 68.52 %, Epsilon: 0.47, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 43, 0s: 453
True Labels - 1s: 132, 0s: 364
Validation Loss: 2.0073, Validation Accuracy: 69.96 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 2.0231, Accuracy: 71.00 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [200/496], Loss: 2.0507, Accuracy: 70.50 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [300/496], Loss: 2.1893, Accuracy: 69.08 %, Epsilon: 0.49, Delta: 0.0030
Epoch [12/12], Step [400/496], Loss: 2.1884, Accuracy: 69.12 %, Epsilon: 0.49, Delta: 0.0030
Predictions - 1s: 210, 0s: 1772
True Labels - 1s: 542, 0s: 1440
-------------------------------
Epoch [12/12] Loss: 2.1280, Accuracy: 69.42 %, Epsilon: 0.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 46, 0s: 450
True Labels - 1s: 132, 0s: 364
Validation Loss: 1.9754, Validation Accuracy: 68.95 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 1.5309 and Validation Accuracy: 72.38 %

-------- Training finished in 4:02 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 13-05-2024 12:45. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 0.006, optimizer: DPOptimizer
Train accuracy: 69.68 %, Validation accuracy: 72.38 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 33, 0s: 585
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 70.06%
Accuracy 2 : 70.06%
Precision: 48.45%
Recall: 49.60%
F1 Score: 45.04%
Classification report:
              precision    recall  f1-score   support

           0     0.7265    0.9444    0.8213       450
           1     0.2424    0.0476    0.0796       168

    accuracy                         0.7006       618
   macro avg     0.4845    0.4960    0.4504       618
weighted avg     0.5949    0.7006    0.6196       618

-------- Testing finished --------
