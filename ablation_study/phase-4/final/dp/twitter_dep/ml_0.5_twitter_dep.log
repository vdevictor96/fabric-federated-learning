Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.5,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0.5_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  2552
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
max_grad_norm:  1.5
Epoch [1/12], Step [100/496], Loss: 1.0815, Accuracy: 75.75 %, Epsilon: 0.04, Delta: 0.0030
Epoch [1/12], Step [200/496], Loss: 1.2510, Accuracy: 73.50 %, Epsilon: 0.07, Delta: 0.0030
Epoch [1/12], Step [300/496], Loss: 1.2805, Accuracy: 72.33 %, Epsilon: 0.08, Delta: 0.0030
Epoch [1/12], Step [400/496], Loss: 1.3324, Accuracy: 71.69 %, Epsilon: 0.10, Delta: 0.0030
Predictions - 1s: 48, 0s: 1934
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [1/12] Loss: 1.3582, Accuracy: 71.24 %, Epsilon: 0.11, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 0, 0s: 496
True Labels - 1s: 130, 0s: 366
Validation Loss: 1.5951, Validation Accuracy: 73.79 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 1.5951 and Validation Accuracy: 73.79 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 1.5315, Accuracy: 69.00 %, Epsilon: 0.13, Delta: 0.0030
Epoch [2/12], Step [200/496], Loss: 1.4866, Accuracy: 70.12 %, Epsilon: 0.14, Delta: 0.0030
Epoch [2/12], Step [300/496], Loss: 1.5060, Accuracy: 70.33 %, Epsilon: 0.15, Delta: 0.0030
Epoch [2/12], Step [400/496], Loss: 1.5088, Accuracy: 70.62 %, Epsilon: 0.16, Delta: 0.0030
Predictions - 1s: 135, 0s: 1847
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [2/12] Loss: 1.6910, Accuracy: 70.18 %, Epsilon: 0.17, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 12, 0s: 484
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.0315, Validation Accuracy: 72.18 %
-------- Validation finished --------
Epoch [3/12], Step [100/496], Loss: 2.3655, Accuracy: 68.75 %, Epsilon: 0.18, Delta: 0.0030
Epoch [3/12], Step [200/496], Loss: 2.2917, Accuracy: 69.88 %, Epsilon: 0.19, Delta: 0.0030
Epoch [3/12], Step [300/496], Loss: 2.3111, Accuracy: 68.67 %, Epsilon: 0.20, Delta: 0.0030
Epoch [3/12], Step [400/496], Loss: 2.2918, Accuracy: 68.69 %, Epsilon: 0.21, Delta: 0.0030
Predictions - 1s: 121, 0s: 1861
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [3/12] Loss: 2.1994, Accuracy: 69.27 %, Epsilon: 0.22, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 13, 0s: 483
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.2571, Validation Accuracy: 71.98 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 2.2058, Accuracy: 70.00 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [200/496], Loss: 2.0606, Accuracy: 69.88 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [300/496], Loss: 2.0445, Accuracy: 69.92 %, Epsilon: 0.24, Delta: 0.0030
Epoch [4/12], Step [400/496], Loss: 2.0790, Accuracy: 70.44 %, Epsilon: 0.25, Delta: 0.0030
Predictions - 1s: 160, 0s: 1822
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [4/12] Loss: 2.0560, Accuracy: 69.32 %, Epsilon: 0.26, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 56, 0s: 440
True Labels - 1s: 130, 0s: 366
Validation Loss: 1.8604, Validation Accuracy: 68.95 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 2.0681, Accuracy: 68.75 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [200/496], Loss: 2.2769, Accuracy: 67.75 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [300/496], Loss: 2.2545, Accuracy: 68.92 %, Epsilon: 0.28, Delta: 0.0030
Epoch [5/12], Step [400/496], Loss: 2.1435, Accuracy: 69.38 %, Epsilon: 0.29, Delta: 0.0030
Predictions - 1s: 213, 0s: 1769
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [5/12] Loss: 2.1212, Accuracy: 68.97 %, Epsilon: 0.29, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 19, 0s: 477
True Labels - 1s: 130, 0s: 366
Validation Loss: 1.8584, Validation Accuracy: 73.59 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 2.2997, Accuracy: 67.25 %, Epsilon: 0.30, Delta: 0.0030
Epoch [6/12], Step [200/496], Loss: 2.2521, Accuracy: 65.50 %, Epsilon: 0.31, Delta: 0.0030
Epoch [6/12], Step [300/496], Loss: 2.0902, Accuracy: 66.50 %, Epsilon: 0.32, Delta: 0.0030
Epoch [6/12], Step [400/496], Loss: 2.1245, Accuracy: 66.50 %, Epsilon: 0.32, Delta: 0.0030
Predictions - 1s: 220, 0s: 1762
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [6/12] Loss: 2.0835, Accuracy: 67.41 %, Epsilon: 0.33, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 10, 0s: 486
True Labels - 1s: 130, 0s: 366
Validation Loss: 1.9714, Validation Accuracy: 72.58 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 1.7833, Accuracy: 69.75 %, Epsilon: 0.33, Delta: 0.0030
Epoch [7/12], Step [200/496], Loss: 1.9591, Accuracy: 71.50 %, Epsilon: 0.34, Delta: 0.0030
Epoch [7/12], Step [300/496], Loss: 2.2437, Accuracy: 69.75 %, Epsilon: 0.35, Delta: 0.0030
Epoch [7/12], Step [400/496], Loss: 2.2588, Accuracy: 69.50 %, Epsilon: 0.35, Delta: 0.0030
Predictions - 1s: 131, 0s: 1851
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [7/12] Loss: 2.2726, Accuracy: 69.88 %, Epsilon: 0.36, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 4, 0s: 492
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.5305, Validation Accuracy: 74.19 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 2.3259, Accuracy: 72.25 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [200/496], Loss: 2.2725, Accuracy: 72.12 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [300/496], Loss: 2.4034, Accuracy: 70.33 %, Epsilon: 0.38, Delta: 0.0030
Epoch [8/12], Step [400/496], Loss: 2.4162, Accuracy: 70.69 %, Epsilon: 0.38, Delta: 0.0030
Predictions - 1s: 148, 0s: 1834
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [8/12] Loss: 2.3258, Accuracy: 70.23 %, Epsilon: 0.39, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 21, 0s: 475
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.0213, Validation Accuracy: 72.78 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 2.2449, Accuracy: 69.50 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [200/496], Loss: 2.1924, Accuracy: 69.50 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [300/496], Loss: 2.0830, Accuracy: 70.42 %, Epsilon: 0.41, Delta: 0.0030
Epoch [9/12], Step [400/496], Loss: 2.1679, Accuracy: 69.31 %, Epsilon: 0.41, Delta: 0.0030
Predictions - 1s: 198, 0s: 1784
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [9/12] Loss: 2.2375, Accuracy: 69.22 %, Epsilon: 0.42, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 29, 0s: 467
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.0445, Validation Accuracy: 70.36 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 2.3403, Accuracy: 69.50 %, Epsilon: 0.42, Delta: 0.0030
Epoch [10/12], Step [200/496], Loss: 2.2393, Accuracy: 69.50 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [300/496], Loss: 2.2962, Accuracy: 67.83 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [400/496], Loss: 2.3041, Accuracy: 67.56 %, Epsilon: 0.44, Delta: 0.0030
Predictions - 1s: 205, 0s: 1777
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [10/12] Loss: 2.2875, Accuracy: 67.56 %, Epsilon: 0.44, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 20, 0s: 476
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.0842, Validation Accuracy: 70.97 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 2.4070, Accuracy: 68.25 %, Epsilon: 0.45, Delta: 0.0030
Epoch [11/12], Step [200/496], Loss: 2.2634, Accuracy: 70.50 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [300/496], Loss: 2.2233, Accuracy: 70.25 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [400/496], Loss: 2.1625, Accuracy: 70.56 %, Epsilon: 0.47, Delta: 0.0030
Predictions - 1s: 164, 0s: 1818
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [11/12] Loss: 2.1983, Accuracy: 69.93 %, Epsilon: 0.47, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 23, 0s: 473
True Labels - 1s: 130, 0s: 366
Validation Loss: 2.0353, Validation Accuracy: 71.17 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 2.2448, Accuracy: 68.50 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [200/496], Loss: 2.1674, Accuracy: 68.62 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [300/496], Loss: 2.2425, Accuracy: 66.75 %, Epsilon: 0.49, Delta: 0.0030
Epoch [12/12], Step [400/496], Loss: 2.2299, Accuracy: 67.69 %, Epsilon: 0.49, Delta: 0.0030
Predictions - 1s: 186, 0s: 1796
True Labels - 1s: 544, 0s: 1438
-------------------------------
Epoch [12/12] Loss: 2.1968, Accuracy: 68.11 %, Epsilon: 0.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 23, 0s: 473
True Labels - 1s: 130, 0s: 366
Validation Loss: 1.9924, Validation Accuracy: 71.57 %
-------- Validation finished --------
Best model in epoch 1 saved with with Validation Loss: 1.5951 and Validation Accuracy: 73.79 %

-------- Training finished in 4:03 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 13-05-2024 12:50. Trained with Centralised Machine Learning technology.
Epoch 1, lr: 0.006, optimizer: DPOptimizer
Train accuracy: 71.24 %, Validation accuracy: 73.79 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 5, 0s: 613
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 72.33%
Accuracy 2 : 72.33%
Precision: 46.38%
Recall: 49.85%
F1 Score: 42.53%
Classification report:
              precision    recall  f1-score   support

           0     0.7276    0.9911    0.8391       450
           1     0.2000    0.0060    0.0116       168

    accuracy                         0.7233       618
   macro avg     0.4638    0.4985    0.4253       618
weighted avg     0.5842    0.7233    0.6142       618

-------- Testing finished --------
