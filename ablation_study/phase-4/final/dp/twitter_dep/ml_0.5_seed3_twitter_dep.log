Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.5,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0.5_seed3_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  887462
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
max_grad_norm:  1.5
Epoch [1/12], Step [100/496], Loss: 0.9834, Accuracy: 66.25 %, Epsilon: 0.04, Delta: 0.0030
Epoch [1/12], Step [200/496], Loss: 1.0456, Accuracy: 69.50 %, Epsilon: 0.07, Delta: 0.0030
Epoch [1/12], Step [300/496], Loss: 1.0929, Accuracy: 71.50 %, Epsilon: 0.08, Delta: 0.0030
Epoch [1/12], Step [400/496], Loss: 1.1999, Accuracy: 70.88 %, Epsilon: 0.10, Delta: 0.0030
Predictions - 1s: 58, 0s: 1924
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [1/12] Loss: 1.2164, Accuracy: 71.09 %, Epsilon: 0.11, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 0, 0s: 496
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.5661, Validation Accuracy: 74.40 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 1.5661 and Validation Accuracy: 74.40 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 1.3046, Accuracy: 74.00 %, Epsilon: 0.13, Delta: 0.0030
Epoch [2/12], Step [200/496], Loss: 1.3496, Accuracy: 70.38 %, Epsilon: 0.14, Delta: 0.0030
Epoch [2/12], Step [300/496], Loss: 1.5050, Accuracy: 70.67 %, Epsilon: 0.15, Delta: 0.0030
Epoch [2/12], Step [400/496], Loss: 1.4747, Accuracy: 69.88 %, Epsilon: 0.16, Delta: 0.0030
Predictions - 1s: 132, 0s: 1850
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [2/12] Loss: 1.5478, Accuracy: 69.48 %, Epsilon: 0.17, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 18, 0s: 478
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.3880, Validation Accuracy: 72.78 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 1.3880 and Validation Accuracy: 72.78 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 1.8802, Accuracy: 69.50 %, Epsilon: 0.18, Delta: 0.0030
Epoch [3/12], Step [200/496], Loss: 1.8744, Accuracy: 67.62 %, Epsilon: 0.19, Delta: 0.0030
Epoch [3/12], Step [300/496], Loss: 1.8293, Accuracy: 69.17 %, Epsilon: 0.20, Delta: 0.0030
Epoch [3/12], Step [400/496], Loss: 1.7805, Accuracy: 69.44 %, Epsilon: 0.21, Delta: 0.0030
Predictions - 1s: 170, 0s: 1812
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [3/12] Loss: 1.7884, Accuracy: 69.17 %, Epsilon: 0.22, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 28, 0s: 468
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.5459, Validation Accuracy: 71.98 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 2.1263, Accuracy: 65.50 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [200/496], Loss: 1.9762, Accuracy: 68.00 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [300/496], Loss: 2.0367, Accuracy: 69.25 %, Epsilon: 0.24, Delta: 0.0030
Epoch [4/12], Step [400/496], Loss: 2.1390, Accuracy: 68.69 %, Epsilon: 0.25, Delta: 0.0030
Predictions - 1s: 152, 0s: 1830
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [4/12] Loss: 2.0622, Accuracy: 69.48 %, Epsilon: 0.26, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 16, 0s: 480
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.9195, Validation Accuracy: 73.99 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 2.0687, Accuracy: 68.75 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [200/496], Loss: 2.2879, Accuracy: 70.88 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [300/496], Loss: 2.1323, Accuracy: 69.58 %, Epsilon: 0.28, Delta: 0.0030
Epoch [5/12], Step [400/496], Loss: 2.0837, Accuracy: 68.44 %, Epsilon: 0.29, Delta: 0.0030
Predictions - 1s: 216, 0s: 1766
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [5/12] Loss: 2.1170, Accuracy: 68.16 %, Epsilon: 0.29, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 29, 0s: 467
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.1162, Validation Accuracy: 72.98 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 2.5828, Accuracy: 63.50 %, Epsilon: 0.30, Delta: 0.0030
Epoch [6/12], Step [200/496], Loss: 2.5646, Accuracy: 64.12 %, Epsilon: 0.31, Delta: 0.0030
Epoch [6/12], Step [300/496], Loss: 2.3470, Accuracy: 64.67 %, Epsilon: 0.32, Delta: 0.0030
Epoch [6/12], Step [400/496], Loss: 2.2280, Accuracy: 66.00 %, Epsilon: 0.32, Delta: 0.0030
Predictions - 1s: 275, 0s: 1707
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [6/12] Loss: 2.2687, Accuracy: 66.40 %, Epsilon: 0.33, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 17, 0s: 479
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.3414, Validation Accuracy: 72.98 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 1.9751, Accuracy: 71.75 %, Epsilon: 0.33, Delta: 0.0030
Epoch [7/12], Step [200/496], Loss: 2.2844, Accuracy: 66.38 %, Epsilon: 0.34, Delta: 0.0030
Epoch [7/12], Step [300/496], Loss: 2.1137, Accuracy: 67.50 %, Epsilon: 0.35, Delta: 0.0030
Epoch [7/12], Step [400/496], Loss: 2.0831, Accuracy: 67.75 %, Epsilon: 0.35, Delta: 0.0030
Predictions - 1s: 234, 0s: 1748
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [7/12] Loss: 2.1810, Accuracy: 66.75 %, Epsilon: 0.36, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 41, 0s: 455
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.7800, Validation Accuracy: 72.98 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 2.3225, Accuracy: 68.50 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [200/496], Loss: 2.3919, Accuracy: 68.75 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [300/496], Loss: 2.2672, Accuracy: 69.08 %, Epsilon: 0.38, Delta: 0.0030
Epoch [8/12], Step [400/496], Loss: 2.2682, Accuracy: 68.94 %, Epsilon: 0.38, Delta: 0.0030
Predictions - 1s: 198, 0s: 1784
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [8/12] Loss: 2.2264, Accuracy: 68.97 %, Epsilon: 0.39, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 15, 0s: 481
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.1554, Validation Accuracy: 72.58 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 1.9504, Accuracy: 73.00 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [200/496], Loss: 2.2672, Accuracy: 69.62 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [300/496], Loss: 2.1596, Accuracy: 69.42 %, Epsilon: 0.41, Delta: 0.0030
Epoch [9/12], Step [400/496], Loss: 2.1145, Accuracy: 69.31 %, Epsilon: 0.41, Delta: 0.0030
Predictions - 1s: 209, 0s: 1773
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [9/12] Loss: 2.1251, Accuracy: 68.82 %, Epsilon: 0.42, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 16, 0s: 480
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.1448, Validation Accuracy: 73.99 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 2.0689, Accuracy: 68.00 %, Epsilon: 0.42, Delta: 0.0030
Epoch [10/12], Step [200/496], Loss: 2.2804, Accuracy: 65.88 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [300/496], Loss: 2.1886, Accuracy: 66.58 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [400/496], Loss: 2.1923, Accuracy: 66.94 %, Epsilon: 0.44, Delta: 0.0030
Predictions - 1s: 267, 0s: 1715
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [10/12] Loss: 2.1868, Accuracy: 66.50 %, Epsilon: 0.44, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 31, 0s: 465
True Labels - 1s: 127, 0s: 369
Validation Loss: 1.9359, Validation Accuracy: 70.97 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 2.1004, Accuracy: 66.50 %, Epsilon: 0.45, Delta: 0.0030
Epoch [11/12], Step [200/496], Loss: 2.0696, Accuracy: 66.38 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [300/496], Loss: 2.1288, Accuracy: 66.00 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [400/496], Loss: 2.1685, Accuracy: 65.38 %, Epsilon: 0.47, Delta: 0.0030
Predictions - 1s: 262, 0s: 1720
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [11/12] Loss: 2.1274, Accuracy: 65.94 %, Epsilon: 0.47, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 16, 0s: 480
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.0013, Validation Accuracy: 73.19 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 2.1072, Accuracy: 69.50 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [200/496], Loss: 1.9882, Accuracy: 69.00 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [300/496], Loss: 2.0815, Accuracy: 68.58 %, Epsilon: 0.49, Delta: 0.0030
Epoch [12/12], Step [400/496], Loss: 2.1563, Accuracy: 67.94 %, Epsilon: 0.49, Delta: 0.0030
Predictions - 1s: 214, 0s: 1768
True Labels - 1s: 547, 0s: 1435
-------------------------------
Epoch [12/12] Loss: 2.1841, Accuracy: 68.16 %, Epsilon: 0.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 17, 0s: 479
True Labels - 1s: 127, 0s: 369
Validation Loss: 2.0076, Validation Accuracy: 72.58 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 1.3880 and Validation Accuracy: 72.78 %

-------- Training finished in 4:03 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 13-05-2024 13:18. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 0.006, optimizer: DPOptimizer
Train accuracy: 69.48 %, Validation accuracy: 72.78 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 24, 0s: 594
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 73.46%
Accuracy 2 : 73.46%
Precision: 66.20%
Recall: 53.06%
F1 Score: 49.44%
Classification report:
              precision    recall  f1-score   support

           0     0.7407    0.9778    0.8429       450
           1     0.5833    0.0833    0.1458       168

    accuracy                         0.7346       618
   macro avg     0.6620    0.5306    0.4944       618
weighted avg     0.6980    0.7346    0.6534       618

-------- Testing finished --------
