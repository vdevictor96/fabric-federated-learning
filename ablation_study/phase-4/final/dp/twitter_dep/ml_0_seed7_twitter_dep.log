Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0_seed7_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  597388
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5816, Accuracy: 70.00 %
Epoch [1/12], Step [200/496], Loss: 0.5280, Accuracy: 75.12 %
Epoch [1/12], Step [300/496], Loss: 0.5003, Accuracy: 77.00 %
Epoch [1/12], Step [400/496], Loss: 0.4914, Accuracy: 77.38 %
Predictions - 1s: 309, 0s: 1673
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [1/12] Loss: 0.4804, Accuracy: 78.15 %
-------------------------------
-------- Validation --------
Predictions - 1s: 31, 0s: 465
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.5024, Validation Accuracy: 76.41 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.5024 and Validation Accuracy: 76.41 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.3957, Accuracy: 81.00 %
Epoch [2/12], Step [200/496], Loss: 0.3853, Accuracy: 82.62 %
Epoch [2/12], Step [300/496], Loss: 0.3899, Accuracy: 82.67 %
Epoch [2/12], Step [400/496], Loss: 0.3790, Accuracy: 83.25 %
Predictions - 1s: 434, 0s: 1548
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [2/12] Loss: 0.3823, Accuracy: 82.85 %
-------------------------------
-------- Validation --------
Predictions - 1s: 215, 0s: 281
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.5202, Validation Accuracy: 71.98 %
-------- Validation finished --------
Epoch [3/12], Step [100/496], Loss: 0.3198, Accuracy: 85.75 %
Epoch [3/12], Step [200/496], Loss: 0.3260, Accuracy: 84.75 %
Epoch [3/12], Step [300/496], Loss: 0.3383, Accuracy: 84.17 %
Epoch [3/12], Step [400/496], Loss: 0.3377, Accuracy: 84.50 %
Predictions - 1s: 468, 0s: 1514
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [3/12] Loss: 0.3278, Accuracy: 84.96 %
-------------------------------
-------- Validation --------
Predictions - 1s: 121, 0s: 375
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.4335, Validation Accuracy: 80.44 %
-------- Validation finished --------
Updated best model in epoch 3 saved with Validation Loss: 0.4335 and Validation Accuracy: 80.44 %
-------------------------------
Epoch [4/12], Step [100/496], Loss: 0.2707, Accuracy: 88.00 %
Epoch [4/12], Step [200/496], Loss: 0.2730, Accuracy: 87.50 %
Epoch [4/12], Step [300/496], Loss: 0.2853, Accuracy: 86.58 %
Epoch [4/12], Step [400/496], Loss: 0.2843, Accuracy: 86.81 %
Predictions - 1s: 509, 0s: 1473
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [4/12] Loss: 0.2782, Accuracy: 87.03 %
-------------------------------
-------- Validation --------
Predictions - 1s: 140, 0s: 356
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.4704, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 0.1999, Accuracy: 92.50 %
Epoch [5/12], Step [200/496], Loss: 0.2048, Accuracy: 91.50 %
Epoch [5/12], Step [300/496], Loss: 0.2148, Accuracy: 90.83 %
Epoch [5/12], Step [400/496], Loss: 0.2138, Accuracy: 91.19 %
Predictions - 1s: 520, 0s: 1462
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [5/12] Loss: 0.2133, Accuracy: 91.12 %
-------------------------------
-------- Validation --------
Predictions - 1s: 143, 0s: 353
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.4854, Validation Accuracy: 79.64 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 0.1628, Accuracy: 94.50 %
Epoch [6/12], Step [200/496], Loss: 0.1667, Accuracy: 94.00 %
Epoch [6/12], Step [300/496], Loss: 0.1702, Accuracy: 93.42 %
Epoch [6/12], Step [400/496], Loss: 0.1799, Accuracy: 93.00 %
Predictions - 1s: 517, 0s: 1465
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [6/12] Loss: 0.1802, Accuracy: 92.89 %
-------------------------------
-------- Validation --------
Predictions - 1s: 158, 0s: 338
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.5447, Validation Accuracy: 79.03 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.1167, Accuracy: 95.25 %
Epoch [7/12], Step [200/496], Loss: 0.1168, Accuracy: 95.50 %
Epoch [7/12], Step [300/496], Loss: 0.1291, Accuracy: 95.25 %
Epoch [7/12], Step [400/496], Loss: 0.1324, Accuracy: 95.00 %
Predictions - 1s: 528, 0s: 1454
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [7/12] Loss: 0.1267, Accuracy: 95.16 %
-------------------------------
-------- Validation --------
Predictions - 1s: 108, 0s: 388
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.5861, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.1172, Accuracy: 94.50 %
Epoch [8/12], Step [200/496], Loss: 0.1067, Accuracy: 95.88 %
Epoch [8/12], Step [300/496], Loss: 0.1016, Accuracy: 96.00 %
Epoch [8/12], Step [400/496], Loss: 0.0954, Accuracy: 96.44 %
Predictions - 1s: 539, 0s: 1443
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [8/12] Loss: 0.0982, Accuracy: 96.22 %
-------------------------------
-------- Validation --------
Predictions - 1s: 122, 0s: 374
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.6247, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.0864, Accuracy: 96.75 %
Epoch [9/12], Step [200/496], Loss: 0.0770, Accuracy: 97.00 %
Epoch [9/12], Step [300/496], Loss: 0.0764, Accuracy: 97.33 %
Epoch [9/12], Step [400/496], Loss: 0.0769, Accuracy: 97.31 %
Predictions - 1s: 536, 0s: 1446
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [9/12] Loss: 0.0812, Accuracy: 97.28 %
-------------------------------
-------- Validation --------
Predictions - 1s: 137, 0s: 359
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.6764, Validation Accuracy: 77.62 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.0559, Accuracy: 98.75 %
Epoch [10/12], Step [200/496], Loss: 0.0734, Accuracy: 97.62 %
Epoch [10/12], Step [300/496], Loss: 0.0698, Accuracy: 97.83 %
Epoch [10/12], Step [400/496], Loss: 0.0677, Accuracy: 97.88 %
Predictions - 1s: 539, 0s: 1443
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [10/12] Loss: 0.0690, Accuracy: 97.73 %
-------------------------------
-------- Validation --------
Predictions - 1s: 134, 0s: 362
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.6902, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.0592, Accuracy: 97.75 %
Epoch [11/12], Step [200/496], Loss: 0.0540, Accuracy: 98.25 %
Epoch [11/12], Step [300/496], Loss: 0.0565, Accuracy: 98.00 %
Epoch [11/12], Step [400/496], Loss: 0.0562, Accuracy: 97.94 %
Predictions - 1s: 545, 0s: 1437
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [11/12] Loss: 0.0551, Accuracy: 98.13 %
-------------------------------
-------- Validation --------
Predictions - 1s: 132, 0s: 364
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.6984, Validation Accuracy: 77.82 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.0545, Accuracy: 98.50 %
Epoch [12/12], Step [200/496], Loss: 0.0541, Accuracy: 98.25 %
Epoch [12/12], Step [300/496], Loss: 0.0524, Accuracy: 98.33 %
Epoch [12/12], Step [400/496], Loss: 0.0526, Accuracy: 98.31 %
Predictions - 1s: 539, 0s: 1443
True Labels - 1s: 540, 0s: 1442
-------------------------------
Epoch [12/12] Loss: 0.0518, Accuracy: 98.34 %
-------------------------------
-------- Validation --------
Predictions - 1s: 135, 0s: 361
True Labels - 1s: 134, 0s: 362
Validation Loss: 0.7073, Validation Accuracy: 78.43 %
-------- Validation finished --------
Best model in epoch 3 saved with with Validation Loss: 0.4335 and Validation Accuracy: 80.44 %

-------- Training finished in 1:39 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 20-04-2024 11:16. Trained with Centralised Machine Learning technology.
Epoch 3, lr: 6e-05, optimizer: AdamW
Train accuracy: 84.96 %, Validation accuracy: 80.44 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 155, 0s: 463
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 83.66%
Accuracy 2 : 83.66%
Precision: 79.65%
Recall: 78.15%
F1 Score: 78.83%
Classification report:
              precision    recall  f1-score   support

           0     0.8769    0.9022    0.8894       450
           1     0.7161    0.6607    0.6873       168

    accuracy                         0.8366       618
   macro avg     0.7965    0.7815    0.7883       618
weighted avg     0.8332    0.8366    0.8344       618

-------- Testing finished --------
