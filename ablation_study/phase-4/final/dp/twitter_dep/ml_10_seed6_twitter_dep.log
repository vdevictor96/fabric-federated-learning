Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 10,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_10_seed6_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  598901
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
max_grad_norm:  1.5
Epoch [1/12], Step [100/496], Loss: 1.1718, Accuracy: 69.25 %, Epsilon: 1.85, Delta: 0.0030
Epoch [1/12], Step [200/496], Loss: 1.2411, Accuracy: 72.12 %, Epsilon: 2.50, Delta: 0.0030
Epoch [1/12], Step [300/496], Loss: 1.2944, Accuracy: 73.92 %, Epsilon: 2.92, Delta: 0.0030
Epoch [1/12], Step [400/496], Loss: 1.3821, Accuracy: 73.38 %, Epsilon: 3.24, Delta: 0.0030
Predictions - 1s: 31, 0s: 1951
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [1/12] Loss: 1.4708, Accuracy: 72.65 %, Epsilon: 3.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 1, 0s: 495
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.4918, Validation Accuracy: 70.56 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 2.4918 and Validation Accuracy: 70.56 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 1.6726, Accuracy: 75.50 %, Epsilon: 3.73, Delta: 0.0030
Epoch [2/12], Step [200/496], Loss: 1.9425, Accuracy: 73.50 %, Epsilon: 3.94, Delta: 0.0030
Epoch [2/12], Step [300/496], Loss: 1.8491, Accuracy: 72.75 %, Epsilon: 4.14, Delta: 0.0030
Epoch [2/12], Step [400/496], Loss: 1.8070, Accuracy: 72.69 %, Epsilon: 4.33, Delta: 0.0030
Predictions - 1s: 66, 0s: 1916
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [2/12] Loss: 1.8446, Accuracy: 72.00 %, Epsilon: 4.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 27, 0s: 469
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.0734, Validation Accuracy: 66.13 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 2.0734 and Validation Accuracy: 66.13 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 2.0695, Accuracy: 70.00 %, Epsilon: 4.66, Delta: 0.0030
Epoch [3/12], Step [200/496], Loss: 2.1052, Accuracy: 69.62 %, Epsilon: 4.83, Delta: 0.0030
Epoch [3/12], Step [300/496], Loss: 2.0754, Accuracy: 70.25 %, Epsilon: 4.98, Delta: 0.0030
Epoch [3/12], Step [400/496], Loss: 2.0466, Accuracy: 69.50 %, Epsilon: 5.13, Delta: 0.0030
Predictions - 1s: 125, 0s: 1857
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [3/12] Loss: 2.0034, Accuracy: 70.23 %, Epsilon: 5.27, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 15, 0s: 481
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.1207, Validation Accuracy: 70.16 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 2.1595, Accuracy: 71.00 %, Epsilon: 5.41, Delta: 0.0030
Epoch [4/12], Step [200/496], Loss: 2.2176, Accuracy: 68.00 %, Epsilon: 5.55, Delta: 0.0030
Epoch [4/12], Step [300/496], Loss: 2.0967, Accuracy: 69.00 %, Epsilon: 5.69, Delta: 0.0030
Epoch [4/12], Step [400/496], Loss: 1.9806, Accuracy: 68.69 %, Epsilon: 5.82, Delta: 0.0030
Predictions - 1s: 187, 0s: 1795
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [4/12] Loss: 2.0016, Accuracy: 68.92 %, Epsilon: 5.94, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 14, 0s: 482
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.1466, Validation Accuracy: 70.36 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 1.9935, Accuracy: 69.00 %, Epsilon: 6.07, Delta: 0.0030
Epoch [5/12], Step [200/496], Loss: 2.1096, Accuracy: 68.88 %, Epsilon: 6.20, Delta: 0.0030
Epoch [5/12], Step [300/496], Loss: 2.0986, Accuracy: 69.75 %, Epsilon: 6.32, Delta: 0.0030
Epoch [5/12], Step [400/496], Loss: 2.1212, Accuracy: 69.19 %, Epsilon: 6.44, Delta: 0.0030
Predictions - 1s: 157, 0s: 1825
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [5/12] Loss: 2.0762, Accuracy: 69.83 %, Epsilon: 6.56, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 36, 0s: 460
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.2367, Validation Accuracy: 66.73 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 1.6485, Accuracy: 73.50 %, Epsilon: 6.67, Delta: 0.0030
Epoch [6/12], Step [200/496], Loss: 2.0210, Accuracy: 72.12 %, Epsilon: 6.79, Delta: 0.0030
Epoch [6/12], Step [300/496], Loss: 2.1135, Accuracy: 71.33 %, Epsilon: 6.90, Delta: 0.0030
Epoch [6/12], Step [400/496], Loss: 2.0910, Accuracy: 70.56 %, Epsilon: 7.01, Delta: 0.0030
Predictions - 1s: 216, 0s: 1766
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [6/12] Loss: 2.1345, Accuracy: 69.48 %, Epsilon: 7.12, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 74, 0s: 422
True Labels - 1s: 145, 0s: 351
Validation Loss: 1.7173, Validation Accuracy: 64.31 %
-------- Validation finished --------
Updated best model in epoch 6 saved with Validation Loss: 1.7173 and Validation Accuracy: 64.31 %
-------------------------------
Epoch [7/12], Step [100/496], Loss: 2.0829, Accuracy: 66.25 %, Epsilon: 7.23, Delta: 0.0030
Epoch [7/12], Step [200/496], Loss: 2.0734, Accuracy: 68.00 %, Epsilon: 7.34, Delta: 0.0030
Epoch [7/12], Step [300/496], Loss: 2.1499, Accuracy: 67.17 %, Epsilon: 7.45, Delta: 0.0030
Epoch [7/12], Step [400/496], Loss: 2.0426, Accuracy: 68.19 %, Epsilon: 7.55, Delta: 0.0030
Predictions - 1s: 245, 0s: 1737
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [7/12] Loss: 2.0905, Accuracy: 69.02 %, Epsilon: 7.65, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 23, 0s: 473
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.3333, Validation Accuracy: 69.35 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 2.2118, Accuracy: 74.00 %, Epsilon: 7.76, Delta: 0.0030
Epoch [8/12], Step [200/496], Loss: 2.1249, Accuracy: 73.62 %, Epsilon: 7.86, Delta: 0.0030
Epoch [8/12], Step [300/496], Loss: 2.1750, Accuracy: 71.75 %, Epsilon: 7.96, Delta: 0.0030
Epoch [8/12], Step [400/496], Loss: 2.2286, Accuracy: 70.12 %, Epsilon: 8.06, Delta: 0.0030
Predictions - 1s: 176, 0s: 1806
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [8/12] Loss: 2.2259, Accuracy: 69.68 %, Epsilon: 8.16, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 24, 0s: 472
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.5245, Validation Accuracy: 68.35 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 2.3963, Accuracy: 69.75 %, Epsilon: 8.26, Delta: 0.0030
Epoch [9/12], Step [200/496], Loss: 2.4038, Accuracy: 68.38 %, Epsilon: 8.36, Delta: 0.0030
Epoch [9/12], Step [300/496], Loss: 2.3508, Accuracy: 68.58 %, Epsilon: 8.46, Delta: 0.0030
Epoch [9/12], Step [400/496], Loss: 2.3085, Accuracy: 69.06 %, Epsilon: 8.55, Delta: 0.0030
Predictions - 1s: 218, 0s: 1764
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [9/12] Loss: 2.3420, Accuracy: 68.57 %, Epsilon: 8.64, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 52, 0s: 444
True Labels - 1s: 145, 0s: 351
Validation Loss: 1.9058, Validation Accuracy: 69.96 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 1.8127, Accuracy: 72.75 %, Epsilon: 8.74, Delta: 0.0030
Epoch [10/12], Step [200/496], Loss: 2.1837, Accuracy: 70.12 %, Epsilon: 8.83, Delta: 0.0030
Epoch [10/12], Step [300/496], Loss: 2.1841, Accuracy: 69.75 %, Epsilon: 8.93, Delta: 0.0030
Epoch [10/12], Step [400/496], Loss: 2.1794, Accuracy: 68.75 %, Epsilon: 9.02, Delta: 0.0030
Predictions - 1s: 231, 0s: 1751
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [10/12] Loss: 2.1484, Accuracy: 69.02 %, Epsilon: 9.11, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 36, 0s: 460
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.1203, Validation Accuracy: 67.94 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 2.2138, Accuracy: 68.50 %, Epsilon: 9.20, Delta: 0.0030
Epoch [11/12], Step [200/496], Loss: 2.2352, Accuracy: 68.88 %, Epsilon: 9.29, Delta: 0.0030
Epoch [11/12], Step [300/496], Loss: 2.1953, Accuracy: 70.08 %, Epsilon: 9.39, Delta: 0.0030
Epoch [11/12], Step [400/496], Loss: 2.2942, Accuracy: 68.50 %, Epsilon: 9.48, Delta: 0.0030
Predictions - 1s: 193, 0s: 1789
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [11/12] Loss: 2.2501, Accuracy: 68.52 %, Epsilon: 9.56, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 30, 0s: 466
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.2034, Validation Accuracy: 68.75 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 2.0442, Accuracy: 70.75 %, Epsilon: 9.65, Delta: 0.0030
Epoch [12/12], Step [200/496], Loss: 1.9814, Accuracy: 70.88 %, Epsilon: 9.74, Delta: 0.0030
Epoch [12/12], Step [300/496], Loss: 2.0640, Accuracy: 70.17 %, Epsilon: 9.83, Delta: 0.0030
Epoch [12/12], Step [400/496], Loss: 2.1513, Accuracy: 69.25 %, Epsilon: 9.92, Delta: 0.0030
Predictions - 1s: 209, 0s: 1773
True Labels - 1s: 529, 0s: 1453
-------------------------------
Epoch [12/12] Loss: 2.1414, Accuracy: 69.42 %, Epsilon: 10.00, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 35, 0s: 461
True Labels - 1s: 145, 0s: 351
Validation Loss: 2.1420, Validation Accuracy: 67.34 %
-------- Validation finished --------
Best model in epoch 6 saved with with Validation Loss: 1.7173 and Validation Accuracy: 64.31 %

-------- Training finished in 4:27 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 13-05-2024 11:54. Trained with Centralised Machine Learning technology.
Epoch 6, lr: 0.006, optimizer: DPOptimizer
Train accuracy: 69.48 %, Validation accuracy: 64.31 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 127, 0s: 491
True Labels - 1s: 168, 0s: 450
NÂº of test samples: 618
Accuracy: 65.86%
Accuracy 2 : 65.86%
Precision: 53.70%
Recall: 53.06%
F1 Score: 53.03%
Classification report:
              precision    recall  f1-score   support

           0     0.7434    0.8111    0.7758       450
           1     0.3307    0.2500    0.2847       168

    accuracy                         0.6586       618
   macro avg     0.5370    0.5306    0.5303       618
weighted avg     0.6312    0.6586    0.6423       618

-------- Testing finished --------
