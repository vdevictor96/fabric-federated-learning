Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 6e-05,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0_seed9_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  413686
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training without differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
Epoch [1/12], Step [100/496], Loss: 0.5426, Accuracy: 74.25 %
Epoch [1/12], Step [200/496], Loss: 0.5263, Accuracy: 74.00 %
Epoch [1/12], Step [300/496], Loss: 0.5026, Accuracy: 75.75 %
Epoch [1/12], Step [400/496], Loss: 0.4824, Accuracy: 77.12 %
Predictions - 1s: 295, 0s: 1687
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [1/12] Loss: 0.4772, Accuracy: 77.45 %
-------------------------------
-------- Validation --------
Predictions - 1s: 116, 0s: 380
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.4520, Validation Accuracy: 77.42 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 0.4520 and Validation Accuracy: 77.42 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 0.3761, Accuracy: 84.00 %
Epoch [2/12], Step [200/496], Loss: 0.4010, Accuracy: 82.88 %
Epoch [2/12], Step [300/496], Loss: 0.3987, Accuracy: 82.58 %
Epoch [2/12], Step [400/496], Loss: 0.3953, Accuracy: 82.56 %
Predictions - 1s: 412, 0s: 1570
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [2/12] Loss: 0.3873, Accuracy: 83.05 %
-------------------------------
-------- Validation --------
Predictions - 1s: 147, 0s: 349
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.4506, Validation Accuracy: 77.62 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 0.4506 and Validation Accuracy: 77.62 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 0.3420, Accuracy: 85.50 %
Epoch [3/12], Step [200/496], Loss: 0.3222, Accuracy: 86.00 %
Epoch [3/12], Step [300/496], Loss: 0.3161, Accuracy: 86.25 %
Epoch [3/12], Step [400/496], Loss: 0.3148, Accuracy: 86.00 %
Predictions - 1s: 450, 0s: 1532
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [3/12] Loss: 0.3197, Accuracy: 85.47 %
-------------------------------
-------- Validation --------
Predictions - 1s: 104, 0s: 392
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.4923, Validation Accuracy: 79.03 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 0.2657, Accuracy: 89.25 %
Epoch [4/12], Step [200/496], Loss: 0.2649, Accuracy: 89.00 %
Epoch [4/12], Step [300/496], Loss: 0.2519, Accuracy: 89.67 %
Epoch [4/12], Step [400/496], Loss: 0.2652, Accuracy: 88.81 %
Predictions - 1s: 466, 0s: 1516
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [4/12] Loss: 0.2728, Accuracy: 88.40 %
-------------------------------
-------- Validation --------
Predictions - 1s: 123, 0s: 373
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.4783, Validation Accuracy: 78.83 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 0.1997, Accuracy: 91.75 %
Epoch [5/12], Step [200/496], Loss: 0.1982, Accuracy: 91.88 %
Epoch [5/12], Step [300/496], Loss: 0.2120, Accuracy: 91.58 %
Epoch [5/12], Step [400/496], Loss: 0.2183, Accuracy: 90.88 %
Predictions - 1s: 486, 0s: 1496
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [5/12] Loss: 0.2189, Accuracy: 91.22 %
-------------------------------
-------- Validation --------
Predictions - 1s: 136, 0s: 360
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.5292, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 0.1773, Accuracy: 93.50 %
Epoch [6/12], Step [200/496], Loss: 0.1633, Accuracy: 94.12 %
Epoch [6/12], Step [300/496], Loss: 0.1628, Accuracy: 93.75 %
Epoch [6/12], Step [400/496], Loss: 0.1620, Accuracy: 93.81 %
Predictions - 1s: 481, 0s: 1501
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [6/12] Loss: 0.1605, Accuracy: 93.79 %
-------------------------------
-------- Validation --------
Predictions - 1s: 125, 0s: 371
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.6056, Validation Accuracy: 78.43 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 0.1359, Accuracy: 96.25 %
Epoch [7/12], Step [200/496], Loss: 0.1327, Accuracy: 95.62 %
Epoch [7/12], Step [300/496], Loss: 0.1260, Accuracy: 95.33 %
Epoch [7/12], Step [400/496], Loss: 0.1289, Accuracy: 95.06 %
Predictions - 1s: 492, 0s: 1490
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [7/12] Loss: 0.1256, Accuracy: 95.36 %
-------------------------------
-------- Validation --------
Predictions - 1s: 103, 0s: 393
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.6829, Validation Accuracy: 77.62 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 0.0941, Accuracy: 95.50 %
Epoch [8/12], Step [200/496], Loss: 0.0931, Accuracy: 96.12 %
Epoch [8/12], Step [300/496], Loss: 0.1009, Accuracy: 95.75 %
Epoch [8/12], Step [400/496], Loss: 0.0994, Accuracy: 95.88 %
Predictions - 1s: 500, 0s: 1482
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [8/12] Loss: 0.0958, Accuracy: 96.06 %
-------------------------------
-------- Validation --------
Predictions - 1s: 123, 0s: 373
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.6926, Validation Accuracy: 78.83 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 0.0775, Accuracy: 97.75 %
Epoch [9/12], Step [200/496], Loss: 0.0856, Accuracy: 97.12 %
Epoch [9/12], Step [300/496], Loss: 0.0814, Accuracy: 97.17 %
Epoch [9/12], Step [400/496], Loss: 0.0857, Accuracy: 96.81 %
Predictions - 1s: 508, 0s: 1474
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [9/12] Loss: 0.0786, Accuracy: 97.17 %
-------------------------------
-------- Validation --------
Predictions - 1s: 146, 0s: 350
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.7211, Validation Accuracy: 79.44 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 0.0751, Accuracy: 97.50 %
Epoch [10/12], Step [200/496], Loss: 0.0758, Accuracy: 97.38 %
Epoch [10/12], Step [300/496], Loss: 0.0723, Accuracy: 97.42 %
Epoch [10/12], Step [400/496], Loss: 0.0687, Accuracy: 97.62 %
Predictions - 1s: 516, 0s: 1466
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [10/12] Loss: 0.0670, Accuracy: 97.68 %
-------------------------------
-------- Validation --------
Predictions - 1s: 127, 0s: 369
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.7684, Validation Accuracy: 78.83 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 0.0496, Accuracy: 99.00 %
Epoch [11/12], Step [200/496], Loss: 0.0456, Accuracy: 98.88 %
Epoch [11/12], Step [300/496], Loss: 0.0541, Accuracy: 98.33 %
Epoch [11/12], Step [400/496], Loss: 0.0508, Accuracy: 98.50 %
Predictions - 1s: 518, 0s: 1464
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [11/12] Loss: 0.0489, Accuracy: 98.69 %
-------------------------------
-------- Validation --------
Predictions - 1s: 145, 0s: 351
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.7713, Validation Accuracy: 78.43 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 0.0506, Accuracy: 97.25 %
Epoch [12/12], Step [200/496], Loss: 0.0545, Accuracy: 97.62 %
Epoch [12/12], Step [300/496], Loss: 0.0565, Accuracy: 97.75 %
Epoch [12/12], Step [400/496], Loss: 0.0528, Accuracy: 97.94 %
Predictions - 1s: 518, 0s: 1464
True Labels - 1s: 518, 0s: 1464
-------------------------------
Epoch [12/12] Loss: 0.0538, Accuracy: 97.88 %
-------------------------------
-------- Validation --------
Predictions - 1s: 150, 0s: 346
True Labels - 1s: 156, 0s: 340
Validation Loss: 0.7687, Validation Accuracy: 77.82 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 0.4506 and Validation Accuracy: 77.62 %

-------- Training finished in 1:40 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 20-04-2024 12:10. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 6e-05, optimizer: AdamW
Train accuracy: 83.05 %, Validation accuracy: 77.62 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 170, 0s: 448
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 80.91%
Accuracy 2 : 80.91%
Precision: 75.88%
Recall: 76.07%
F1 Score: 75.97%
Classification report:
              precision    recall  f1-score   support

           0     0.8705    0.8667    0.8686       450
           1     0.6471    0.6548    0.6509       168

    accuracy                         0.8091       618
   macro avg     0.7588    0.7607    0.7597       618
weighted avg     0.8098    0.8091    0.8094       618

-------- Testing finished --------
