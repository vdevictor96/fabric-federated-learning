Current configuration:
{
    "concurrency_flag": true,
    "data_distribution": "iid",
    "dataset": "twitter_dep",
    "device": "cuda",
    "dp_delta": 0.003,
    "dp_epsilon": 0.5,
    "eval_batch_size": 4,
    "eval_flag": true,
    "eval_size": 0.2,
    "fed_alg": "fedavg",
    "layers": 3,
    "learning_rate": 0.006,
    "max_length": 512,
    "ml_mode": "ml",
    "model": "bert_small",
    "model_name": "ml_0.5_seed9_twitter_dep",
    "models_path": "/local/vpaloma/fabric-federated-learning/ablation_study/phase-4/final/dp/twitter_dep",
    "mu": 0.5,
    "num_clients": 5,
    "num_epochs": 12,
    "num_rounds": 4,
    "optimizer": "AdamW",
    "progress_bar_flag": false,
    "save_model": true,
    "scheduler": "linear",
    "scheduler_warmup_steps": 0,
    "seed": "random",
    "test_flag": true,
    "train_batch_size": 4,
    "train_size": 0.8
}
-------- Configuration loaded --------

-------- Setting device --------
cuda device selected and available.
-------- Device set --------

-------- Setting seed --------
seed set:  639538
-------- Seed set --------

-------- Creating Model --------
-------- Model created --------

-------- Setting Trainable Layers --------
Training the last 3 layers.

Total parameters count: 28764674
Trainable parameters count: 3416066
-------- Trainable Layers set --------

-------- Creating Tokenizer --------
-------- Tokenizer created --------

-------- Creating Train and Eval Dataloaders --------
Train Loader: 1982 total sentences. 496 batches of size 4.
Eval Loader: 496 total sentences. 124 batches of size 4.
-------- Train and Eval Dataloaders created --------

-------- Creating Optimizer --------
-------- Optimizer created --------

-------- Creating Scheduler --------
-------- Scheduler created --------

-------- Training --------
Training with Centralised Machine Learning technology.
Training with differential privacy.
Concurrency flag is set to True, but ml mode is selected. Concurrency flag will be ignored.
max_grad_norm:  1.5
Epoch [1/12], Step [100/496], Loss: 1.0123, Accuracy: 74.00 %, Epsilon: 0.04, Delta: 0.0030
Epoch [1/12], Step [200/496], Loss: 1.1502, Accuracy: 72.62 %, Epsilon: 0.07, Delta: 0.0030
Epoch [1/12], Step [300/496], Loss: 1.1505, Accuracy: 72.25 %, Epsilon: 0.08, Delta: 0.0030
Epoch [1/12], Step [400/496], Loss: 1.2348, Accuracy: 71.56 %, Epsilon: 0.10, Delta: 0.0030
Predictions - 1s: 37, 0s: 1945
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [1/12] Loss: 1.3838, Accuracy: 70.99 %, Epsilon: 0.11, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 7, 0s: 489
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.3139, Validation Accuracy: 76.41 %
-------- Validation finished --------
Updated best model in epoch 1 saved with Validation Loss: 1.3139 and Validation Accuracy: 76.41 %
-------------------------------
Epoch [2/12], Step [100/496], Loss: 1.2691, Accuracy: 64.50 %, Epsilon: 0.13, Delta: 0.0030
Epoch [2/12], Step [200/496], Loss: 1.3977, Accuracy: 66.88 %, Epsilon: 0.14, Delta: 0.0030
Epoch [2/12], Step [300/496], Loss: 1.4262, Accuracy: 69.25 %, Epsilon: 0.15, Delta: 0.0030
Epoch [2/12], Step [400/496], Loss: 1.5302, Accuracy: 69.56 %, Epsilon: 0.16, Delta: 0.0030
Predictions - 1s: 147, 0s: 1835
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [2/12] Loss: 1.5830, Accuracy: 69.07 %, Epsilon: 0.17, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 20, 0s: 476
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.2101, Validation Accuracy: 76.21 %
-------- Validation finished --------
Updated best model in epoch 2 saved with Validation Loss: 1.2101 and Validation Accuracy: 76.21 %
-------------------------------
Epoch [3/12], Step [100/496], Loss: 1.9266, Accuracy: 63.00 %, Epsilon: 0.18, Delta: 0.0030
Epoch [3/12], Step [200/496], Loss: 1.9654, Accuracy: 66.50 %, Epsilon: 0.19, Delta: 0.0030
Epoch [3/12], Step [300/496], Loss: 1.9248, Accuracy: 69.17 %, Epsilon: 0.20, Delta: 0.0030
Epoch [3/12], Step [400/496], Loss: 1.9573, Accuracy: 70.00 %, Epsilon: 0.21, Delta: 0.0030
Predictions - 1s: 147, 0s: 1835
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [3/12] Loss: 1.9865, Accuracy: 69.17 %, Epsilon: 0.22, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 34, 0s: 462
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.5846, Validation Accuracy: 73.39 %
-------- Validation finished --------
Epoch [4/12], Step [100/496], Loss: 1.7542, Accuracy: 68.00 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [200/496], Loss: 2.0316, Accuracy: 66.00 %, Epsilon: 0.23, Delta: 0.0030
Epoch [4/12], Step [300/496], Loss: 2.1080, Accuracy: 67.25 %, Epsilon: 0.24, Delta: 0.0030
Epoch [4/12], Step [400/496], Loss: 2.1225, Accuracy: 67.44 %, Epsilon: 0.25, Delta: 0.0030
Predictions - 1s: 200, 0s: 1782
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [4/12] Loss: 2.1277, Accuracy: 67.51 %, Epsilon: 0.26, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 16, 0s: 480
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.8081, Validation Accuracy: 75.00 %
-------- Validation finished --------
Epoch [5/12], Step [100/496], Loss: 2.2818, Accuracy: 65.25 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [200/496], Loss: 2.1165, Accuracy: 64.75 %, Epsilon: 0.27, Delta: 0.0030
Epoch [5/12], Step [300/496], Loss: 2.0391, Accuracy: 65.08 %, Epsilon: 0.28, Delta: 0.0030
Epoch [5/12], Step [400/496], Loss: 2.0353, Accuracy: 65.31 %, Epsilon: 0.29, Delta: 0.0030
Predictions - 1s: 268, 0s: 1714
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [5/12] Loss: 1.9349, Accuracy: 67.10 %, Epsilon: 0.29, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 19, 0s: 477
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.6761, Validation Accuracy: 74.80 %
-------- Validation finished --------
Epoch [6/12], Step [100/496], Loss: 1.5998, Accuracy: 70.75 %, Epsilon: 0.30, Delta: 0.0030
Epoch [6/12], Step [200/496], Loss: 1.7951, Accuracy: 64.62 %, Epsilon: 0.31, Delta: 0.0030
Epoch [6/12], Step [300/496], Loss: 1.8899, Accuracy: 63.25 %, Epsilon: 0.32, Delta: 0.0030
Epoch [6/12], Step [400/496], Loss: 1.9161, Accuracy: 64.44 %, Epsilon: 0.32, Delta: 0.0030
Predictions - 1s: 310, 0s: 1672
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [6/12] Loss: 1.9279, Accuracy: 65.59 %, Epsilon: 0.33, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 33, 0s: 463
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.7856, Validation Accuracy: 73.59 %
-------- Validation finished --------
Epoch [7/12], Step [100/496], Loss: 2.1276, Accuracy: 66.50 %, Epsilon: 0.33, Delta: 0.0030
Epoch [7/12], Step [200/496], Loss: 2.0356, Accuracy: 65.62 %, Epsilon: 0.34, Delta: 0.0030
Epoch [7/12], Step [300/496], Loss: 2.0699, Accuracy: 66.00 %, Epsilon: 0.35, Delta: 0.0030
Epoch [7/12], Step [400/496], Loss: 2.0875, Accuracy: 66.81 %, Epsilon: 0.35, Delta: 0.0030
Predictions - 1s: 244, 0s: 1738
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [7/12] Loss: 2.0990, Accuracy: 67.20 %, Epsilon: 0.36, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 21, 0s: 475
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.6468, Validation Accuracy: 74.80 %
-------- Validation finished --------
Epoch [8/12], Step [100/496], Loss: 2.3017, Accuracy: 69.00 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [200/496], Loss: 2.3841, Accuracy: 68.50 %, Epsilon: 0.37, Delta: 0.0030
Epoch [8/12], Step [300/496], Loss: 2.3178, Accuracy: 68.50 %, Epsilon: 0.38, Delta: 0.0030
Epoch [8/12], Step [400/496], Loss: 2.3445, Accuracy: 67.06 %, Epsilon: 0.38, Delta: 0.0030
Predictions - 1s: 180, 0s: 1802
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [8/12] Loss: 2.2711, Accuracy: 68.21 %, Epsilon: 0.39, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 12, 0s: 484
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.8487, Validation Accuracy: 75.81 %
-------- Validation finished --------
Epoch [9/12], Step [100/496], Loss: 2.3754, Accuracy: 66.50 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [200/496], Loss: 2.3180, Accuracy: 67.75 %, Epsilon: 0.40, Delta: 0.0030
Epoch [9/12], Step [300/496], Loss: 2.2566, Accuracy: 67.83 %, Epsilon: 0.41, Delta: 0.0030
Epoch [9/12], Step [400/496], Loss: 2.3834, Accuracy: 67.69 %, Epsilon: 0.41, Delta: 0.0030
Predictions - 1s: 195, 0s: 1787
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [9/12] Loss: 2.3780, Accuracy: 67.66 %, Epsilon: 0.42, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 15, 0s: 481
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.8121, Validation Accuracy: 75.20 %
-------- Validation finished --------
Epoch [10/12], Step [100/496], Loss: 2.1471, Accuracy: 66.75 %, Epsilon: 0.42, Delta: 0.0030
Epoch [10/12], Step [200/496], Loss: 2.3028, Accuracy: 64.75 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [300/496], Loss: 2.2377, Accuracy: 66.42 %, Epsilon: 0.43, Delta: 0.0030
Epoch [10/12], Step [400/496], Loss: 2.1584, Accuracy: 67.56 %, Epsilon: 0.44, Delta: 0.0030
Predictions - 1s: 188, 0s: 1794
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [10/12] Loss: 2.1437, Accuracy: 67.91 %, Epsilon: 0.44, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 8, 0s: 488
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.7711, Validation Accuracy: 75.81 %
-------- Validation finished --------
Epoch [11/12], Step [100/496], Loss: 2.0244, Accuracy: 70.50 %, Epsilon: 0.45, Delta: 0.0030
Epoch [11/12], Step [200/496], Loss: 2.1862, Accuracy: 69.38 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [300/496], Loss: 2.2396, Accuracy: 68.67 %, Epsilon: 0.46, Delta: 0.0030
Epoch [11/12], Step [400/496], Loss: 2.2633, Accuracy: 68.12 %, Epsilon: 0.47, Delta: 0.0030
Predictions - 1s: 187, 0s: 1795
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [11/12] Loss: 2.2282, Accuracy: 68.47 %, Epsilon: 0.47, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 23, 0s: 473
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.6912, Validation Accuracy: 74.40 %
-------- Validation finished --------
Epoch [12/12], Step [100/496], Loss: 2.3947, Accuracy: 64.50 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [200/496], Loss: 2.2297, Accuracy: 66.62 %, Epsilon: 0.48, Delta: 0.0030
Epoch [12/12], Step [300/496], Loss: 2.1593, Accuracy: 67.25 %, Epsilon: 0.49, Delta: 0.0030
Epoch [12/12], Step [400/496], Loss: 2.1458, Accuracy: 67.81 %, Epsilon: 0.49, Delta: 0.0030
Predictions - 1s: 216, 0s: 1766
True Labels - 1s: 560, 0s: 1422
-------------------------------
Epoch [12/12] Loss: 2.1412, Accuracy: 67.00 %, Epsilon: 0.50, Delta: 0.0030
-------------------------------
-------- Validation --------
Predictions - 1s: 28, 0s: 468
True Labels - 1s: 114, 0s: 382
Validation Loss: 1.6441, Validation Accuracy: 73.79 %
-------- Validation finished --------
Best model in epoch 2 saved with with Validation Loss: 1.2101 and Validation Accuracy: 76.21 %

-------- Training finished in 4:02 --------

Test flag enabled. Testing the model

-------- Loading best model from model_path --------
Loaded model bert-small from date 13-05-2024 11:49. Trained with Centralised Machine Learning technology.
Epoch 2, lr: 0.006, optimizer: DPOptimizer
Train accuracy: 69.07 %, Validation accuracy: 76.21 %
-------- Best model loaded --------

-------- Creating Test Dataloader --------
Test Loader: 618 total sentences. 78 batches of size 8.
-------- Test Dataloader created --------

-------- Testing --------
Predictions - 1s: 27, 0s: 591
True Labels - 1s: 168, 0s: 450
Nº of test samples: 618
Accuracy: 72.65%
Accuracy 2 : 72.65%
Precision: 60.96%
Recall: 52.31%
F1 Score: 48.55%
Classification report:
              precision    recall  f1-score   support

           0     0.7377    0.9689    0.8377       450
           1     0.4815    0.0774    0.1333       168

    accuracy                         0.7265       618
   macro avg     0.6096    0.5231    0.4855       618
weighted avg     0.6681    0.7265    0.6462       618

-------- Testing finished --------
